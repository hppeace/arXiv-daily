<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [YCB-Ev SD: Synthetic event-vision dataset for 6DoF object pose estimation](https://arxiv.org/abs/2511.11344)
*Pavel Rojtberg, Julius KÃ¼hn*

#### ğŸ§© TL;DR
æœ¬æ–‡æå‡ºäº†YCB-Ev SDï¼Œä¸€ä¸ªç”¨äº6DoFç‰©ä½“å§¿æ€ä¼°è®¡çš„æ ‡å‡†åˆ†è¾¨ç‡äº‹ä»¶ç›¸æœºåˆæˆæ•°æ®é›†ï¼Œå¡«è¡¥äº†äº‹ä»¶è§†è§‰é¢†åŸŸç¼ºä¹ç»¼åˆæ€§åˆæˆæ•°æ®èµ„æºçš„ç©ºç™½ã€‚é€šè¿‡ç³»ç»Ÿè¯„ä¼°ä¸åŒäº‹ä»¶è¡¨ç¤ºæ–¹æ³•ï¼Œç ”ç©¶å‘ç°çº¿æ€§è¡°å‡æ—¶é—´è¡¨é¢ä¸åŒé€šé“ææ€§ç¼–ç åœ¨CNNæ¨ç†ä¸­å®ç°äº†æœ€ä¼˜çš„å§¿æ€ä¼°è®¡æ€§èƒ½ã€‚

---

#### ğŸ“˜ Detailed Summary
**Motivation:** å½“å‰åˆæˆæ•°æ®åœ¨åŸºäºå¸§çš„è®¡ç®—æœºè§†è§‰ä¸­å·²æˆä¸ºåŸºç¡€èµ„æºï¼Œä½†äº‹ä»¶è§†è§‰é¢†åŸŸç¼ºä¹å¯æ¯”è¾ƒçš„ç»¼åˆæ€§æ•°æ®é›†ã€‚æœ¬æ–‡æ—¨åœ¨è§£å†³è¿™ä¸€ç ”ç©¶ç©ºç™½ï¼Œä¸º6DoFç‰©ä½“å§¿æ€ä¼°è®¡æä¾›æ ‡å‡†åˆ†è¾¨ç‡çš„äº‹ä»¶ç›¸æœºåˆæˆæ•°æ®èµ„æºã€‚

**Method:** é‡‡ç”¨åŸºäºç‰©ç†æ¸²æŸ“çš„åœºæ™¯ç”Ÿæˆ50,000ä¸ªæŒç»­34æ¯«ç§’çš„äº‹ä»¶åºåˆ—ï¼Œéµå¾ªBOPåŸºå‡†æ–¹æ³•ã€‚ç”Ÿæˆæ¡†æ¶ä½¿ç”¨æ¨¡æ‹Ÿçº¿æ€§ç›¸æœºè¿åŠ¨ç¡®ä¿å®Œæ•´åœºæ™¯è¦†ç›–ï¼ŒåŒ…æ‹¬èƒŒæ™¯æ´»åŠ¨ã€‚ç³»ç»Ÿè¯„ä¼°äº†ä¸åŒäº‹ä»¶è¡¨ç¤ºæ–¹æ³•ï¼ŒåŒ…æ‹¬æ—¶é—´è¡¨é¢ç¼–ç ç­–ç•¥å’Œææ€§ä¿¡æ¯å¤„ç†æ–¹å¼ã€‚

**Result:** å®éªŒè¡¨æ˜çº¿æ€§è¡°å‡æ—¶é—´è¡¨é¢ä¸åŒé€šé“ææ€§ç¼–ç åœ¨å§¿æ€ä¼°è®¡æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºæŒ‡æ•°è¡°å‡å’Œå•é€šé“æ›¿ä»£æ–¹æ¡ˆã€‚ææ€§ä¿¡æ¯å¯¹æ€§èƒ½æå‡è´¡çŒ®æœ€å¤§ï¼Œè€Œçº¿æ€§æ—¶é—´ç¼–ç æ¯”æŒ‡æ•°è¡°å‡æ›´æœ‰æ•ˆåœ°ä¿ç•™äº†å…³é”®è¿åŠ¨ä¿¡æ¯ã€‚

**Conclusion:** è¯¥ç ”ç©¶ä¸ºäº‹ä»¶è§†è§‰ç¤¾åŒºæä¾›äº†é¦–ä¸ªç»¼åˆæ€§åˆæˆæ•°æ®é›†ï¼Œä¿ƒè¿›äº†å¯å¤ç°çš„åŸºå‡†æµ‹è¯•å’Œç«‹å³ç ”ç©¶ä½¿ç”¨ã€‚ææ€§ä¿¡æ¯å’Œçº¿æ€§æ—¶é—´ç¼–ç çš„ä¼˜åŒ–ç»„åˆä¸ºäº‹ä»¶ç›¸æœºæ•°æ®å¤„ç†æä¾›äº†é‡è¦æŒ‡å¯¼ï¼Œæ•°æ®é›†ä»¥ç»“æ„åŒ–æ ¼å¼æä¾›åŸå§‹äº‹ä»¶æµå’Œé¢„è®¡ç®—æœ€ä¼˜è¡¨ç¤ºã€‚

---

#### ğŸ“„ Abstract
We introduce YCB-Ev SD, a synthetic dataset of event-camera data at standard definition (SD) resolution for 6DoF object pose estimation. While synthetic data has become fundamental in frame-based computer vision, event-based vision lacks comparable comprehensive resources. Addressing this gap, we present 50,000 event sequences of 34 ms duration each, synthesized from Physically Based Rendering (PBR) scenes of YCB-Video objects following the Benchmark for 6D Object Pose (BOP) methodology. Our generation framework employs simulated linear camera motion to ensure complete scene coverage, including background activity.
  Through systematic evaluation of event representations for CNN-based inference, we demonstrate that time-surfaces with linear decay and dual-channel polarity encoding achieve superior pose estimation performance, outperforming exponential decay and single-channel alternatives by significant margins. Our analysis reveals that polarity information contributes most substantially to performance gains, while linear temporal encoding preserves critical motion information more effectively than exponential decay. The dataset is provided in a structured format with both raw event streams and precomputed optimal representations to facilitate immediate research use and reproducible benchmarking.
  The dataset is publicly available at https://huggingface.co/datasets/paroj/ycbev_sd.
