{"id": "2602.09717", "categories": ["cs.CV", "cs.AI", "cs.ET", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.09717", "abs": "https://arxiv.org/abs/2602.09717", "authors": ["Radib Bin Kabir", "Tawsif Tashwar Dipto", "Mehedi Ahamed", "Sabbir Ahmed", "Md Hasanul Kabir"], "title": "From Lightweight CNNs to SpikeNets: Benchmarking Accuracy-Energy Tradeoffs with Pruned Spiking SqueezeNet", "comment": null, "summary": "Spiking Neural Networks (SNNs) are increasingly studied as energy-efficient alternatives to Convolutional Neural Networks (CNNs), particularly for edge intelligence. However, prior work has largely emphasized large-scale models, leaving the design and evaluation of lightweight CNN-to-SNN pipelines underexplored. In this paper, we present the first systematic benchmark of lightweight SNNs obtained by converting compact CNN architectures into spiking networks, where activations are modeled with Leaky-Integrate-and-Fire (LIF) neurons and trained using surrogate gradient descent under a unified setup. We construct spiking variants of ShuffleNet, SqueezeNet, MnasNet, and MixNet, and evaluate them on CIFAR-10, CIFAR-100, and TinyImageNet, measuring accuracy, F1-score, parameter count, computational complexity, and energy consumption. Our results show that SNNs can achieve up to 15.7x higher energy efficiency than their CNN counterparts while retaining competitive accuracy. Among these, the SNN variant of SqueezeNet consistently outperforms other lightweight SNNs. To further optimize this model, we apply a structured pruning strategy that removes entire redundant modules, yielding a pruned architecture, SNN-SqueezeNet-P. This pruned model improves CIFAR-10 accuracy by 6% and reduces parameters by 19% compared to the original SNN-SqueezeNet. Crucially, it narrows the gap with CNN-SqueezeNet, achieving nearly the same accuracy (only 1% lower) but with an 88.1% reduction in energy consumption due to sparse spike-driven computations. Together, these findings establish lightweight SNNs as practical, low-power alternatives for edge deployment, highlighting a viable path toward deploying high-performance, low-power intelligence on the edge.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u5bf9\u8f7b\u91cf\u7ea7\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u5c06\u7d27\u51d1\u578bCNN\u67b6\u6784\u8f6c\u6362\u4e3aSNN\u6a21\u578b\uff0c\u5e76\u5e94\u7528\u7ed3\u6784\u5316\u526a\u679d\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe15.7\u500d\u7684\u80fd\u91cf\u6548\u7387\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u6027\u7cbe\u5ea6\uff0c\u4e3a\u8fb9\u7f18\u667a\u80fd\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u4f4e\u529f\u8017\u66ff\u4ee3\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5927\u89c4\u6a21\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u800c\u8f7b\u91cf\u7ea7CNN\u5230SNN\u8f6c\u6362\u6d41\u7a0b\u7684\u8bbe\u8ba1\u4e0e\u8bc4\u4f30\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u8fd9\u9650\u5236\u4e86SNN\u4f5c\u4e3a\u80fd\u91cf\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\u5728\u8fb9\u7f18\u8ba1\u7b97\u573a\u666f\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u7814\u7a76\u91c7\u7528\u7edf\u4e00\u7684\u8f6c\u6362\u6846\u67b6\uff0c\u5c06ShuffleNet\u3001SqueezeNet\u3001MnasNet\u548cMixNet\u7b49\u7d27\u51d1\u578bCNN\u67b6\u6784\u8f6c\u6362\u4e3a\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u53d8\u4f53\uff0c\u4f7f\u7528Leaky-Integrate-and-Fire\u795e\u7ecf\u5143\u5efa\u6a21\u6fc0\u6d3b\uff0c\u901a\u8fc7\u66ff\u4ee3\u68af\u5ea6\u4e0b\u964d\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u5bf9\u6700\u4f73\u6a21\u578b\u5e94\u7528\u7ed3\u6784\u5316\u526a\u679d\u7b56\u7565\u79fb\u9664\u5197\u4f59\u6a21\u5757\uff0c\u5f97\u5230SNN-SqueezeNet-P\u67b6\u6784\u3002", "result": "\u5b9e\u9a8c\u5728CIFAR-10\u3001CIFAR-100\u548cTinyImageNet\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86\u51c6\u786e\u7387\u3001F1\u5206\u6570\u3001\u53c2\u6570\u91cf\u3001\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u80fd\u8017\u7b49\u6307\u6807\uff0c\u7ed3\u679c\u663e\u793aSNN\u76f8\u6bd4CNN\u53ef\u5b9e\u73b0\u9ad8\u8fbe15.7\u500d\u7684\u80fd\u91cf\u6548\u7387\u63d0\u5347\uff0c\u5176\u4e2dSNN-SqueezeNet\u8868\u73b0\u6700\u4f73\uff1b\u7ecf\u8fc7\u7ed3\u6784\u5316\u526a\u679d\u7684SNN-SqueezeNet-P\u5728CIFAR-10\u4e0a\u51c6\u786e\u7387\u63d0\u53476%\uff0c\u53c2\u6570\u91cf\u51cf\u5c1119%\uff0c\u4e0eCNN-SqueezeNet\u7684\u7cbe\u5ea6\u5dee\u8ddd\u4ec51%\uff0c\u4f46\u80fd\u8017\u964d\u4f4e88.1%\u3002", "conclusion": "\u8be5\u7814\u7a76\u786e\u7acb\u4e86\u8f7b\u91cf\u7ea7SNN\u4f5c\u4e3a\u8fb9\u7f18\u90e8\u7f72\u7684\u5b9e\u7528\u4f4e\u529f\u8017\u66ff\u4ee3\u65b9\u6848\uff0c\u8bc1\u660e\u4e86\u901a\u8fc7\u67b6\u6784\u8f6c\u6362\u548c\u4f18\u5316\u7b56\u7565\u53ef\u4ee5\u5728\u4fdd\u6301\u7ade\u4e89\u6027\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u80fd\u8017\uff0c\u4e3a\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u90e8\u7f72\u9ad8\u6027\u80fd\u3001\u4f4e\u529f\u8017\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2602.09746", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2602.09746", "abs": "https://arxiv.org/abs/2602.09746", "authors": ["Younes Bouhadjar", "Emre Neftci"], "title": "Sparse Axonal and Dendritic Delays Enable Competitive SNNs for Keyword Classification", "comment": "7 pages, 3 figures, and 4 tables", "summary": "Training transmission delays in spiking neural networks (SNNs) has been shown to substantially improve their performance on complex temporal tasks. In this work, we show that learning either axonal or dendritic delays enables deep feedforward SNNs composed of leaky integrate-and-fire (LIF) neurons to reach accuracy comparable to existing synaptic delay learning approaches, while significantly reducing memory and computational overhead. SNN models with either axonal or dendritic delays achieve up to $95.58\\%$ on the Google Speech Command (GSC) and $80.97\\%$ on the Spiking Speech Command (SSC) datasets, matching or exceeding prior methods based on synaptic delays or more complex neuron models. By adjusting the delay parameters, we obtain improved performance for synaptic delay learning baselines, strengthening the comparison. We find that axonal delays offer the most favorable trade-off, combining lower buffering requirements with slightly higher accuracy than dendritic delays. We further show that the performance of axonal and dendritic delay models is largely preserved under strong delay sparsity, with as few as $20\\%$ of delays remaining active, further reducing buffering requirements. Overall, our results indicate that learnable axonal and dendritic delays provide a resource-efficient and effective mechanism for temporal representation in SNNs. Code will be made available publicly upon acceptance. Code is available at https://github.com/YounesBouhadjar/AxDenSynDelaySNN", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u5728\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u4e2d\u5b66\u4e60\u8f74\u7a81\u6216\u6811\u7a81\u5ef6\u8fdf\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684\u7a81\u89e6\u5ef6\u8fdf\u5b66\u4e60\u65b9\u6cd5\uff0c\u80fd\u4ee5\u66f4\u4f4e\u7684\u5185\u5b58\u548c\u8ba1\u7b97\u5f00\u9500\u5b9e\u73b0\u76f8\u5f53\u7684\u65f6\u5e8f\u4efb\u52a1\u6027\u80fd\uff0c\u4e3aSNN\u63d0\u4f9b\u4e86\u4e00\u79cd\u8d44\u6e90\u9ad8\u6548\u7684\u65f6\u5e8f\u8868\u793a\u673a\u5236\u3002", "motivation": "\u73b0\u6709\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u53ef\u5b66\u4e60\u4f20\u8f93\u5ef6\u8fdf\u65b9\u6cd5\uff08\u7279\u522b\u662f\u7a81\u89e6\u5ef6\u8fdf\uff09\u5b58\u5728\u8f83\u9ad8\u7684\u5185\u5b58\u548c\u8ba1\u7b97\u5f00\u9500\uff0c\u9700\u8981\u63a2\u7d22\u66f4\u9ad8\u6548\u7684\u5ef6\u8fdf\u5b66\u4e60\u673a\u5236\u6765\u63d0\u5347SNN\u5728\u590d\u6742\u65f6\u5e8f\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u540c\u65f6\u964d\u4f4e\u8d44\u6e90\u6d88\u8017\u3002", "method": "\u7814\u7a76\u91c7\u7528\u7531\u6cc4\u6f0f\u79ef\u5206\u53d1\u653e\u795e\u7ecf\u5143\u7ec4\u6210\u7684\u6df1\u5ea6\u524d\u9988SNN\u67b6\u6784\uff0c\u5206\u522b\u5b9e\u73b0\u4e86\u8f74\u7a81\u5ef6\u8fdf\u548c\u6811\u7a81\u5ef6\u8fdf\u7684\u5b66\u4e60\u673a\u5236\uff0c\u5e76\u4e0e\u4f20\u7edf\u7684\u7a81\u89e6\u5ef6\u8fdf\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u5bf9\u6bd4\uff0c\u901a\u8fc7\u8c03\u6574\u5ef6\u8fdf\u53c2\u6570\u4f18\u5316\u57fa\u7ebf\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5728Google Speech Command\u548cSpiking Speech Command\u6570\u636e\u96c6\u4e0a\uff0c\u8f74\u7a81\u548c\u6811\u7a81\u5ef6\u8fdf\u6a21\u578b\u5206\u522b\u8fbe\u523095.58%\u548c80.97%\u7684\u51c6\u786e\u7387\uff0c\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u57fa\u4e8e\u7a81\u89e6\u5ef6\u8fdf\u6216\u66f4\u590d\u6742\u795e\u7ecf\u5143\u6a21\u578b\u7684\u5148\u524d\u65b9\u6cd5\uff0c\u4e14\u8f74\u7a81\u5ef6\u8fdf\u5728\u7f13\u51b2\u9700\u6c42\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u63d0\u4f9b\u4e86\u6700\u4f73\u6743\u8861\uff0c\u5373\u4f7f\u572820%\u5ef6\u8fdf\u7a00\u758f\u6027\u4e0b\u6027\u80fd\u4ecd\u57fa\u672c\u4fdd\u6301\u3002", "conclusion": "\u53ef\u5b66\u4e60\u7684\u8f74\u7a81\u548c\u6811\u7a81\u5ef6\u8fdf\u4e3aSNN\u63d0\u4f9b\u4e86\u4e00\u79cd\u8d44\u6e90\u9ad8\u6548\u4e14\u6709\u6548\u7684\u65f6\u5e8f\u8868\u793a\u673a\u5236\uff0c\u8f74\u7a81\u5ef6\u8fdf\u5c24\u5176\u5177\u6709\u4f18\u52bf\uff0c\u5176\u8f83\u4f4e\u7684\u7f13\u51b2\u9700\u6c42\u548c\u826f\u597d\u7684\u6027\u80fd\u4fdd\u6301\u80fd\u529b\u4f7f\u5176\u66f4\u9002\u5408\u5b9e\u9645\u90e8\u7f72\uff0c\u5ef6\u8fdf\u7a00\u758f\u6027\u8fdb\u4e00\u6b65\u964d\u4f4e\u4e86\u8d44\u6e90\u9700\u6c42\u3002"}}
