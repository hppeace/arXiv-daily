<div id=toc></div>

# Table of Contents

- [cs.NE](#cs.NE) [Total: 1]


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [1] [Unveiling the Spatial-temporal Effective Receptive Fields of Spiking Neural Networks](https://arxiv.org/abs/2510.21403)
*Jieyuan Zhang, Xiaolong Zhou, Shuai Wang, Wenjie Wei, Hanwen Liu, Qian Sun, Malu Zhang, Yang Yang, Haizhou Li*

#### ğŸ§© TL;DR
æœ¬æ–‡æå‡ºäº†æ—¶ç©ºæœ‰æ•ˆæ„Ÿå—é‡ï¼ˆST-ERFï¼‰æ¡†æ¶æ¥åˆ†æåŸºäºTransformerçš„è„‰å†²ç¥ç»ç½‘ç»œï¼Œå¹¶è®¾è®¡äº†ä¸¤ç§æ–°å‹é€šé“æ··åˆå™¨æ¶æ„MLPixerå’ŒSRBæ¥å¢å¼ºå…¨å±€æ—¶ç©ºæ„Ÿå—é‡ï¼Œæ˜¾è‘—æå‡äº†è§†è§‰é•¿åºåˆ—å»ºæ¨¡ä»»åŠ¡çš„æ€§èƒ½ã€‚

---

#### ğŸ“˜ Detailed Summary
**Motivation:** è„‰å†²ç¥ç»ç½‘ç»œåœ¨è§†è§‰é•¿åºåˆ—å»ºæ¨¡ä»»åŠ¡ä¸­éš¾ä»¥è¾¾åˆ°ç«äº‰æ€§æ€§èƒ½ï¼Œä¸»è¦é—®é¢˜åœ¨äºç¼ºä¹æœ‰æ•ˆçš„å…¨å±€æ—¶ç©ºç‰¹å¾æå–èƒ½åŠ›ï¼Œè€Œä¼ ç»Ÿæœ‰æ•ˆæ„Ÿå—é‡åˆ†æå·¥å…·åœ¨SNNä¸­çš„é€‚ç”¨æ€§å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚

**Method:** æå‡ºäº†æ—¶ç©ºæœ‰æ•ˆæ„Ÿå—é‡ï¼ˆST-ERFï¼‰åˆ†ææ¡†æ¶æ¥è¯„ä¼°Transformer-based SNNsçš„æ„Ÿå—é‡åˆ†å¸ƒç‰¹æ€§ï¼Œå¹¶è®¾è®¡äº†ä¸¤ç§æ–°å‹é€šé“æ··åˆå™¨æ¶æ„ï¼šåŸºäºå¤šå±‚æ„ŸçŸ¥æœºçš„MLPixerå’ŒåŸºäºsplash-and-reconstructçš„SRBæ¨¡å—ï¼Œé€šè¿‡åœ¨æ—©æœŸç½‘ç»œé˜¶æ®µå¢å¼ºå…¨å±€ç©ºé—´æ„Ÿå—é‡æ¥æ”¹è¿›ç‰¹å¾å»ºæ¨¡èƒ½åŠ›ã€‚

**Result:** åœ¨Meta-SDTå˜ä½“ä»¥åŠç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸Šçš„å¹¿æ³›å®éªŒéªŒè¯äº†æ‰€ææ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œæ˜¾è‘—æå‡äº†åŸºäºTransformerçš„SNNsåœ¨è§†è§‰é•¿åºåˆ—å»ºæ¨¡ä»»åŠ¡ä¸­çš„æ€§èƒ½è¡¨ç°ã€‚

**Conclusion:** æå‡ºçš„ST-ERFæ¡†æ¶ä¸ä»…è§£å†³äº†å½“å‰SNNsåœ¨è§†è§‰é•¿åºåˆ—å»ºæ¨¡ä¸­çš„æ€§èƒ½ç“¶é¢ˆï¼Œè¿˜ä¸ºæ›´å¹¿æ³›SNNæ¶æ„çš„è®¾è®¡å’Œä¼˜åŒ–æä¾›äº†æœ‰ä»·å€¼çš„åˆ†æå·¥å…·å’Œè®¾è®¡æ€è·¯ï¼Œæ¨åŠ¨äº†è„‰å†²ç¥ç»ç½‘ç»œåœ¨å¤æ‚è§†è§‰ä»»åŠ¡ä¸­çš„åº”ç”¨å‘å±•ã€‚

---

#### ğŸ“„ Abstract
Spiking Neural Networks (SNNs) demonstrate significant potential for
energy-efficient neuromorphic computing through an event-driven paradigm. While
training methods and computational models have greatly advanced, SNNs struggle
to achieve competitive performance in visual long-sequence modeling tasks. In
artificial neural networks, the effective receptive field (ERF) serves as a
valuable tool for analyzing feature extraction capabilities in visual
long-sequence modeling. Inspired by this, we introduce the Spatio-Temporal
Effective Receptive Field (ST-ERF) to analyze the ERF distributions across
various Transformer-based SNNs. Based on the proposed ST-ERF, we reveal that
these models suffer from establishing a robust global ST-ERF, thereby limiting
their visual feature modeling capabilities. To overcome this issue, we propose
two novel channel-mixer architectures:
\underline{m}ulti-\underline{l}ayer-\underline{p}erceptron-based
m\underline{ixer} (MLPixer) and \underline{s}plash-and-\underline{r}econstruct
\underline{b}lock (SRB). These architectures enhance global spatial ERF through
all timesteps in early network stages of Transformer-based SNNs, improving
performance on challenging visual long-sequence modeling tasks. Extensive
experiments conducted on the Meta-SDT variants and across object detection and
semantic segmentation tasks further validate the effectiveness of our proposed
method. Beyond these specific applications, we believe the proposed ST-ERF
framework can provide valuable insights for designing and optimizing SNN
architectures across a broader range of tasks. The code is available at
\href{https://github.com/EricZhang1412/Spatial-temporal-ERF}{\faGithub~EricZhang1412/Spatial-temporal-ERF}.
