{"id": "2602.20548", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.20548", "abs": "https://arxiv.org/abs/2602.20548", "authors": ["Shuai Wang", "Malu Zhang", "Yulin Jiang", "Dehao Zhang", "Ammar Belatreche", "Yu Liang", "Yimeng Shan", "Zijian Zhou", "Yang Yang", "Haizhou Li"], "title": "Robust Spiking Neural Networks Against Adversarial Attacks", "comment": "Published as a conference paper at ICLR 2026", "summary": "Spiking Neural Networks (SNNs) represent a promising paradigm for energy-efficient neuromorphic computing due to their bio-plausible and spike-driven characteristics. However, the robustness of SNNs in complex adversarial environments remains significantly constrained. In this study, we theoretically demonstrate that those threshold-neighboring spiking neurons are the key factors limiting the robustness of directly trained SNNs. We find that these neurons set the upper limits for the maximum potential strength of adversarial attacks and are prone to state-flipping under minor disturbances. To address this challenge, we propose a Threshold Guarding Optimization (TGO) method, which comprises two key aspects. First, we incorporate additional constraints into the loss function to move neurons' membrane potentials away from their thresholds. It increases SNNs' gradient sparsity, thereby reducing the theoretical upper bound of adversarial attacks. Second, we introduce noisy spiking neurons to transition the neuronal firing mechanism from deterministic to probabilistic, decreasing their state-flipping probability due to minor disturbances. Extensive experiments conducted in standard adversarial scenarios prove that our method significantly enhances the robustness of directly trained SNNs. These findings pave the way for advancing more reliable and secure neuromorphic computing in real-world applications."}
{"id": "2602.20790", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.20790", "abs": "https://arxiv.org/abs/2602.20790", "authors": ["Sheng Zhong", "Zhongyang Ren", "Xiya Zhu", "Dehao Yuan", "Cornelia Fermuller", "Yi Zhou"], "title": "Real-time Motion Segmentation with Event-based Normal Flow", "comment": null, "summary": "Event-based cameras are bio-inspired sensors with pixels that independently and asynchronously respond to brightness changes at microsecond resolution, offering the potential to handle visual tasks in challenging scenarios. However, due to the sparse information content in individual events, directly processing the raw event data to solve vision tasks is highly inefficient, which severely limits the applicability of state-of-the-art methods in real-time tasks, such as motion segmentation, a fundamental task for dynamic scene understanding. Incorporating normal flow as an intermediate representation to compress motion information from event clusters within a localized region provides a more effective solution. In this work, we propose a normal flow-based motion segmentation framework for event-based vision. Leveraging the dense normal flow directly learned from event neighborhoods as input, we formulate the motion segmentation task as an energy minimization problem solved via graph cuts, and optimize it iteratively with normal flow clustering and motion model fitting. By using a normal flow-based motion model initialization and fitting method, the proposed system is able to efficiently estimate the motion models of independently moving objects with only a limited number of candidate models, which significantly reduces the computational complexity and ensures real-time performance, achieving nearly a 800x speedup in comparison to the open-source state-of-the-art method. Extensive evaluations on multiple public datasets fully demonstrate the accuracy and efficiency of our framework."}
