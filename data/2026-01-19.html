<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <title>2026-01-19.md</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@5/github-markdown.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <style>
    body {
      background-color: #fafafa;
      font-family: 'Inter', sans-serif;
      padding: 2rem;
    }
    .markdown-body {
      max-width: 900px;
      margin: auto;
      background: white;
      padding: 2rem;
      border-radius: 12px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    h1, h2, h3 {
      border-bottom: 1px solid #eaecef;
      padding-bottom: 0.3em;
    }
  </style>
</head>
<body>
  <article class="markdown-body">
    <div id=toc></div>

<h1 id="table-of-contents">Table of Contents</h1>
<ul>
<li><a href="#cs.NE">cs.NE</a> [Total: 2]</li>
</ul>
<div id='cs.NE'></div>

<h1 id="csne-back">cs.NE <a href="#toc">[Back]</a></h1>
<h3 id="1-line-based-event-preprocessing-towards-low-energy-neuromorphic-computer-vision">[1] <a href="https://arxiv.org/abs/2601.10742">Line-based Event Preprocessing: Towards Low-Energy Neuromorphic Computer Vision</a></h3>
<p><em>AmÃ©lie Gruel, Pierre Lewden, Adrien F. Vincent, Sylvain SaÃ¯ghi</em></p>
<h4 id="tldr">ğŸ§© TL;DR</h4>
<p>è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºçº¿æ®µçš„äº‹ä»¶æ•°æ®é¢„å¤„ç†æ–¹æ³•ï¼Œç”¨äºä¼˜åŒ–ç¥ç»å½¢æ€è§†è§‰ç³»ç»Ÿçš„èƒ½è€—ï¼Œåœ¨ä¸‰ä¸ªåŸºå‡†äº‹ä»¶æ•°æ®é›†ä¸Šå®ç°äº†èƒ½è€—ä¸åˆ†ç±»æ€§èƒ½ä¹‹é—´çš„æœ‰åˆ©æƒè¡¡ã€‚</p>
<hr />
<h4 id="detailed-summary">ğŸ“˜ Detailed Summary</h4>
<p><strong>Motivation:</strong> å°½ç®¡ç¥ç»å½¢æ€è§†è§‰åœ¨ç”Ÿç‰©å¯å‘æ€§ã€èƒ½è€—ã€å»¶è¿Ÿå’ŒåŠ¨æ€è§†è§‰æ•°æ®å¤„ç†å†…å­˜ä½¿ç”¨æ–¹é¢å…·æœ‰ä¼˜åŠ¿ï¼Œä½†å…¶èƒ½è€—ä¼˜åŒ–ä»æ˜¯åµŒå…¥å¼åº”ç”¨é¢ä¸´çš„é‡è¦æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯ç¥ç»å½¢æ€ç¡¬ä»¶çš„èƒ½è€—ä¸çªè§¦æ“ä½œæ•°é‡æˆæ­£æ¯”ï¼Œå› æ­¤éœ€è¦é¢„å¤„ç†äº‹ä»¶æ•°æ®ä»¥ä¼˜åŒ–æ•°æ®é‡ã€‚</p>
<p><strong>Method:</strong> ç ”ç©¶æ‰©å±•äº†ç«¯åˆ°ç«¯ç¥ç»å½¢æ€çº¿æ®µæ£€æµ‹æœºåˆ¶ï¼Œå¼•å…¥äº†åŸºäºçº¿æ®µçš„äº‹ä»¶æ•°æ®é¢„å¤„ç†æ–¹æ³•ï¼Œé€šè¿‡é¢„å¤„ç†ç­–ç•¥å‡å°‘éœ€è¦å¤„ç†çš„äº‹ä»¶æ•°é‡ï¼Œä»è€Œé™ä½ç¥ç»å½¢æ€ç¡¬ä»¶ä¸Šçš„ç†è®ºèƒ½è€—ã€‚</p>
<p><strong>Result:</strong> åœ¨ä¸‰ä¸ªåŸºå‡†äº‹ä»¶æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œé¢„å¤„ç†æ–¹æ³•åœ¨èƒ½è€—å’Œåˆ†ç±»æ€§èƒ½ä¹‹é—´å®ç°äº†æœ‰åˆ©æƒè¡¡ï¼Œæ ¹æ®ä¸åŒçš„çº¿æ®µé¢„å¤„ç†ç­–ç•¥å’Œåˆ†ç±»ä»»åŠ¡å¤æ‚åº¦ï¼Œå¯ä»¥ä¿æŒæˆ–æé«˜åˆ†ç±»å‡†ç¡®ç‡çš„åŒæ—¶æ˜¾è‘—é™ä½ç†è®ºèƒ½è€—ã€‚</p>
<p><strong>Conclusion:</strong> è¯¥ç ”ç©¶ç³»ç»Ÿæ€§åœ°æé«˜äº†ç¥ç»å½¢æ€åˆ†ç±»çš„æ•ˆç‡ï¼Œä¸ºé€šè¿‡äº‹ä»¶é¢„å¤„ç†å®ç°æ›´èŠ‚èƒ½çš„ç¥ç»å½¢æ€è®¡ç®—æœºè§†è§‰å¥ å®šäº†åŸºç¡€ï¼Œå±•ç¤ºäº†é¢„å¤„ç†åœ¨ä¼˜åŒ–ç¥ç»å½¢æ€ç³»ç»Ÿèƒ½è€—æ€§èƒ½å¹³è¡¡æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
<hr />
<h4 id="abstract">ğŸ“„ Abstract</h4>
<p>Neuromorphic vision made significant progress in recent years, thanks to the natural match between spiking neural networks and event data in terms of biological inspiration, energy savings, latency and memory use for dynamic visual data processing. However, optimising its energy requirements still remains a challenge within the community, especially for embedded applications. One solution may reside in preprocessing events to optimise data quantity thus lowering the energy cost on neuromorphic hardware, proportional to the number of synaptic operations. To this end, we extend an end-to-end neuromorphic line detection mechanism to introduce line-based event data preprocessing. Our results demonstrate on three benchmark event-based datasets that preprocessing leads to an advantageous trade-off between energy consumption and classification performance. Depending on the line-based preprocessing strategy and the complexity of the classification task, we show that one can maintain or increase the classification accuracy while significantly reducing the theoretical energy consumption. Our approach systematically leads to a significant improvement of the neuromorphic classification efficiency, thus laying the groundwork towards a more frugal neuromorphic computer vision thanks to event preprocessing.</p>
<h3 id="2-effects-of-introducing-synaptic-scaling-on-spiking-neural-network-learning">[2] <a href="https://arxiv.org/abs/2601.11261">Effects of Introducing Synaptic Scaling on Spiking Neural Network Learning</a></h3>
<p><em>Shinnosuke Touda, Hirotsugu Okuno</em></p>
<h4 id="tldr_1">ğŸ§© TL;DR</h4>
<p>è¯¥ç ”ç©¶æ¢ç´¢äº†å¤šç§ç¥ç»å¯å¡‘æ€§æœºåˆ¶ï¼ˆSTDPå’Œçªè§¦ç¼©æ”¾ï¼‰å¯¹è„‰å†²ç¥ç»ç½‘ç»œä¸­èƒœè€…å…¨å¾—ç½‘ç»œå­¦ä¹ æ€§èƒ½çš„å½±å“ï¼Œå‘ç°åŸºäºL2èŒƒæ•°çš„çªè§¦ç¼©æ”¾èƒ½æ˜¾è‘—æå‡åˆ†ç±»å‡†ç¡®ç‡ã€‚</p>
<hr />
<h4 id="detailed-summary_1">ğŸ“˜ Detailed Summary</h4>
<p><strong>Motivation:</strong> è¯¥ç ”ç©¶æ—¨åœ¨æ¢ç´¢å¤šç§ç¥ç»å¯å¡‘æ€§æœºåˆ¶ï¼ˆå¦‚è„‰å†²æ—¶é—´ä¾èµ–å¯å¡‘æ€§å’Œçªè§¦ç¼©æ”¾ï¼‰å¯¹è„‰å†²ç¥ç»ç½‘ç»œå­¦ä¹ æ€§èƒ½çš„å½±å“ï¼Œç‰¹åˆ«æ˜¯è¿™äº›ç”Ÿç‰©å¯å‘çš„æ— ç›‘ç£å­¦ä¹ æœºåˆ¶å¦‚ä½•ååŒä½œç”¨ä»¥æå‡èƒœè€…å…¨å¾—ç½‘ç»œçš„åˆ†ç±»èƒ½åŠ›ã€‚</p>
<p><strong>Method:</strong> ç ”ç©¶æ„å»ºäº†ä¸€ä¸ªåŸºäºPythonå®ç°çš„èƒœè€…å…¨å¾—è„‰å†²ç¥ç»ç½‘ç»œï¼Œæ•´åˆäº†å¤šç§ç¥ç»å¯å¡‘æ€§æœºåˆ¶ï¼ŒåŒ…æ‹¬è„‰å†²æ—¶é—´ä¾èµ–å¯å¡‘æ€§å’Œä¸åŒç±»å‹çš„çªè§¦ç¼©æ”¾æ–¹æ³•ï¼Œä½¿ç”¨MNISTå’ŒFashion-MNISTæ•°æ®é›†è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ï¼Œå¹¶ç³»ç»Ÿè°ƒæ•´äº†ç¥ç»å…ƒæ•°é‡ã€STDPæ—¶é—´å¸¸æ•°å’Œçªè§¦ç¼©æ”¾å½’ä¸€åŒ–æ–¹æ³•ç­‰å…³é”®å‚æ•°ã€‚</p>
<p><strong>Result:</strong> å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºL2èŒƒæ•°çš„çªè§¦ç¼©æ”¾æ–¹æ³•å¯¹æå‡åˆ†ç±»æ€§èƒ½æœ€ä¸ºæœ‰æ•ˆï¼Œå½“å…´å¥‹å±‚å’ŒæŠ‘åˆ¶å±‚å‡è®¾ç½®ä¸º400ä¸ªç¥ç»å…ƒæ—¶ï¼Œç½‘ç»œåœ¨MNISTæ•°æ®é›†ä¸Šè¾¾åˆ°88.84%çš„åˆ†ç±»å‡†ç¡®ç‡ï¼Œåœ¨Fashion-MNISTæ•°æ®é›†ä¸Šè¾¾åˆ°68.01%çš„å‡†ç¡®ç‡ï¼Œä»…éœ€ä¸€ä¸ªè®­ç»ƒå‘¨æœŸã€‚</p>
<p><strong>Conclusion:</strong> è¯¥ç ”ç©¶è¯å®äº†å¤šç§ç¥ç»å¯å¡‘æ€§æœºåˆ¶ååŒä½œç”¨èƒ½æœ‰æ•ˆæå‡è„‰å†²ç¥ç»ç½‘ç»œçš„å­¦ä¹ æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯L2èŒƒæ•°çªè§¦ç¼©æ”¾çš„å…³é”®ä½œç”¨ï¼Œä¸ºå¼€å‘æ›´é«˜æ•ˆã€æ›´ç”Ÿç‰©åˆç†çš„æ— ç›‘ç£å­¦ä¹ ç®—æ³•æä¾›äº†é‡è¦è§è§£ï¼Œå¹¶å±•ç¤ºäº†è„‰å†²ç¥ç»ç½‘ç»œåœ¨æ¨¡å¼è¯†åˆ«ä»»åŠ¡ä¸­çš„æ½œåŠ›ã€‚</p>
<hr />
<h4 id="abstract_1">ğŸ“„ Abstract</h4>
<p>Spiking neural networks (SNNs) employing unsupervised learning methods inspired by neural plasticity are expected to be a new framework for artificial intelligence. In this study, we investigated the effect of multiple types of neural plasticity, such as spike-time-dependent plasticity (STDP) and synaptic scaling, on the learning in a winner-take-all (WTA) network composed of spiking neurons. We implemented a WTA network with multiple types of neural plasticity using Python. The MNIST and the Fashion-MNIST datasets were used for training and testing. We varied the number of neurons, the time constant of STDP, and the normalization method used in synaptic scaling to compare classification accuracy. The results demonstrated that synaptic scaling based on the L2 norm was the most effective in improving classification performance. By implementing L2-norm-based synaptic scaling and setting the number of neurons in both excitatory and inhibitory layers to 400, the network achieved classification accuracies of 88.84 % on the MNIST dataset and 68.01 % on the Fashion-MNIST dataset after one epoch of training.</p>
  </article>
</body>
</html>
