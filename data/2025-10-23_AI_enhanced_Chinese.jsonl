{"id": "2510.19560", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.19560", "abs": "https://arxiv.org/abs/2510.19560", "authors": ["Yao Deng", "Xian Zhong", "Wenxuan Liu", "Zhaofei Yu", "Jingling Yuan", "Tiejun Huang"], "title": "HAD: Hierarchical Asymmetric Distillation to Bridge Spatio-Temporal Gaps in Event-Based Object Tracking", "comment": null, "summary": "RGB cameras excel at capturing rich texture details with high spatial\nresolution, whereas event cameras offer exceptional temporal resolution and a\nhigh dynamic range (HDR). Leveraging their complementary strengths can\nsubstantially enhance object tracking under challenging conditions, such as\nhigh-speed motion, HDR environments, and dynamic background interference.\nHowever, a significant spatio-temporal asymmetry exists between these two\nmodalities due to their fundamentally different imaging mechanisms, hindering\neffective multi-modal integration. To address this issue, we propose\n{Hierarchical Asymmetric Distillation} (HAD), a multi-modal knowledge\ndistillation framework that explicitly models and mitigates spatio-temporal\nasymmetries. Specifically, HAD proposes a hierarchical alignment strategy that\nminimizes information loss while maintaining the student network's\ncomputational efficiency and parameter compactness. Extensive experiments\ndemonstrate that HAD consistently outperforms state-of-the-art methods, and\ncomprehensive ablation studies further validate the effectiveness and necessity\nof each designed component. The code will be released soon.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c42\u6b21\u5316\u975e\u5bf9\u79f0\u84b8\u998f\uff08HAD\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u548c\u7f13\u89e3RGB\u76f8\u673a\u4e0e\u4e8b\u4ef6\u76f8\u673a\u4e4b\u95f4\u7684\u65f6\u7a7a\u4e0d\u5bf9\u79f0\u6027\uff0c\u6709\u6548\u878d\u5408\u4e24\u79cd\u6a21\u6001\u7684\u4e92\u8865\u4f18\u52bf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u76ee\u6807\u8ddf\u8e2a\u6027\u80fd\u3002", "motivation": "RGB\u76f8\u673a\u548c\u4e8b\u4ef6\u76f8\u673a\u5728\u6210\u50cf\u673a\u5236\u4e0a\u5b58\u5728\u6839\u672c\u5dee\u5f02\uff0c\u5bfc\u81f4\u663e\u8457\u7684\u65f6\u7a7a\u4e0d\u5bf9\u79f0\u6027\uff0c\u963b\u788d\u4e86\u4e24\u79cd\u6a21\u6001\u7684\u6709\u6548\u878d\u5408\u3002\u8fd9\u79cd\u4e0d\u5bf9\u79f0\u6027\u9650\u5236\u4e86\u5728\u9ad8\u901f\u8fd0\u52a8\u3001\u9ad8\u52a8\u6001\u8303\u56f4\u73af\u5883\u548c\u52a8\u6001\u80cc\u666f\u5e72\u6270\u7b49\u6311\u6218\u6027\u6761\u4ef6\u4e0b\u76ee\u6807\u8ddf\u8e2a\u6027\u80fd\u7684\u63d0\u5347\u3002", "method": "\u63d0\u51fa\u5c42\u6b21\u5316\u975e\u5bf9\u79f0\u84b8\u998f\uff08HAD\uff09\u6846\u67b6\uff0c\u91c7\u7528\u5c42\u6b21\u5316\u5bf9\u9f50\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u5b66\u751f\u7f51\u7edc\u8ba1\u7b97\u6548\u7387\u548c\u53c2\u6570\u7d27\u51d1\u6027\u7684\u540c\u65f6\u6700\u5c0f\u5316\u4fe1\u606f\u635f\u5931\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u65f6\u7a7a\u4e0d\u5bf9\u79f0\u6027\u6765\u5b9e\u73b0\u591a\u6a21\u6001\u77e5\u8bc6\u84b8\u998f\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660eHAD\u6846\u67b6\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5168\u9762\u7684\u6d88\u878d\u7814\u7a76\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u6bcf\u4e2a\u8bbe\u8ba1\u7ec4\u4ef6\u7684\u6709\u6548\u6027\u548c\u5fc5\u8981\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u548c\u7f13\u89e3\u6a21\u6001\u95f4\u4e0d\u5bf9\u79f0\u6027\u53ef\u4ee5\u6709\u6548\u878d\u5408\u4e92\u8865\u4fe1\u606f\uff0c\u4e3a\u591a\u6a21\u6001\u89c6\u89c9\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e3a\u672a\u6765\u5728\u8ba1\u7b97\u6548\u7387\u548c\u6027\u80fd\u5e73\u8861\u65b9\u9762\u7684\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2510.19764", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2510.19764", "abs": "https://arxiv.org/abs/2510.19764", "authors": ["James C. Knight", "Johanna Senk", "Thomas Nowotny"], "title": "A flexible framework for structural plasticity in GPU-accelerated sparse spiking neural networks", "comment": "22 pages, 9 figures, 2 tables", "summary": "The majority of research in both training Artificial Neural Networks (ANNs)\nand modeling learning in biological brains focuses on synaptic plasticity,\nwhere learning equates to changing the strength of existing connections.\nHowever, in biological brains, structural plasticity - where new connections\nare created and others removed - is also vital, not only for effective learning\nbut also for recovery from damage and optimal resource usage. Inspired by\nstructural plasticity, pruning is often used in machine learning to remove weak\nconnections from trained models to reduce the computational requirements of\ninference. However, the machine learning frameworks typically used for\nbackpropagation-based training of both ANNs and Spiking Neural Networks (SNNs)\nare optimized for dense connectivity, meaning that pruning does not help reduce\nthe training costs of ever-larger models. The GeNN simulator already supports\nefficient GPU-accelerated simulation of sparse SNNs for computational\nneuroscience and machine learning. Here, we present a new flexible framework\nfor implementing GPU-accelerated structural plasticity rules and demonstrate\nthis first using the e-prop supervised learning rule and DEEP R to train\nefficient, sparse SNN classifiers and then, in an unsupervised learning\ncontext, to learn topographic maps. Compared to baseline dense models, our\nsparse classifiers reduce training time by up to 10x while the DEEP R rewiring\nenables them to perform as well as the original models. We demonstrate\ntopographic map formation in faster-than-realtime simulations, provide insights\ninto the connectivity evolution, and measure simulation speed versus network\nsize. The proposed framework will enable further research into achieving and\nmaintaining sparsity in network structure and neural communication, as well as\nexploring the computational benefits of sparsity in a range of neuromorphic\napplications.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u652f\u6301GPU\u52a0\u901f\u7ed3\u6784\u53ef\u5851\u6027\u89c4\u5219\u7684\u65b0\u578b\u7075\u6d3b\u6846\u67b6\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u5728\u76d1\u7763\u548c\u65e0\u76d1\u7763\u5b66\u4e60\u73af\u5883\u4e2d\u8bad\u7ec3\u7a00\u758f\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff0c\u76f8\u6bd4\u5bc6\u96c6\u6a21\u578b\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c11\u9ad8\u8fbe10\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u540c\u7b49\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u548c\u751f\u7269\u5927\u8111\u5b66\u4e60\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u7a81\u89e6\u53ef\u5851\u6027\uff0c\u800c\u5ffd\u89c6\u4e86\u7ed3\u6784\u53ef\u5851\u6027\u5728\u6709\u6548\u5b66\u4e60\u3001\u635f\u4f24\u6062\u590d\u548c\u8d44\u6e90\u4f18\u5316\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002\u867d\u7136\u526a\u679d\u6280\u672f\u5e38\u7528\u4e8e\u51cf\u5c11\u63a8\u7406\u8ba1\u7b97\u9700\u6c42\uff0c\u4f46\u73b0\u6709\u673a\u5668\u5b66\u4e60\u6846\u67b6\u9488\u5bf9\u5bc6\u96c6\u8fde\u63a5\u4f18\u5316\uff0c\u65e0\u6cd5\u964d\u4f4e\u5927\u578b\u6a21\u578b\u7684\u8bad\u7ec3\u6210\u672c\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8eGeNN\u6a21\u62df\u5668\u7684\u65b0\u578bGPU\u52a0\u901f\u7ed3\u6784\u53ef\u5851\u6027\u6846\u67b6\uff0c\u9996\u5148\u4f7f\u7528e-prop\u76d1\u7763\u5b66\u4e60\u89c4\u5219\u548cDEEP R\u8bad\u7ec3\u9ad8\u6548\u7684\u7a00\u758fSNN\u5206\u7c7b\u5668\uff0c\u7136\u540e\u5728\u65e0\u76d1\u7763\u5b66\u4e60\u73af\u5883\u4e2d\u5b66\u4e60\u62d3\u6251\u6620\u5c04\u3002\u8be5\u6846\u67b6\u652f\u6301\u52a8\u6001\u521b\u5efa\u548c\u79fb\u9664\u8fde\u63a5\u7684\u7ed3\u6784\u53ef\u5851\u6027\u673a\u5236\u3002", "result": "\u7a00\u758f\u5206\u7c7b\u5668\u76f8\u6bd4\u57fa\u7ebf\u5bc6\u96c6\u6a21\u578b\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c11\u9ad8\u8fbe10\u500d\uff0cDEEP R\u91cd\u8fde\u63a5\u673a\u5236\u4f7f\u5176\u6027\u80fd\u4e0e\u539f\u59cb\u6a21\u578b\u76f8\u5f53\u3002\u5b9e\u73b0\u4e86\u5feb\u4e8e\u5b9e\u65f6\u6a21\u62df\u7684\u62d3\u6251\u6620\u5c04\u5f62\u6210\uff0c\u63d0\u4f9b\u4e86\u8fde\u63a5\u6027\u6f14\u5316\u6d1e\u5bdf\uff0c\u5e76\u6d4b\u91cf\u4e86\u6a21\u62df\u901f\u5ea6\u4e0e\u7f51\u7edc\u89c4\u6a21\u7684\u5173\u7cfb\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5728\u7f51\u7edc\u7ed3\u6784\u548c\u795e\u7ecf\u901a\u4fe1\u4e2d\u5b9e\u73b0\u548c\u7ef4\u6301\u7a00\u758f\u6027\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u540c\u65f6\u4e3a\u63a2\u7d22\u7a00\u758f\u6027\u5728\u5404\u79cd\u795e\u7ecf\u5f62\u6001\u5e94\u7528\u4e2d\u7684\u8ba1\u7b97\u4f18\u52bf\u63d0\u4f9b\u4e86\u5e73\u53f0\uff0c\u63a8\u52a8\u4e86\u7ed3\u6784\u53ef\u5851\u6027\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u53d1\u5c55\u3002"}}
