<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <title>2026-02-06.md</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@5/github-markdown.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <style>
    body {
      background-color: #fafafa;
      font-family: 'Inter', sans-serif;
      padding: 2rem;
    }
    .markdown-body {
      max-width: 900px;
      margin: auto;
      background: white;
      padding: 2rem;
      border-radius: 12px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    h1, h2, h3 {
      border-bottom: 1px solid #eaecef;
      padding-bottom: 0.3em;
    }
  </style>
</head>
<body>
  <article class="markdown-body">
    <div id=toc></div>

<h1 id="table-of-contents">Table of Contents</h1>
<ul>
<li><a href="#cs.CV">cs.CV</a> [Total: 1]</li>
<li><a href="#cs.AI">cs.AI</a> [Total: 1]</li>
</ul>
<div id='cs.CV'></div>

<h1 id="cscv-back">cs.CV <a href="#toc">[Back]</a></h1>
<h3 id="1-neuro-inspired-visual-pattern-recognition-via-biological-reservoir-computing">[1] <a href="https://arxiv.org/abs/2602.05737">Neuro-Inspired Visual Pattern Recognition via Biological Reservoir Computing</a></h3>
<p><em>Luca Ciampi, Ludovico Iannello, Fabrizio Tonelli, Gabriele Lagani, Angelo Di Garbo, Federico Cremisi, Giuseppe Amato</em></p>
<h4 id="tldr">ğŸ§© TL;DR</h4>
<p>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç¥ç»å¯å‘çš„å‚¨å±‚è®¡ç®—æ–¹æ³•ï¼Œåˆ©ç”¨ä½“å¤–åŸ¹å…»çš„çš®å±‚ç¥ç»å…ƒç½‘ç»œä½œä¸ºç‰©ç†å‚¨å±‚ï¼Œé€šè¿‡é«˜å¯†åº¦å¤šç”µæé˜µåˆ—è¿›è¡Œåˆºæ¿€å’Œè¯»å–ï¼Œå®ç°äº†åŸºäºç”Ÿç‰©ç¥ç»ç½‘ç»œçš„é™æ€è§†è§‰æ¨¡å¼è¯†åˆ«ä»»åŠ¡ã€‚</p>
<hr />
<h4 id="detailed-summary">ğŸ“˜ Detailed Summary</h4>
<p><strong>Motivation:</strong> ä¼ ç»Ÿå‚¨å±‚è®¡ç®—ä¾èµ–äººå·¥é€’å½’æ¨¡å‹è¿‘ä¼¼ç¥ç»åŠ¨åŠ›å­¦ï¼Œæœ¬ç ”ç©¶æ—¨åœ¨æ¢ç´¢åˆ©ç”¨æ´»ä½“ç¥ç»å›è·¯ä½œä¸ºè®¡ç®—åŸºè´¨çš„ç”Ÿç‰©å‚¨å±‚è®¡ç®—æ–¹æ³•ï¼Œä»¥æ›´ç›´æ¥åœ°æ•´åˆç”Ÿç‰©åŸç†åˆ°æœºå™¨å­¦ä¹ ä¸­ï¼Œå¹¶ä¸ºç¥ç»å½¢æ€è®¡ç®—æ¡†æ¶æä¾›æ–°çš„ç”Ÿç‰©é›†æˆé€”å¾„ã€‚</p>
<p><strong>Method:</strong> é‡‡ç”¨ä½“å¤–åŸ¹å…»çš„çš®å±‚ç¥ç»å…ƒç½‘ç»œä½œä¸ºç‰©ç†å‚¨å±‚ï¼Œåˆ©ç”¨é«˜å¯†åº¦å¤šç”µæé˜µåˆ—åŒæ—¶è¿›è¡Œåˆºæ¿€å’Œè¯»å–ï¼Œè¾“å…¥æ¨¡å¼é€šè¿‡é€‰å®šç”µæä¼ é€’ï¼Œå…¶ä½™ç”µææ•è·é«˜ç»´ç¥ç»å“åº”ï¼Œæœ€åä½¿ç”¨çº¿æ€§è¯»å‡ºå±‚å¯¹å‚¨å±‚çŠ¶æ€è¿›è¡Œåˆ†ç±»ï¼Œæ„æˆå®Œæ•´çš„ç”Ÿç‰©å‚¨å±‚è®¡ç®—ç³»ç»Ÿã€‚</p>
<p><strong>Result:</strong> ç³»ç»Ÿåœ¨ä»ç‚¹åˆ°å®šå‘æ¡å½¢ã€æ—¶é’Ÿæ•°å­—å½¢çŠ¶åˆ°MNISTæ‰‹å†™æ•°å­—çš„é€’å¢éš¾åº¦ä»»åŠ¡åºåˆ—ä¸­è¡¨ç°è‰¯å¥½ï¼Œå°½ç®¡ç”Ÿç‰©ç¥ç»å“åº”å­˜åœ¨å™ªå£°ã€è‡ªå‘æ´»åŠ¨å’Œä¼šè¯é—´å·®å¼‚ç­‰å›ºæœ‰å˜å¼‚æ€§ï¼Œä½†ä»èƒ½ç”Ÿæˆæ”¯æŒå‡†ç¡®åˆ†ç±»çš„é«˜ç»´è¡¨ç¤ºï¼Œè¯æ˜äº†ä½“å¤–çš®å±‚ç½‘ç»œä½œä¸ºé™æ€è§†è§‰æ¨¡å¼è¯†åˆ«å‚¨å±‚çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Conclusion:</strong> è¯¥ç ”ç©¶å±•ç¤ºäº†ä½“å¤–çš®å±‚ç½‘ç»œå¯ä½œä¸ºæœ‰æ•ˆçš„å‚¨å±‚ç”¨äºé™æ€è§†è§‰æ¨¡å¼è¯†åˆ«ï¼Œä¸ºå°†æ´»ä½“ç¥ç»åŸºè´¨æ•´åˆåˆ°ç¥ç»å½¢æ€è®¡ç®—æ¡†æ¶å¼€è¾Ÿäº†æ–°é€”å¾„ï¼Œæ›´å¹¿æ³›åœ°æ”¯æŒäº†å°†ç”Ÿç‰©åŸç†èå…¥æœºå™¨å­¦ä¹ çš„åŠªåŠ›ï¼Œå¹¶è¯´æ˜äº†æ´»ä½“ç¥ç»ç³»ç»Ÿå¦‚ä½•ä¸ºè®¾è®¡é«˜æ•ˆä¸”ç”Ÿç‰©å­¦åŸºç¡€çš„è®¡ç®—æ¨¡å‹æä¾›ä¿¡æ¯ã€‚</p>
<hr />
<h4 id="abstract">ğŸ“„ Abstract</h4>
<p>In this paper, we present a neuro-inspired approach to reservoir computing (RC) in which a network of in vitro cultured cortical neurons serves as the physical reservoir. Rather than relying on artificial recurrent models to approximate neural dynamics, our biological reservoir computing (BRC) system leverages the spontaneous and stimulus-evoked activity of living neural circuits as its computational substrate. A high-density multi-electrode array (HD-MEA) provides simultaneous stimulation and readout across hundreds of channels: input patterns are delivered through selected electrodes, while the remaining ones capture the resulting high-dimensional neural responses, yielding a biologically grounded feature representation. A linear readout layer (single-layer perceptron) is then trained to classify these reservoir states, enabling the living neural network to perform static visual pattern-recognition tasks within a computer-vision framework. We evaluate the system across a sequence of tasks of increasing difficulty, ranging from pointwise stimuli to oriented bars, clock-digit-like shapes, and handwritten digits from the MNIST dataset. Despite the inherent variability of biological neural responses-arising from noise, spontaneous activity, and inter-session differences-the system consistently generates high-dimensional representations that support accurate classification. These results demonstrate that in vitro cortical networks can function as effective reservoirs for static visual pattern recognition, opening new avenues for integrating living neural substrates into neuromorphic computing frameworks. More broadly, this work contributes to the effort to incorporate biological principles into machine learning and supports the goals of neuro-inspired vision by illustrating how living neural systems can inform the design of efficient and biologically grounded computational models.</p>
<div id='cs.AI'></div>

<h1 id="csai-back">cs.AI <a href="#toc">[Back]</a></h1>
<h3 id="2-learning-event-based-shooter-models-from-virtual-reality-experiments">[2] <a href="https://arxiv.org/abs/2602.06023">Learning Event-Based Shooter Models from Virtual Reality Experiments</a></h3>
<p><em>Christopher A. McClurg, Alan R. Wagner</em></p>
<h4 id="tldr_1">ğŸ§© TL;DR</h4>
<p>æœ¬ç ”ç©¶å¼€å‘äº†ä¸€ç§æ•°æ®é©±åŠ¨çš„ç¦»æ•£äº‹ä»¶æ¨¡æ‹Ÿå™¨ï¼Œç”¨äºè¯„ä¼°å­¦æ ¡å®‰å…¨å¹²é¢„ç­–ç•¥ï¼Œé€šè¿‡ä»VRç ”ç©¶ä¸­å­¦ä¹ å‚ä¸è€…è¡Œä¸ºæ¥æ¨¡æ‹Ÿæªæ‰‹ç§»åŠ¨å’Œè¡ŒåŠ¨ï¼Œä¸ºè‡ªä¸»å®‰å…¨å¹²é¢„çš„å¼€å‘æä¾›äº†å¯æ‰©å±•çš„æ›¿ä»£æ–¹æ¡ˆã€‚</p>
<hr />
<h4 id="detailed-summary_1">ğŸ“˜ Detailed Summary</h4>
<p><strong>Motivation:</strong> è™šæ‹Ÿç°å®è™½ç„¶ä¸ºè¯„ä¼°é«˜é£é™©åœºæ™¯ä¸‹çš„å­¦æ ¡å®‰å…¨æªæ–½æä¾›äº†å®éªŒæ§åˆ¶å’Œè¡Œä¸ºä¿çœŸåº¦ï¼Œä½†è¯„ä¼°æ–°å¹²é¢„æªæ–½éœ€è¦ä¸ºæ¯ä¸ªæ¡ä»¶æ‹›å‹Ÿæ–°çš„å‚ä¸è€…é˜Ÿåˆ—ï¼Œä½¿å¾—å¤§è§„æ¨¡æˆ–è¿­ä»£è¯„ä¼°å˜å¾—å›°éš¾ï¼Œè¿™åœ¨éœ€è¦å¤§é‡è®­ç»ƒè½®æ¬¡çš„å¹²é¢„ç­–ç•¥å­¦ä¹ ä¸­å°¤ä¸ºå—é™ã€‚</p>
<p><strong>Method:</strong> æœ¬ç ”ç©¶å¼€å‘äº†ä¸€ç§æ•°æ®é©±åŠ¨çš„ç¦»æ•£äº‹ä»¶æ¨¡æ‹Ÿå™¨ï¼Œå°†æªæ‰‹ç§»åŠ¨å’ŒåŒºåŸŸå†…è¡ŒåŠ¨å»ºæ¨¡ä¸ºä»VRç ”ç©¶ä¸­å‚ä¸è€…è¡Œä¸ºå­¦ä¹ çš„éšæœºè¿‡ç¨‹ï¼Œè¯¥æ¨¡æ‹Ÿå™¨èƒ½å¤Ÿå†ç°å…³é”®ç»éªŒæ¨¡å¼ï¼Œå¹¶ç”¨äºæ£€æŸ¥åŸºäºæœºå™¨äººçš„æªæ‰‹å¹²é¢„ç­–ç•¥çš„å½±å“ã€‚</p>
<p><strong>Result:</strong> ä¸€æ—¦è¯æ˜è¯¥æ¨¡æ‹Ÿå™¨èƒ½å¤Ÿå†ç°å…³é”®ç»éªŒæ¨¡å¼ï¼Œå®ƒå°±èƒ½å¤Ÿå®ç°å¹²é¢„ç­–ç•¥çš„å¯æ‰©å±•è¯„ä¼°å’Œå­¦ä¹ ï¼Œè¿™äº›ç­–ç•¥ç›´æ¥ä½¿ç”¨äººç±»å—è¯•è€…è¿›è¡Œè®­ç»ƒæ˜¯ä¸å¯è¡Œçš„ï¼Œä¸ºè‡ªä¸»å­¦æ ¡å®‰å…¨å¹²é¢„çš„å¼€å‘æä¾›äº†å¯æ‰©å±•çš„æ›¿ä»£æ–¹æ¡ˆã€‚</p>
<p><strong>Conclusion:</strong> è¿™é¡¹å·¥ä½œå±•ç¤ºäº†ä¸€ä¸ªä»é«˜ä¿çœŸåˆ°ä¸­ä¿çœŸçš„æ¨¡æ‹Ÿå·¥ä½œæµç¨‹ï¼Œä¸ºå¼€å‘å’Œè¯„ä¼°è‡ªä¸»å­¦æ ¡å®‰å…¨å¹²é¢„æä¾›äº†å¯æ‰©å±•çš„æ›¿ä»£æ–¹æ¡ˆï¼Œè§£å†³äº†VRç ”ç©¶ä¸­å‚ä¸è€…æ‹›å‹Ÿé™åˆ¶å’Œå¤§è§„æ¨¡è¯„ä¼°çš„æŒ‘æˆ˜ã€‚</p>
<hr />
<h4 id="abstract_1">ğŸ“„ Abstract</h4>
<p>Virtual reality (VR) has emerged as a powerful tool for evaluating school security measures in high-risk scenarios such as school shootings, offering experimental control and high behavioral fidelity. However, assessing new interventions in VR requires recruiting new participant cohorts for each condition, making large-scale or iterative evaluation difficult. These limitations are especially restrictive when attempting to learn effective intervention strategies, which typically require many training episodes. To address this challenge, we develop a data-driven discrete-event simulator (DES) that models shooter movement and in-region actions as stochastic processes learned from participant behavior in VR studies. We use the simulator to examine the impact of a robot-based shooter intervention strategy. Once shown to reproduce key empirical patterns, the DES enables scalable evaluation and learning of intervention strategies that are infeasible to train directly with human subjects. Overall, this work demonstrates a high-to-mid fidelity simulation workflow that provides a scalable surrogate for developing and evaluating autonomous school-security interventions.</p>
  </article>
</body>
</html>
