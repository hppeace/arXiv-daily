<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <title>2025-12-04.md</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@5/github-markdown.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <style>
    body {
      background-color: #fafafa;
      font-family: 'Inter', sans-serif;
      padding: 2rem;
    }
    .markdown-body {
      max-width: 900px;
      margin: auto;
      background: white;
      padding: 2rem;
      border-radius: 12px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    h1, h2, h3 {
      border-bottom: 1px solid #eaecef;
      padding-bottom: 0.3em;
    }
  </style>
</head>
<body>
  <article class="markdown-body">
    <div id=toc></div>

<h1 id="table-of-contents">Table of Contents</h1>
<ul>
<li><a href="#cs.NE">cs.NE</a> [Total: 2]</li>
</ul>
<div id='cs.NE'></div>

<h1 id="csne-back">cs.NE <a href="#toc">[Back]</a></h1>
<h3 id="1-hybrid-temporal-8-bit-spike-coding-for-spiking-neural-network-surrogate-training">[1] <a href="https://arxiv.org/abs/2512.03879">Hybrid Temporal-8-Bit Spike Coding for Spiking Neural Network Surrogate Training</a></h3>
<p><em>Luu Trong Nhan, Luu Trung Duong, Pham Ngoc Nam, Truong Cong Thang</em></p>
<h4 id="tldr">ğŸ§© TL;DR</h4>
<p>è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ··åˆæ—¶ç©ºæ¯”ç‰¹è„‰å†²ç¼–ç æ–¹æ³•ï¼Œå°†æ¯”ç‰¹å¹³é¢åˆ†è§£ä¸æ—¶é—´ç¼–ç åŸç†ç›¸ç»“åˆï¼Œé¦–æ¬¡ä¸ºSNNçš„ä»£ç†æ¢¯åº¦è®­ç»ƒè®¾è®¡äº†ä¸“é—¨çš„æ··åˆæ—¶ç©ºæ¯”ç‰¹ç¼–ç æ–¹æ¡ˆï¼Œåœ¨å¤šä¸ªè§†è§‰åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚</p>
<hr />
<h4 id="detailed-summary">ğŸ“˜ Detailed Summary</h4>
<p><strong>Motivation:</strong> è„‰å†²ç¥ç»ç½‘ç»œåœ¨è§†è§‰ä»»åŠ¡ä¸­éš¾ä»¥è¾¾åˆ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œå°½ç®¡æ··åˆé€Ÿç‡-æ—¶é—´ç¼–ç ç­–ç•¥ï¼ˆç‰¹åˆ«æ˜¯ç»“åˆæ¯”ç‰¹å¹³é¢è¡¨ç¤ºçš„æ–¹æ³•ï¼‰å·²æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨ä»£ç†æ¢¯åº¦è®­ç»ƒæ–¹é¢ä»æœ‰æ”¹è¿›ç©ºé—´ï¼Œæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³è¿™ä¸€æ€§èƒ½å·®è·ã€‚</p>
<p><strong>Method:</strong> æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ··åˆæ—¶ç©ºæ¯”ç‰¹è„‰å†²ç¼–ç æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†æ¯”ç‰¹å¹³é¢åˆ†è§£ä¸æ—¶é—´ç¼–ç åŸç†ç›¸ç»“åˆï¼Œä¸“é—¨ä¸ºä»£ç†æ¢¯åº¦è®­ç»ƒçš„SNNè®¾è®¡ï¼Œé€šè¿‡æ•´åˆæ¯”ç‰¹å¹³é¢ä¿¡æ¯å’Œæ—¶é—´ç¼–ç æœºåˆ¶æ¥å¢å¼ºä¿¡æ¯è¡¨ç¤ºèƒ½åŠ›ã€‚</p>
<p><strong>Result:</strong> åœ¨å¤šä¸ªè®¡ç®—æœºè§†è§‰åŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç›¸æ¯”å·²å»ºç«‹çš„è„‰å†²ç¼–ç æŠ€æœ¯å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ç”šè‡³å®ç°äº†æ€§èƒ½æ”¹è¿›ï¼ŒéªŒè¯äº†æ··åˆæ—¶ç©ºæ¯”ç‰¹ç¼–ç çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Conclusion:</strong> è¿™æ˜¯é¦–ä¸ªä¸“é—¨ä¸ºSNNä»£ç†æ¢¯åº¦è®­ç»ƒè®¾è®¡çš„æ··åˆæ—¶ç©ºæ¯”ç‰¹ç¼–ç æ–¹æ¡ˆï¼Œç ”ç©¶ç»“æœè¡¨æ˜ç»“åˆæ¯”ç‰¹å¹³é¢åˆ†è§£ä¸æ—¶é—´ç¼–ç åŸç†èƒ½å¤Ÿæœ‰æ•ˆæå‡SNNåœ¨è§†è§‰ä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼Œä¸ºæœªæ¥è„‰å†²ç¼–ç ç­–ç•¥çš„å‘å±•æä¾›äº†æ–°æ–¹å‘ã€‚</p>
<hr />
<h4 id="abstract">ğŸ“„ Abstract</h4>
<p>Spiking neural networks (SNNs) have emerged as a promising direction in both computational neuroscience and artificial intelligence, offering advantages such as strong biological plausibility and low energy consumption on neuromorphic hardware. Despite these benefits, SNNs still face challenges in achieving state-of-the-art performance on vision tasks. Recent work has shown that hybrid rate-temporal coding strategies (particularly those incorporating bit-plane representations of images into traditional rate coding schemes) can significantly improve performance when trained with surrogate backpropagation. Motivated by these findings, this study proposes a hybrid temporal-bit spike coding method that integrates bit-plane decompositions with temporal coding principles. Through extensive experiments across multiple computer vision benchmarks, we demonstrate that blending bit-plane information with temporal coding yields competitive, and in some cases improved, performance compared to established spike-coding techniques. To the best of our knowledge, this is the first work to introduce a hybrid temporal-bit coding scheme specifically designed for surrogate gradient training of SNNs.</p>
<h3 id="2-parameter-efficient-hybrid-spiking-quantum-convolutional-neural-network-with-surrogate-gradient-and-quantum-data-reupload">[2] <a href="https://arxiv.org/abs/2512.03895">Parameter efficient hybrid spiking-quantum convolutional neural network with surrogate gradient and quantum data-reupload</a></h3>
<p><em>Luu Trong Nhan, Luu Trung Duong, Pham Ngoc Nam, Truong Cong Thang</em></p>
<h4 id="tldr_1">ğŸ§© TL;DR</h4>
<p>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°é¢–çš„Spiking-Quantum Data Re-uploadå·ç§¯ç¥ç»ç½‘ç»œï¼ˆSQDR-CNNï¼‰æ¶æ„ï¼Œèƒ½å¤Ÿåœ¨å•ä¸€åå‘ä¼ æ’­æ¡†æ¶ä¸­è”åˆè®­ç»ƒå·ç§¯è„‰å†²ç¥ç»ç½‘ç»œå’Œé‡å­ç”µè·¯ï¼Œæ— éœ€ä¾èµ–é¢„è®­ç»ƒçš„è„‰å†²ç¼–ç å™¨ï¼Œæ˜¾è‘—å‡å°‘äº†æ¨¡å‹å‚æ•°éœ€æ±‚ã€‚</p>
<hr />
<h4 id="detailed-summary_1">ğŸ“˜ Detailed Summary</h4>
<p><strong>Motivation:</strong> ç°æœ‰Spiking Quantum Neural Networkï¼ˆSQNNï¼‰å®ç°é€šå¸¸ä¾èµ–äºé¢„è®­ç»ƒçš„è„‰å†²ç¥ç»ç½‘ç»œï¼Œè¿™æ˜¯ç”±äºè„‰å†²æ´»åŠ¨çš„ä¸å¯å¾®åˆ†æ€§å’Œå½“å‰SNNç¼–ç å™¨çš„æœ‰é™å¯æ‰©å±•æ€§æ‰€å¯¼è‡´çš„é™åˆ¶ï¼Œè¿™é˜»ç¢äº†è„‰å†²ç¥ç»ç½‘ç»œä¸é‡å­ç”µè·¯çš„è”åˆä¼˜åŒ–è®­ç»ƒã€‚</p>
<p><strong>Method:</strong> æœ¬ç ”ç©¶æå‡ºäº†Spiking-Quantum Data Re-uploadå·ç§¯ç¥ç»ç½‘ç»œï¼ˆSQDR-CNNï¼‰æ¶æ„ï¼Œè¯¥æ¶æ„å°†å·ç§¯è„‰å†²ç¥ç»ç½‘ç»œä¸é‡å­ç”µè·¯é›†æˆåœ¨å•ä¸€å¯å¾®æ¡†æ¶ä¸­ï¼Œé‡‡ç”¨é‡å­æ•°æ®é‡ä¸Šä¼ æŠ€æœ¯ï¼Œå¹¶åœ¨å™ªå£°æ¨¡æ‹Ÿé‡å­ç¯å¢ƒä¸‹æµ‹è¯•äº†ä¸åŒè®­ç»ƒç®—æ³•å’Œåˆå§‹åŒ–ç­–ç•¥çš„è®¾è®¡ã€‚</p>
<p><strong>Result:</strong> SQDR-CNNåœ¨æ— éœ€é¢„è®­ç»ƒè„‰å†²ç¼–ç å™¨å’Œæ•°æ®é›†å­é›†çš„æƒ…å†µä¸‹å®ç°äº†åˆç†æ€§èƒ½æ”¶æ•›ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›SNNåŸºçº¿æ¨¡å‹å¹³å‡æœ€é«˜å‡†ç¡®ç‡çš„86%ï¼ŒåŒæ—¶ä»…ä½¿ç”¨æœ€å°è„‰å†²æ¨¡å‹å‚æ•°çš„0.5%ï¼Œæ˜¾è‘—å‡å°‘äº†å‚æ•°éœ€æ±‚ã€‚</p>
<p><strong>Conclusion:</strong> è¯¥ç ”ç©¶é€šè¿‡æ•´åˆç¥ç»å½¢æ€è®¡ç®—å’Œé‡å­è®¡ç®—èŒƒå¼ï¼Œä¸ºå¤šæ¨¡æ€å¯å­¦ä¹ ç³»ç»Ÿå¼€è¾Ÿäº†æ–°çš„ç ”ç©¶æ–¹å‘ï¼Œå±•ç¤ºäº†åœ¨å•ä¸€æ¡†æ¶ä¸­è”åˆä¼˜åŒ–è„‰å†²å’Œé‡å­ç»„ä»¶çš„å¯è¡Œæ€§ï¼Œä¸ºæœªæ¥æ··åˆè®¡ç®—æ¶æ„çš„å‘å±•æä¾›äº†ç†è®ºåŸºç¡€å’ŒæŠ€æœ¯è·¯å¾„ã€‚</p>
<hr />
<h4 id="abstract_1">ğŸ“„ Abstract</h4>
<p>The rapid advancement of artificial intelligence (AI) and deep learning (DL) has catalyzed the emergence of several optimization-driven subfields, notably neuromorphic computing and quantum machine learning. Leveraging the differentiable nature of hybrid models, researchers have explored their potential to address complex problems through unified optimization strategies. One such development is the Spiking Quantum Neural Network (SQNN), which combines principles from spiking neural networks (SNNs) and quantum computing. However, existing SQNN implementations often depend on pretrained SNNs due to the non-differentiable nature of spiking activity and the limited scalability of current SNN encoders. In this work, we propose a novel architecture, Spiking-Quantum Data Re-upload Convolutional Neural Network (SQDR-CNN), that enables joint training of convolutional SNNs and quantum circuits within a single backpropagation framework. Unlike its predecessor, SQDR-CNN allow convergence to reasonable performance without the reliance of pretrained spiking encoder and subsetting datasets. We also clarified some theoretical foundations, testing new design using quantum data-reupload with different training algorithm-initialization and evaluate the performance of the proposed model under noisy simulated quantum environments. As a result, we were able to achieve 86% of the mean top-performing accuracy of the SOTA SNN baselines, yet uses only 0.5% of the smallest spiking model's parameters. Through this integration of neuromorphic and quantum paradigms, we aim to open new research directions and foster technological progress in multi-modal, learnable systems.</p>
  </article>
</body>
</html>
