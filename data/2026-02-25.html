<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <title>2026-02-25.md</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@5/github-markdown.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <style>
    body {
      background-color: #fafafa;
      font-family: 'Inter', sans-serif;
      padding: 2rem;
    }
    .markdown-body {
      max-width: 900px;
      margin: auto;
      background: white;
      padding: 2rem;
      border-radius: 12px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    h1, h2, h3 {
      border-bottom: 1px solid #eaecef;
      padding-bottom: 0.3em;
    }
  </style>
</head>
<body>
  <article class="markdown-body">
    <div id=toc></div>

<h1 id="table-of-contents">Table of Contents</h1>
<ul>
<li><a href="#cs.CV">cs.CV</a> [Total: 2]</li>
</ul>
<div id='cs.CV'></div>

<h1 id="cscv-back">cs.CV <a href="#toc">[Back]</a></h1>
<h3 id="1-robust-spiking-neural-networks-against-adversarial-attacks">[1] <a href="https://arxiv.org/abs/2602.20548">Robust Spiking Neural Networks Against Adversarial Attacks</a></h3>
<p><em>Shuai Wang, Malu Zhang, Yulin Jiang, Dehao Zhang, Ammar Belatreche, Yu Liang, Yimeng Shan, Zijian Zhou, Yang Yang, Haizhou Li</em></p>
<h4 id="tldr">ğŸ§© TL;DR</h4>
<p>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§é˜ˆå€¼å®ˆå«ä¼˜åŒ–æ–¹æ³•ï¼Œé€šè¿‡å°†ç¥ç»å…ƒè†œç”µä½è¿œç¦»é˜ˆå€¼å¹¶å¼•å…¥å™ªå£°å°–å³°ç¥ç»å…ƒï¼Œæ˜¾è‘—æå‡äº†ç›´æ¥è®­ç»ƒè„‰å†²ç¥ç»ç½‘ç»œçš„å¯¹æŠ—é²æ£’æ€§ï¼Œä¸ºå¯é ç¥ç»å½¢æ€è®¡ç®—å¥ å®šäº†åŸºç¡€ã€‚</p>
<hr />
<h4 id="detailed-summary">ğŸ“˜ Detailed Summary</h4>
<p><strong>Motivation:</strong> è„‰å†²ç¥ç»ç½‘ç»œå› å…¶ç”Ÿç‰©å¯å¡‘æ€§å’Œè„‰å†²é©±åŠ¨ç‰¹æ€§åœ¨èŠ‚èƒ½ç¥ç»å½¢æ€è®¡ç®—ä¸­å…·æœ‰æ½œåŠ›ï¼Œä½†å…¶åœ¨å¤æ‚å¯¹æŠ—ç¯å¢ƒä¸­çš„é²æ£’æ€§å—åˆ°æ˜¾è‘—é™åˆ¶ã€‚ç ”ç©¶å‘ç°é˜ˆå€¼é‚»è¿‘çš„è„‰å†²ç¥ç»å…ƒæ˜¯é™åˆ¶ç›´æ¥è®­ç»ƒSNNé²æ£’æ€§çš„å…³é”®å› ç´ ï¼Œè¿™äº›ç¥ç»å…ƒè®¾å®šäº†å¯¹æŠ—æ”»å‡»æœ€å¤§æ½œåœ¨å¼ºåº¦çš„ä¸Šé™ï¼Œå¹¶å®¹æ˜“åœ¨å¾®å°æ‰°åŠ¨ä¸‹å‘ç”ŸçŠ¶æ€ç¿»è½¬ã€‚</p>
<p><strong>Method:</strong> æœ¬ç ”ç©¶æå‡ºäº†é˜ˆå€¼å®ˆå«ä¼˜åŒ–æ–¹æ³•ï¼ŒåŒ…å«ä¸¤ä¸ªå…³é”®æ–¹é¢ï¼šé¦–å…ˆåœ¨æŸå¤±å‡½æ•°ä¸­åŠ å…¥é¢å¤–çº¦æŸï¼Œä½¿ç¥ç»å…ƒè†œç”µä½è¿œç¦»é˜ˆå€¼ï¼Œä»è€Œå¢åŠ SNNçš„æ¢¯åº¦ç¨€ç–æ€§å¹¶é™ä½å¯¹æŠ—æ”»å‡»çš„ç†è®ºä¸Šé™ï¼›å…¶æ¬¡å¼•å…¥å™ªå£°å°–å³°ç¥ç»å…ƒï¼Œå°†ç¥ç»å…ƒæ”¾ç”µæœºåˆ¶ä»ç¡®å®šæ€§è½¬å˜ä¸ºæ¦‚ç‡æ€§ï¼Œé™ä½å› å¾®å°æ‰°åŠ¨å¯¼è‡´çš„çŠ¶æ€ç¿»è½¬æ¦‚ç‡ã€‚</p>
<p><strong>Result:</strong> åœ¨æ ‡å‡†å¯¹æŠ—åœºæ™¯ä¸‹è¿›è¡Œçš„å¹¿æ³›å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—å¢å¼ºäº†ç›´æ¥è®­ç»ƒSNNçš„é²æ£’æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œé€šè¿‡å°†ç¥ç»å…ƒè†œç”µä½è¿œç¦»é˜ˆå€¼å’Œå¼•å…¥æ¦‚ç‡æ€§æ”¾ç”µæœºåˆ¶ï¼Œæœ‰æ•ˆé™ä½äº†å¯¹æŠ—æ”»å‡»çš„ç†è®ºä¸Šé™å’ŒçŠ¶æ€ç¿»è½¬æ¦‚ç‡ï¼Œä»è€Œæå‡äº†ç½‘ç»œåœ¨å¯¹æŠ—ç¯å¢ƒä¸­çš„ç¨³å®šæ€§ã€‚</p>
<p><strong>Conclusion:</strong> è¯¥ç ”ç©¶æ­ç¤ºäº†é˜ˆå€¼é‚»è¿‘ç¥ç»å…ƒå¯¹SNNé²æ£’æ€§çš„é™åˆ¶æœºåˆ¶ï¼Œå¹¶æå‡ºäº†æœ‰æ•ˆçš„ä¼˜åŒ–æ–¹æ³•ã€‚è¿™äº›å‘ç°ä¸ºæ¨è¿›ç°å®åº”ç”¨ä¸­æ›´å¯é ã€æ›´å®‰å…¨çš„ç¥ç»å½¢æ€è®¡ç®—é“ºå¹³äº†é“è·¯ï¼Œä¸ºæ„å»ºæŠ—å¯¹æŠ—æ”»å‡»çš„SNNç³»ç»Ÿæä¾›äº†æ–°çš„ç†è®ºæ¡†æ¶å’ŒæŠ€æœ¯é€”å¾„ã€‚</p>
<hr />
<h4 id="abstract">ğŸ“„ Abstract</h4>
<p>Spiking Neural Networks (SNNs) represent a promising paradigm for energy-efficient neuromorphic computing due to their bio-plausible and spike-driven characteristics. However, the robustness of SNNs in complex adversarial environments remains significantly constrained. In this study, we theoretically demonstrate that those threshold-neighboring spiking neurons are the key factors limiting the robustness of directly trained SNNs. We find that these neurons set the upper limits for the maximum potential strength of adversarial attacks and are prone to state-flipping under minor disturbances. To address this challenge, we propose a Threshold Guarding Optimization (TGO) method, which comprises two key aspects. First, we incorporate additional constraints into the loss function to move neurons' membrane potentials away from their thresholds. It increases SNNs' gradient sparsity, thereby reducing the theoretical upper bound of adversarial attacks. Second, we introduce noisy spiking neurons to transition the neuronal firing mechanism from deterministic to probabilistic, decreasing their state-flipping probability due to minor disturbances. Extensive experiments conducted in standard adversarial scenarios prove that our method significantly enhances the robustness of directly trained SNNs. These findings pave the way for advancing more reliable and secure neuromorphic computing in real-world applications.</p>
<h3 id="2-real-time-motion-segmentation-with-event-based-normal-flow">[2] <a href="https://arxiv.org/abs/2602.20790">Real-time Motion Segmentation with Event-based Normal Flow</a></h3>
<p><em>Sheng Zhong, Zhongyang Ren, Xiya Zhu, Dehao Yuan, Cornelia Fermuller, Yi Zhou</em></p>
<h4 id="tldr_1">ğŸ§© TL;DR</h4>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ³•å‘æµçš„äº‹ä»¶ç›¸æœºè¿åŠ¨åˆ†å‰²æ¡†æ¶ï¼Œé€šè¿‡å°†æ³•å‘æµä½œä¸ºä¸­é—´è¡¨ç¤ºæ¥å‹ç¼©äº‹ä»¶ç°‡ä¸­çš„è¿åŠ¨ä¿¡æ¯ï¼Œå¹¶é‡‡ç”¨å›¾å‰²èƒ½é‡æœ€å°åŒ–æ–¹æ³•å®ç°é«˜æ•ˆåˆ†å‰²ï¼Œç›¸æ¯”ç°æœ‰æ–¹æ³•å®ç°äº†è¿‘800å€çš„åŠ é€Ÿã€‚</p>
<hr />
<h4 id="detailed-summary_1">ğŸ“˜ Detailed Summary</h4>
<p><strong>Motivation:</strong> äº‹ä»¶ç›¸æœºè™½ç„¶å…·æœ‰å¾®ç§’çº§åˆ†è¾¨ç‡çš„ä¼˜åŠ¿ï¼Œä½†å•ä¸ªäº‹ä»¶åŒ…å«çš„ä¿¡æ¯ç¨€ç–ï¼Œç›´æ¥å¤„ç†åŸå§‹äº‹ä»¶æ•°æ®è§£å†³è§†è§‰ä»»åŠ¡æ•ˆç‡ä½ä¸‹ï¼Œä¸¥é‡é™åˆ¶äº†ç°æœ‰æ–¹æ³•åœ¨å®æ—¶ä»»åŠ¡ï¼ˆå¦‚è¿åŠ¨åˆ†å‰²ï¼‰ä¸­çš„é€‚ç”¨æ€§ï¼Œè€Œæ³•å‘æµä½œä¸ºä¸­é—´è¡¨ç¤ºèƒ½å¤Ÿå‹ç¼©å±€éƒ¨åŒºåŸŸå†…äº‹ä»¶ç°‡çš„è¿åŠ¨ä¿¡æ¯ï¼Œæä¾›æ›´æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Method:</strong> è¯¥æ–¹æ³•æå‡ºåŸºäºæ³•å‘æµçš„äº‹ä»¶è§†è§‰è¿åŠ¨åˆ†å‰²æ¡†æ¶ï¼Œåˆ©ç”¨ä»äº‹ä»¶é‚»åŸŸç›´æ¥å­¦ä¹ å¾—åˆ°çš„å¯†é›†æ³•å‘æµä½œä¸ºè¾“å…¥ï¼Œå°†è¿åŠ¨åˆ†å‰²ä»»åŠ¡è¡¨è¿°ä¸ºé€šè¿‡å›¾å‰²è§£å†³çš„èƒ½é‡æœ€å°åŒ–é—®é¢˜ï¼Œå¹¶é€šè¿‡æ³•å‘æµèšç±»å’Œè¿åŠ¨æ¨¡å‹æ‹Ÿåˆè¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼Œé‡‡ç”¨åŸºäºæ³•å‘æµçš„è¿åŠ¨æ¨¡å‹åˆå§‹åŒ–å’Œæ‹Ÿåˆæ–¹æ³•ï¼Œä»…éœ€æœ‰é™æ•°é‡çš„å€™é€‰æ¨¡å‹å³å¯é«˜æ•ˆä¼°è®¡ç‹¬ç«‹è¿åŠ¨ç‰©ä½“çš„è¿åŠ¨æ¨¡å‹ã€‚</p>
<p><strong>Result:</strong> æ‰€æç³»ç»Ÿæ˜¾è‘—é™ä½äº†è®¡ç®—å¤æ‚åº¦å¹¶ç¡®ä¿äº†å®æ—¶æ€§èƒ½ï¼Œç›¸æ¯”å¼€æºçš„æœ€å…ˆè¿›æ–¹æ³•å®ç°äº†è¿‘800å€çš„åŠ é€Ÿï¼Œåœ¨å¤šä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°å……åˆ†è¯æ˜äº†è¯¥æ¡†æ¶çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚</p>
<p><strong>Conclusion:</strong> è¯¥ç ”ç©¶é€šè¿‡å¼•å…¥æ³•å‘æµä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œæœ‰æ•ˆè§£å†³äº†äº‹ä»¶ç›¸æœºè¿åŠ¨åˆ†å‰²ä¸­çš„è®¡ç®—æ•ˆç‡é—®é¢˜ï¼Œæå‡ºçš„æ¡†æ¶åœ¨ä¿æŒé«˜ç²¾åº¦çš„åŒæ—¶å®ç°äº†å®æ—¶æ€§èƒ½ï¼Œä¸ºåŠ¨æ€åœºæ™¯ç†è§£ä¸­çš„å®æ—¶è§†è§‰ä»»åŠ¡æä¾›äº†å®ç”¨è§£å†³æ–¹æ¡ˆï¼Œå±•ç¤ºäº†æ³•å‘æµåœ¨äº‹ä»¶è§†è§‰å¤„ç†ä¸­çš„æ½œåŠ›ã€‚</p>
<hr />
<h4 id="abstract_1">ğŸ“„ Abstract</h4>
<p>Event-based cameras are bio-inspired sensors with pixels that independently and asynchronously respond to brightness changes at microsecond resolution, offering the potential to handle visual tasks in challenging scenarios. However, due to the sparse information content in individual events, directly processing the raw event data to solve vision tasks is highly inefficient, which severely limits the applicability of state-of-the-art methods in real-time tasks, such as motion segmentation, a fundamental task for dynamic scene understanding. Incorporating normal flow as an intermediate representation to compress motion information from event clusters within a localized region provides a more effective solution. In this work, we propose a normal flow-based motion segmentation framework for event-based vision. Leveraging the dense normal flow directly learned from event neighborhoods as input, we formulate the motion segmentation task as an energy minimization problem solved via graph cuts, and optimize it iteratively with normal flow clustering and motion model fitting. By using a normal flow-based motion model initialization and fitting method, the proposed system is able to efficiently estimate the motion models of independently moving objects with only a limited number of candidate models, which significantly reduces the computational complexity and ensures real-time performance, achieving nearly a 800x speedup in comparison to the open-source state-of-the-art method. Extensive evaluations on multiple public datasets fully demonstrate the accuracy and efficiency of our framework.</p>
  </article>
</body>
</html>
