<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.NE](#cs.NE) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Benchmarking Microsaccade Recognition with Event Cameras: A Novel Dataset and Evaluation](https://arxiv.org/abs/2510.24231)
*Waseem Shariff, Timothy Hanley, Maciej Stec, Hossein Javidnia, Peter Corcoran*

#### ğŸ§© TL;DR
æœ¬ç ”ç©¶æå‡ºäº†é¦–ä¸ªåŸºäºäº‹ä»¶ç›¸æœºçš„å¾®çœ¼è·³æ•°æ®é›†ï¼Œå¹¶å¼€å‘äº†è„‰å†²ç¥ç»ç½‘ç»œæ¨¡å‹ç”¨äºå¾®çœ¼è·³è§’åº¦ä½ç§»åˆ†ç±»ï¼Œå®ç°äº†çº¦90%çš„å¹³å‡å‡†ç¡®ç‡ï¼Œä¸ºç²¾ç»†è¿åŠ¨è¯†åˆ«å’Œäº‹ä»¶è§†è§‰ç ”ç©¶å»ºç«‹äº†åŸºå‡†ã€‚

---

#### ğŸ“˜ Detailed Summary
**Motivation:** ä¼ ç»Ÿå¾®çœ¼è·³ç ”ç©¶ä¾èµ–çœ¼åŠ¨ä»ªæˆ–åŸºäºå¸§çš„åˆ†ææ–¹æ³•ï¼Œè™½ç„¶ç²¾ç¡®ä½†æˆæœ¬é«˜æ˜‚ä¸”æ—¶ç©ºåˆ†è¾¨ç‡æœ‰é™ï¼Œè€Œäº‹ä»¶æ„ŸçŸ¥æŠ€æœ¯æä¾›äº†é«˜é€Ÿã€ä½å»¶è¿Ÿçš„æ›¿ä»£æ–¹æ¡ˆï¼Œèƒ½å¤Ÿé«˜æ•ˆæ•æ‰ç²¾ç»†çš„æ—¶ç©ºå˜åŒ–ã€‚

**Method:** ä½¿ç”¨Blenderæ¸²æŸ“é«˜ä¿çœŸçœ¼åŠ¨åœºæ™¯ï¼Œæ¨¡æ‹Ÿ0.5è‡³2.0åº¦è§’ä½ç§»çš„å¾®çœ¼è·³å¹¶åˆ†ä¸ºä¸ƒç±»ï¼Œé€šè¿‡v2eè½¬æ¢ä¸ºäº‹ä»¶æµï¼›è¯„ä¼°äº†Spiking-VGG11/13/16æ¨¡å‹ï¼Œå¹¶æå‡ºäº†å…‰å­¦æµå¢å¼ºçš„Spiking-VGG16Flowå˜ä½“ï¼Œåœ¨SpikingJellyä¸­å®ç°ã€‚

**Result:** æ¨¡å‹å®ç°äº†çº¦90%çš„å¹³å‡åˆ†ç±»å‡†ç¡®ç‡ï¼ŒæˆåŠŸæ ¹æ®è§’åº¦ä½ç§»å¯¹å¾®çœ¼è·³è¿›è¡Œåˆ†ç±»ï¼Œä¸”åˆ†ç±»æ€§èƒ½ä¸äº‹ä»¶æ•°é‡æˆ–æŒç»­æ—¶é—´æ— å…³ï¼Œå¾®çœ¼è·³æŒç»­æ—¶é—´èŒƒå›´ä¸º0.25æ¯«ç§’è‡³2.25æ¯«ç§’ã€‚

**Conclusion:** ç ”ç©¶è¯æ˜äº†è„‰å†²ç¥ç»ç½‘ç»œåœ¨ç²¾ç»†è¿åŠ¨è¯†åˆ«ä¸­çš„æ½œåŠ›ï¼Œä¸ºåŸºäºäº‹ä»¶çš„è§†è§‰ç ”ç©¶å»ºç«‹äº†åŸºå‡†ï¼Œæ•°æ®é›†ã€ä»£ç å’Œè®­ç»ƒæ¨¡å‹å°†å…¬å¼€æä¾›ä»¥ä¿ƒè¿›ç›¸å…³ç ”ç©¶å‘å±•ã€‚

---

#### ğŸ“„ Abstract
Microsaccades are small, involuntary eye movements vital for visual
perception and neural processing. Traditional microsaccade studies typically
use eye trackers or frame-based analysis, which, while precise, are costly and
limited in scalability and temporal resolution. Event-based sensing offers a
high-speed, low-latency alternative by capturing fine-grained spatiotemporal
changes efficiently. This work introduces a pioneering event-based microsaccade
dataset to support research on small eye movement dynamics in cognitive
computing. Using Blender, we render high-fidelity eye movement scenarios and
simulate microsaccades with angular displacements from 0.5 to 2.0 degrees,
divided into seven distinct classes. These are converted to event streams using
v2e, preserving the natural temporal dynamics of microsaccades, with durations
ranging from 0.25 ms to 2.25 ms. We evaluate the dataset using Spiking-VGG11,
Spiking-VGG13, and Spiking-VGG16, and propose Spiking-VGG16Flow, an
optical-flow-enhanced variant implemented in SpikingJelly. The models achieve
around 90 percent average accuracy, successfully classifying microsaccades by
angular displacement, independent of event count or duration. These results
demonstrate the potential of spiking neural networks for fine motion
recognition and establish a benchmark for event-based vision research. The
dataset, code, and trained models will be publicly available at
https://waseemshariff126.github.io/microsaccades/ .


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [2] [Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks](https://arxiv.org/abs/2510.24461)
*Korneel Van den Berghe, Stein Stroobants, Vijay Janapa Reddi, G. C. H. E. de Croon*

#### ğŸ§© TL;DR
æœ¬ç ”ç©¶ç³»ç»Ÿåˆ†æäº†SNNä¸­æ›¿ä»£æ¢¯åº¦çš„æ–œç‡è®¾ç½®ï¼Œå¹¶æå‡ºäº†ä¸€ç§åˆ©ç”¨ç‰¹æƒå¼•å¯¼ç­–ç•¥çš„æ–°è®­ç»ƒæ–¹æ³•ï¼Œåœ¨çœŸå®ä¸–ç•Œæ— äººæœºä½ç½®æ§åˆ¶ä»»åŠ¡ä¸­å®ç°äº†æ˜¾è‘—æ€§èƒ½æå‡ï¼Œå°†å¹³å‡å›æŠ¥ä»-200ç‚¹æå‡è‡³400ç‚¹ã€‚

---

#### ğŸ“˜ Detailed Summary
**Motivation:** è¯¥ç ”ç©¶æ—¨åœ¨è§£å†³SNNåœ¨å¤æ‚æ§åˆ¶ä»»åŠ¡ä¸­é¢ä¸´çš„ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼šä¸€æ˜¯è„‰å†²ç¥ç»å…ƒçš„ä¸å¯å¾®ç‰¹æ€§éœ€è¦ä½¿ç”¨æ›¿ä»£æ¢¯åº¦ä½†å…¶ä¼˜åŒ–ç‰¹æ€§ä¸æ˜ç¡®ï¼ŒäºŒæ˜¯SNNçš„çŠ¶æ€åŠ¨æ€éœ€è¦åœ¨åºåˆ—ä¸Šè®­ç»ƒï¼Œè€Œåœ¨å¼ºåŒ–å­¦ä¹ ä¸­æ—©æœŸè®­ç»ƒåºåˆ—é•¿åº¦æœ‰é™ä¼šé˜»ç¢ç½‘ç»œåº¦è¿‡é¢„çƒ­æœŸã€‚

**Method:** ç ”ç©¶ç³»ç»Ÿåˆ†æäº†æ›¿ä»£æ¢¯åº¦æ–œç‡è®¾ç½®çš„å½±å“ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°é¢–çš„è®­ç»ƒæ–¹æ³•ï¼Œåˆ©ç”¨ç‰¹æƒå¼•å¯¼ç­–ç•¥æ¥å¼•å¯¼å­¦ä¹ è¿‡ç¨‹ï¼ŒåŒæ—¶ä»ç„¶åˆ©ç”¨è„‰å†²ç­–ç•¥çš„åœ¨çº¿ç¯å¢ƒäº¤äº’ï¼Œç»“åˆè‡ªé€‚åº”æ–œç‡è°ƒåº¦è¿›è¡Œä¼˜åŒ–ã€‚

**Result:** åœ¨å¼ºåŒ–å­¦ä¹ è®¾ç½®ä¸­ï¼Œè¾ƒæµ…çš„æ–œç‡æˆ–è°ƒåº¦æ–œç‡ä½¿è®­ç»ƒå’Œæœ€ç»ˆéƒ¨ç½²æ€§èƒ½æé«˜äº†2.1å€ï¼›åœ¨çœŸå®ä¸–ç•Œæ— äººæœºä½ç½®æ§åˆ¶ä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•å®ç°äº†400ç‚¹çš„å¹³å‡å›æŠ¥ï¼Œæ˜¾è‘—ä¼˜äºè¡Œä¸ºå…‹éš†å’ŒTD3BCç­‰æ–¹æ³•ï¼Œåè€…åœ¨ç›¸åŒæ¡ä»¶ä¸‹æœ€å¤šåªèƒ½è¾¾åˆ°-200ç‚¹ã€‚

**Conclusion:** è¿™é¡¹å·¥ä½œæ¨è¿›äº†å¯¹SNNä¸­æ›¿ä»£æ¢¯åº¦å­¦ä¹ çš„ç†è®ºç†è§£ï¼Œå¹¶å¼€å‘äº†å®ç”¨çš„ç¥ç»å½¢æ€æ§åˆ¶å™¨è®­ç»ƒæ–¹æ³•ï¼Œåœ¨çœŸå®ä¸–ç•Œæœºå™¨äººç³»ç»Ÿä¸­å¾—åˆ°éªŒè¯ï¼Œä¸ºé«˜æ•ˆç¥ç»å½¢æ€è®¡ç®—åœ¨æœºå™¨äººæ§åˆ¶ä¸­çš„åº”ç”¨æä¾›äº†é‡è¦åŸºç¡€ã€‚

---

#### ğŸ“„ Abstract
Neuromorphic computing systems are set to revolutionize energy-constrained
robotics by achieving orders-of-magnitude efficiency gains, while enabling
native temporal processing. Spiking Neural Networks (SNNs) represent a
promising algorithmic approach for these systems, yet their application to
complex control tasks faces two critical challenges: (1) the non-differentiable
nature of spiking neurons necessitates surrogate gradients with unclear
optimization properties, and (2) the stateful dynamics of SNNs require training
on sequences, which in reinforcement learning (RL) is hindered by limited
sequence lengths during early training, preventing the network from bridging
its warm-up period.
  We address these challenges by systematically analyzing surrogate gradient
slope settings, showing that shallower slopes increase gradient magnitude in
deeper layers but reduce alignment with true gradients. In supervised learning,
we find no clear preference for fixed or scheduled slopes. The effect is much
more pronounced in RL settings, where shallower slopes or scheduled slopes lead
to a 2.1x improvement in both training and final deployed performance. Next, we
propose a novel training approach that leverages a privileged guiding policy to
bootstrap the learning process, while still exploiting online environment
interactions with the spiking policy. Combining our method with an adaptive
slope schedule for a real-world drone position control task, we achieve an
average return of 400 points, substantially outperforming prior techniques,
including Behavioral Cloning and TD3BC, which achieve at most --200 points
under the same conditions. This work advances both the theoretical
understanding of surrogate gradient learning in SNNs and practical training
methodologies for neuromorphic controllers demonstrated in real-world robotic
systems.


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [3] [All in one timestep: Enhancing Sparsity and Energy efficiency in Multi-level Spiking Neural Networks](https://arxiv.org/abs/2510.24637)
*Andrea Castagnetti, Alain Pegatoquet, BenoÃ®t Miramond*

#### ğŸ§© TL;DR
æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šçº§è„‰å†²ç¥ç»å…ƒæ¨¡å‹å’Œç¨€ç–ResNetæ¶æ„ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒäººå·¥ç¥ç»ç½‘ç»œæ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½è„‰å†²ç¥ç»ç½‘ç»œçš„æ¨ç†å»¶è¿Ÿå’Œèƒ½è€—ï¼Œåœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç²¾åº¦å¹¶å‡å°‘äº†20%ä»¥ä¸Šçš„ç½‘ç»œæ´»åŠ¨ã€‚

---

#### ğŸ“˜ Detailed Summary
**Motivation:** è„‰å†²ç¥ç»ç½‘ç»œè™½ç„¶å…·æœ‰ç¨€ç–è®¡ç®—å’Œä½åŠŸè€—çš„ç†è®ºä¼˜åŠ¿ï¼Œä½†å…¶äºŒå…ƒè„‰å†²ç‰¹æ€§ä¼šå¯¼è‡´æ˜¾è‘—çš„ä¿¡æ¯æŸå¤±å’Œç²¾åº¦ä¸‹é™ï¼Œè¿™é™åˆ¶äº†SNNsåœ¨å®é™…åº”ç”¨ä¸­çš„æ€§èƒ½è¡¨ç°å’Œèƒ½æ•ˆä¼˜åŠ¿ã€‚

**Method:** æå‡ºäº†å¤šçº§è„‰å†²ç¥ç»å…ƒæ¨¡å‹ä»¥å‡å°‘é‡åŒ–è¯¯å·®å¹¶æœ€å°åŒ–æ¨ç†å»¶è¿Ÿï¼ŒåŒæ—¶è®¾è®¡äº†ç¨€ç–ResNetæ¶æ„æ¥è§£å†³æ®‹å·®è¿æ¥ä¸­çš„è„‰å†²é›ªå´©æ•ˆåº”é—®é¢˜ï¼Œé€šè¿‡åˆ†æè„‰å†²åœ¨æ®‹å·®è¿æ¥ä¸­çš„ä¼ æ’­ç‰¹æ€§ä¼˜åŒ–äº†ç½‘ç»œç»“æ„ã€‚

**Result:** åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œå¤šçº§SNNsç›¸æ¯”äºŒå…ƒSNNså¯å°†èƒ½è€—é™ä½2-3å€ï¼Œåœ¨ç¥ç»å½¢æ€æ•°æ®ä¸Šèƒ½å°†æ¨ç†å»¶è¿Ÿå‹ç¼©è‡³1ä¸ªæ—¶é—´æ­¥é•¿ï¼Œç›¸æ¯”å…ˆå‰ç»“æœå®ç°äº†10å€çš„å‹ç¼©å› å­ï¼ŒåŒæ—¶ç¨€ç–ResNetæ¶æ„åœ¨ä¿æŒæœ€å…ˆè¿›ç²¾åº¦çš„åŸºç¡€ä¸Šå‡å°‘äº†20%ä»¥ä¸Šçš„ç½‘ç»œæ´»åŠ¨ã€‚

**Conclusion:** å¤šçº§è„‰å†²ç¥ç»å…ƒæ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå¹³è¡¡é‡åŒ–è¯¯å·®å’Œæ¨ç†å»¶è¿Ÿï¼Œç»“åˆä¼˜åŒ–çš„ç¨€ç–ResNetæ¶æ„å¯ä»¥æ˜¾è‘—æå‡è„‰å†²ç¥ç»ç½‘ç»œçš„æ€§èƒ½å’Œèƒ½æ•ˆï¼Œä¸ºSNNsåœ¨ä½åŠŸè€—è¾¹ç¼˜è®¡ç®—è®¾å¤‡ä¸Šçš„å®é™…éƒ¨ç½²æä¾›äº†å¯è¡Œçš„æŠ€æœ¯è·¯å¾„ã€‚

---

#### ğŸ“„ Abstract
Spiking Neural Networks (SNNs) are one of the most promising bio-inspired
neural networks models and have drawn increasing attention in recent years. The
event-driven communication mechanism of SNNs allows for sparse and
theoretically low-power operations on dedicated neuromorphic hardware. However,
the binary nature of instantaneous spikes also leads to considerable
information loss in SNNs, resulting in accuracy degradation. To address this
issue, we propose a multi-level spiking neuron model able to provide both
low-quantization error and minimal inference latency while approaching the
performance of full precision Artificial Neural Networks (ANNs). Experimental
results with popular network architectures and datasets, show that multi-level
spiking neurons provide better information compression, allowing therefore a
reduction in latency without performance loss. When compared to binary SNNs on
image classification scenarios, multi-level SNNs indeed allow reducing by 2 to
3 times the energy consumption depending on the number of quantization
intervals. On neuromorphic data, our approach allows us to drastically reduce
the inference latency to 1 timestep, which corresponds to a compression factor
of 10 compared to previously published results. At the architectural level, we
propose a new residual architecture that we call Sparse-ResNet. Through a
careful analysis of the spikes propagation in residual connections we highlight
a spike avalanche effect, that affects most spiking residual architectures.
Using our Sparse-ResNet architecture, we can provide state-of-the-art accuracy
results in image classification while reducing by more than 20% the network
activity compared to the previous spiking ResNets.
