{"id": "2511.20175", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.20175", "abs": "https://arxiv.org/abs/2511.20175", "authors": ["Federico Paredes-Valles", "Yoshitaka Miyatani", "Kirk Y. W. Scheper"], "title": "Realizing Fully-Integrated, Low-Power, Event-Based Pupil Tracking with Neuromorphic Hardware", "comment": "17 pages, 14 figures, 3 tables", "summary": "Eye tracking is fundamental to numerous applications, yet achieving robust, high-frequency tracking with ultra-low power consumption remains challenging for wearable platforms. While event-based vision sensors offer microsecond resolution and sparse data streams, they have lacked fully integrated, low-power processing solutions capable of real-time inference. In this work, we present the first battery-powered, wearable pupil-center-tracking system with complete on-device integration, combining event-based sensing and neuromorphic processing on the commercially available Speck2f system-on-chip with lightweight coordinate decoding on a low-power microcontroller. Our solution features a novel uncertainty-quantifying spiking neural network with gated temporal decoding, optimized for strict memory and bandwidth constraints, complemented by systematic deployment mechanisms that bridge the reality gap. We validate our system on a new multi-user dataset and demonstrate a wearable prototype with dual neuromorphic devices achieving robust binocular pupil tracking at 100 Hz with an average power consumption below 5 mW per eye. Our work demonstrates that end-to-end neuromorphic computing enables practical, always-on eye tracking for next-generation energy-efficient wearable systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u9996\u4e2a\u7535\u6c60\u4f9b\u7535\u7684\u53ef\u7a7f\u6234\u77b3\u5b54\u4e2d\u5fc3\u8ffd\u8e2a\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e8b\u4ef6\u89c6\u89c9\u4f20\u611f\u4e0e\u795e\u7ecf\u5f62\u6001\u5904\u7406\u7684\u7aef\u5230\u7aef\u96c6\u6210\uff0c\u5728Speck2f\u7247\u4e0a\u7cfb\u7edf\u4e0a\u5b9e\u73b0\u4e86100Hz\u53cc\u76ee\u5149\u5b66\u8ffd\u8e2a\uff0c\u6bcf\u773c\u5e73\u5747\u529f\u8017\u4f4e\u4e8e5mW\u3002", "motivation": "\u5f53\u524d\u53ef\u7a7f\u6234\u5e73\u53f0\u5728\u5b9e\u73b0\u7a33\u5065\u3001\u9ad8\u9891\u7387\u773c\u52a8\u8ffd\u8e2a\u7684\u540c\u65f6\u4fdd\u6301\u8d85\u4f4e\u529f\u8017\u9762\u4e34\u6311\u6218\uff0c\u4e8b\u4ef6\u89c6\u89c9\u4f20\u611f\u5668\u867d\u7136\u63d0\u4f9b\u5fae\u79d2\u7ea7\u5206\u8fa8\u7387\u548c\u7a00\u758f\u6570\u636e\u6d41\uff0c\u4f46\u7f3a\u4e4f\u5b8c\u5168\u96c6\u6210\u7684\u4f4e\u529f\u8017\u5b9e\u65f6\u63a8\u7406\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5546\u7528Speck2f\u7247\u4e0a\u7cfb\u7edf\u96c6\u6210\u4e8b\u4ef6\u4f20\u611f\u4e0e\u795e\u7ecf\u5f62\u6001\u5904\u7406\uff0c\u7ed3\u5408\u4f4e\u529f\u8017\u5fae\u63a7\u5236\u5668\u8fdb\u884c\u8f7b\u91cf\u7ea7\u5750\u6807\u89e3\u7801\uff1b\u63d0\u51fa\u65b0\u578b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff0c\u914d\u5907\u95e8\u63a7\u65f6\u5e8f\u89e3\u7801\u673a\u5236\uff0c\u9488\u5bf9\u4e25\u683c\u5185\u5b58\u548c\u5e26\u5bbd\u7ea6\u675f\u4f18\u5316\uff0c\u5e76\u901a\u8fc7\u7cfb\u7edf\u5316\u90e8\u7f72\u673a\u5236\u5f25\u5408\u73b0\u5b9e\u5dee\u8ddd\u3002", "result": "\u5728\u591a\u7528\u6237\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u6027\u80fd\uff0c\u53ef\u7a7f\u6234\u539f\u578b\u914d\u5907\u53cc\u795e\u7ecf\u5f62\u6001\u8bbe\u5907\uff0c\u5b9e\u73b0100Hz\u7a33\u5065\u53cc\u76ee\u5149\u5b66\u8ffd\u8e2a\uff0c\u6bcf\u773c\u5e73\u5747\u529f\u8017\u4f4e\u4e8e5mW\u3002", "conclusion": "\u7aef\u5230\u7aef\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u4e3a\u4e0b\u4e00\u4ee3\u9ad8\u80fd\u6548\u53ef\u7a7f\u6234\u7cfb\u7edf\u5b9e\u73b0\u4e86\u5b9e\u7528\u7684\u5e38\u5f00\u773c\u52a8\u8ffd\u8e2a\uff0c\u8bc1\u660e\u4e86\u5b8c\u5168\u96c6\u6210\u7684\u4e8b\u4ef6\u9a71\u52a8\u7cfb\u7edf\u5728\u8d85\u4f4e\u529f\u8017\u4e0b\u7684\u53ef\u884c\u6027\u3002"}}
