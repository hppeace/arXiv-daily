<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 15]
- [cs.CL](#cs.CL) [Total: 8]
- [cs.AI](#cs.AI) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Cluster-Aware Prompt Ensemble Learning for Few-Shot Vision-Language Model Adaptation](https://arxiv.org/abs/2510.09867)
*Zhi Chen, Xin Yu, Xiaohui Tao, Yan Li, Zi Huang*

#### 🧩 TL;DR
本文提出了聚类感知提示集成学习框架CAPEL，通过将提示集成从特征空间转移到分类logits空间，并引入聚类保持正则化，解决了传统提示集成方法中特征平均导致类中心偏移的问题，显著提升了视觉语言模型的零样本分类性能。

---

#### 📘 Detailed Summary
**Motivation:** 传统视觉语言模型中的提示集成方法通过平均多个上下文提示的文本特征来实现零样本分类，但这种方法往往导致次优结果，因为特征平均会使类中心偏离真实的类分布，无法有效保留上下文提示的聚类特性。

**Method:** 提出了聚类感知提示集成学习框架CAPEL，该方法将图像分类到由不同提示表示的多个类簇中，在分类logits空间而非特征空间进行提示集成，更好地与视觉特征分布对齐；同时引入聚类保持正则化项来优化提示微调，保持不同簇间提示的区分性；还集成了自适应提示加权技术，动态调整有缺陷或模糊提示的注意力权重。

**Result:** CAPEL框架在多个数据集和任务上展现出稳健的性能，通过保留上下文提示的聚类特性，显著提升了零样本分类的准确性和鲁棒性，有效解决了传统特征平均方法导致的类中心偏移问题。

**Conclusion:** 该研究表明在分类logits空间进行提示集成比在特征空间更有效，聚类保持机制对于维持提示的区分性至关重要，为视觉语言模型的提示优化提供了新的方向，未来可扩展到更复杂的多模态任务中。

---

#### 📄 Abstract
Vision-language models (VLMs) such as CLIP achieve zero-shot transfer across
various tasks by pre-training on numerous image-text pairs. These models often
benefit from using an ensemble of context prompts to represent a class. Despite
being effective, conventional prompt ensembling that averages textual features
of context prompts often yields suboptimal results. This is because feature
averaging shifts the class centroids away from the true class distribution. To
address this issue, we propose the Cluster-Aware Prompt Ensemble Learning
(CAPEL) framework, which preserves the cluster nature of context prompts. CAPEL
classifies images into one of several class clusters, each represented by a
distinct prompt. Instead of ensembling prompts in the feature space, we perform
ensembling in the classification logits space, aligning better with the visual
feature distribution. To further optimize prompt fine-tuning while maintaining
cluster-specific discriminative power, we introduce a cluster-preserving
regularization term. This ensures that prompts remain distinct and specialized
for different clusters, preventing collapse into a uniform direction.
Additionally, we integrate an adaptive prompt weighting technique to
dynamically adjust the attention weights for flawed or ambiguous prompts,
ensuring robust performance across diverse datasets and tasks.


### [2] [Opacity-Gradient Driven Density Control for Compact and Efficient Few-Shot 3D Gaussian Splatting](https://arxiv.org/abs/2510.10257)
*Abdelrhman Elrawy, Emad A. Mohammed*

#### 🧩 TL;DR
本文提出了一种改进3D高斯泼溅在少样本场景下效率的框架，通过使用不透明度梯度作为轻量级渲染误差代理来替代标准位置梯度启发式，结合保守剪枝策略和深度相关损失，在保持重建质量的同时显著减少了基元数量。

---

#### 📘 Detailed Summary
**Motivation:** 3D高斯泼溅在少样本场景中面临过拟合和重建膨胀问题，现有方法如FSGS虽然提高了质量但显著增加了基元数量，本研究旨在通过优化核心3DGS算法来优先考虑效率问题。

**Method:** 采用基于不透明度梯度的新型致密化触发机制替代标准位置梯度启发式，结合更保守的剪枝策略来防止破坏性优化循环，并使用标准深度相关损失提供几何指导。

**Result:** 在3视图LLFF数据集上，模型比FSGS紧凑40%以上（32k vs 57k基元），在Mip-NeRF 360数据集上实现了约70%的基元减少，仅以适度的重建指标损失为代价。

**Conclusion:** 该框架在少样本视图合成的质量-效率帕累托边界上建立了新的最先进水平，证明了通过重新设计核心优化策略可以实现效率的根本性改进，同时保持竞争性的重建性能。

---

#### 📄 Abstract
3D Gaussian Splatting (3DGS) struggles in few-shot scenarios, where its
standard adaptive density control (ADC) can lead to overfitting and bloated
reconstructions. While state-of-the-art methods like FSGS improve quality, they
often do so by significantly increasing the primitive count. This paper
presents a framework that revises the core 3DGS optimization to prioritize
efficiency. We replace the standard positional gradient heuristic with a novel
densification trigger that uses the opacity gradient as a lightweight proxy for
rendering error. We find this aggressive densification is only effective when
paired with a more conservative pruning schedule, which prevents destructive
optimization cycles. Combined with a standard depth-correlation loss for
geometric guidance, our framework demonstrates a fundamental improvement in
efficiency. On the 3-view LLFF dataset, our model is over 40% more compact (32k
vs. 57k primitives) than FSGS, and on the Mip-NeRF 360 dataset, it achieves a
reduction of approximately 70%. This dramatic gain in compactness is achieved
with a modest trade-off in reconstruction metrics, establishing a new
state-of-the-art on the quality-vs-efficiency Pareto frontier for few-shot view
synthesis.


### [3] [AVoCaDO: An Audiovisual Video Captioner Driven by Temporal Orchestration](https://arxiv.org/abs/2510.10395)
*Xinlong Chen, Yue Ding, Weihong Lin, Jingyun Hua, Linli Yao, Yang Shi, Bozhou Li, Yuanxing Zhang, Qiang Liu, Pengfei Wan, Liang Wang, Tieniu Tan*

#### 🧩 TL;DR
本文提出了AVoCaDO，一种基于视听时序编排的强大多模态视频描述模型，通过两阶段后训练方法在多个基准测试中显著优于现有开源模型。

---

#### 📘 Detailed Summary
**Motivation:** 视听视频描述任务旨在生成语义丰富且具有视觉和听觉事件时序对齐的描述，这对视频理解和生成具有重要意义。现有方法在时序对齐和模态协调方面存在不足，需要更有效的多模态融合机制。

**Method:** 提出两阶段后训练流程：AVoCaDO SFT阶段在新构建的107K高质量时序对齐视听描述数据集上进行监督微调；AVoCaDO GRPO阶段利用定制的奖励函数进一步增强时序一致性和对话准确性，同时规范化描述长度并减少模型坍塌。

**Result:** AVoCaDO在四个视听视频描述基准测试中显著优于现有开源模型，在仅视觉设置的VDC和DREAM-1K基准测试中也取得了有竞争力的性能表现。

**Conclusion:** 该研究表明基于时序编排的视听融合策略能有效提升视频描述质量，两阶段后训练方法为多模态模型优化提供了有效范式，未来可扩展到更广泛的多模态理解任务。

---

#### 📄 Abstract
Audiovisual video captioning aims to generate semantically rich descriptions
with temporal alignment between visual and auditory events, thereby benefiting
both video understanding and generation. In this paper, we present AVoCaDO, a
powerful audiovisual video captioner driven by the temporal orchestration
between audio and visual modalities. We propose a two-stage post-training
pipeline: (1) AVoCaDO SFT, which fine-tunes the model on a newly curated
dataset of 107K high-quality, temporally-aligned audiovisual captions; and (2)
AVoCaDO GRPO, which leverages tailored reward functions to further enhance
temporal coherence and dialogue accuracy while regularizing caption length and
reducing collapse. Experimental results demonstrate that AVoCaDO significantly
outperforms existing open-source models across four audiovisual video
captioning benchmarks, and also achieves competitive performance on the VDC and
DREAM-1K benchmark under visual-only settings.


### [4] [GLOFNet -- A Multimodal Dataset for GLOF Monitoring and Prediction](https://arxiv.org/abs/2510.10546)
*Zuha Fatima, Muhammad Anser Sohaib, Muhammad Talha, Sidra Sultana, Ayesha Kanwal, Nazia Perwaiz*

#### 🧩 TL;DR
本文提出了GLOFNet，一个用于冰川湖溃决洪水监测和预测的多模态数据集，整合了多光谱影像、冰川运动速度和地表温度数据，为罕见灾害预测提供了结构化基准。

---

#### 📘 Detailed Summary
**Motivation:** 冰川湖溃决洪水是高山地区罕见但具有破坏性的灾害，现有研究受限于碎片化和单模态数据，主要关注事后制图，而预测需要结合视觉指标与物理前兆的协调数据集。

**Method:** 研究整合了三种互补数据源：Sentinel-2多光谱影像用于空间监测、NASA ITS_LIVE速度产品用于冰川运动学、MODIS地表温度记录用于长期趋势分析，并进行了云掩膜、质量过滤、归一化、时间插值、数据增强和循环编码等预处理。

**Result:** 探索性分析揭示了冰川速度的季节性周期、每十年约0.8K的长期升温趋势以及冰冻圈条件的空间异质性，数据集公开可用以支持未来冰川灾害预测研究。

**Conclusion:** GLOFNet通过解决类别不平衡、云污染和粗分辨率等挑战，为基准测试多模态深度学习方法在罕见灾害预测中的应用提供了结构化基础，推动了冰川灾害预测研究的发展。

---

#### 📄 Abstract
Glacial Lake Outburst Floods (GLOFs) are rare but destructive hazards in high
mountain regions, yet predictive research is hindered by fragmented and
unimodal data. Most prior efforts emphasize post-event mapping, whereas
forecasting requires harmonized datasets that combine visual indicators with
physical precursors. We present GLOFNet, a multimodal dataset for GLOF
monitoring and prediction, focused on the Shisper Glacier in the Karakoram. It
integrates three complementary sources: Sentinel-2 multispectral imagery for
spatial monitoring, NASA ITS_LIVE velocity products for glacier kinematics, and
MODIS Land Surface Temperature records spanning over two decades. Preprocessing
included cloud masking, quality filtering, normalization, temporal
interpolation, augmentation, and cyclical encoding, followed by harmonization
across modalities. Exploratory analysis reveals seasonal glacier velocity
cycles, long-term warming of ~0.8 K per decade, and spatial heterogeneity in
cryospheric conditions. The resulting dataset, GLOFNet, is publicly available
to support future research in glacial hazard prediction. By addressing
challenges such as class imbalance, cloud contamination, and coarse resolution,
GLOFNet provides a structured foundation for benchmarking multimodal deep
learning approaches to rare hazard prediction.


### [5] [Injecting Frame-Event Complementary Fusion into Diffusion for Optical Flow in Challenging Scenes](https://arxiv.org/abs/2510.10577)
*Haonan Wang, Hanyu Zhou, Haoyue Liu, Luxin Yan*

#### 🧩 TL;DR
本文提出了一种基于扩散模型的帧-事件外观-边界融合光流估计框架Diff-ABFlow，通过扩散模型学习从噪声流到清晰流的映射，解决了高速和低光场景下传统光流估计方法因运动模糊和光照不足导致的性能下降问题。

---

#### 📘 Detailed Summary
**Motivation:** 传统光流估计方法在高速和低光场景下面临运动模糊和光照不足的挑战，导致纹理减弱、噪声放大，并影响帧相机的外观饱和度和边界完整性。现有方法虽然通过特征融合或域适应引入事件相机来改善边界完整性，但外观特征仍然退化，严重影响了基于视觉特征到运动场映射的判别模型和生成模型的性能。

**Method:** 提出Diff-ABFlow框架，基于扩散模型构建帧-事件外观-边界融合的光流估计方法。该框架利用扩散模型学习从噪声流到清晰流的映射过程，不依赖于退化的视觉特征，结合帧相机提供密集外观饱和度和事件相机提供密集边界完整性的互补优势。

**Result:** 该方法在高速和低光退化场景下显著提升了光流估计性能，通过扩散模型的生成能力有效克服了传统方法在恶劣成像条件下的局限性，实现了更准确和鲁棒的运动场估计。

**Conclusion:** 研究表明扩散模型为光流估计提供了一种不依赖于退化视觉特征的新范式，帧-事件传感器的互补融合策略为解决极端成像条件下的运动估计问题开辟了新的技术路径，为计算机视觉在挑战性场景中的应用提供了重要启示。

---

#### 📄 Abstract
Optical flow estimation has achieved promising results in conventional scenes
but faces challenges in high-speed and low-light scenes, which suffer from
motion blur and insufficient illumination. These conditions lead to weakened
texture and amplified noise and deteriorate the appearance saturation and
boundary completeness of frame cameras, which are necessary for motion feature
matching. In degraded scenes, the frame camera provides dense appearance
saturation but sparse boundary completeness due to its long imaging time and
low dynamic range. In contrast, the event camera offers sparse appearance
saturation, while its short imaging time and high dynamic range gives rise to
dense boundary completeness. Traditionally, existing methods utilize feature
fusion or domain adaptation to introduce event to improve boundary
completeness. However, the appearance features are still deteriorated, which
severely affects the mostly adopted discriminative models that learn the
mapping from visual features to motion fields and generative models that
generate motion fields based on given visual features. So we introduce
diffusion models that learn the mapping from noising flow to clear flow, which
is not affected by the deteriorated visual features. Therefore, we propose a
novel optical flow estimation framework Diff-ABFlow based on diffusion models
with frame-event appearance-boundary fusion.


### [6] [A Machine Learning Perspective on Automated Driving Corner Cases](https://arxiv.org/abs/2510.10653)
*Sebastian Schmidt, Julius Körner, Stephan Günnemann*

#### 🧩 TL;DR
本研究提出了一种基于数据分布视角的机器学习方法，用于自动驾驶等高风险应用中的角点案例识别。该方法统一了现有场景分类方法，在标准基准测试中实现了强大的角点案例检测性能。

---

#### 📘 Detailed Summary
**Motivation:** 传统方法通过示例分类处理角点案例，但这种方法缺乏可扩展性且忽视了机器学习模型训练数据的泛化能力。现有方法缺乏数据覆盖视角，无法有效处理高风险应用中的安全问题。

**Method:** 提出了一种考虑底层数据分布的新型机器学习方法，开发了基于分布视角的角点案例识别框架，能够对单个样本进行有效的感知识别。

**Result:** 该方法成功统一了现有基于场景的角点案例分类法，在扩展的标准分布外检测基准上实现了强大的角点案例检测性能，并通过新引入的雾增强Lost & Found数据集支持组合角点案例分析。

**Conclusion:** 研究为角点案例识别提供了原则性基础，强调了无需人工规范的定义方法，为高风险应用的安全操作提供了分布视角的理论支撑和实践框架。

---

#### 📄 Abstract
For high-stakes applications, like autonomous driving, a safe operation is
necessary to prevent harm, accidents, and failures. Traditionally, difficult
scenarios have been categorized into corner cases and addressed individually.
However, this example-based categorization is not scalable and lacks a data
coverage perspective, neglecting the generalization to training data of machine
learning models. In our work, we propose a novel machine learning approach that
takes the underlying data distribution into account. Based on our novel
perspective, we present a framework for effective corner case recognition for
perception on individual samples. In our evaluation, we show that our approach
(i) unifies existing scenario-based corner case taxonomies under a
distributional perspective, (ii) achieves strong performance on corner case
detection tasks across standard benchmarks for which we extend established
out-of-distribution detection benchmarks, and (iii) enables analysis of
combined corner cases via a newly introduced fog-augmented Lost & Found
dataset. These results provide a principled basis for corner case recognition,
underlining our manual specification-free definition.


### [7] [Uncovering Anomalous Events for Marine Environmental Monitoring via Visual Anomaly Detection](https://arxiv.org/abs/2510.10750)
*Laura Weihl, Nejc Novak, Stefan H. Bengtson, Malte Pedersen*

#### 🧩 TL;DR
本研究提出了AURA——首个多标注者水下视觉异常检测基准数据集，并评估了四种深度神经网络模型在两种海洋场景中的表现，揭示了当前模型性能对训练数据量和视觉内容变异性的高度敏感性。

---

#### 📘 Detailed Summary
**Motivation:** 水下视频监测是评估海洋生物多样性的有效策略，但海量无事件视频使得人工检查极不实用，需要自动识别有趣或异常事件的解决方案。

**Method:** 研究探索了基于深度神经网络的水下视觉异常检测方法，引入了首个多标注者基准数据集AURA，并评估了四种VAD模型在两种海洋场景中的表现，同时强调了鲁棒帧选择策略对提取有意义视频片段的重要性。

**Result:** 实验结果表明当前VAD模型性能差异显著，对训练数据量和定义"正常"场景的视觉内容变异性高度敏感，与多标注者的比较揭示了软标签和共识标签的价值。

**Conclusion:** 该研究为支持科学探索和可扩展生物多样性监测提供了实用方法，强调了多标注者基准和鲁棒帧选择策略在水下视觉异常检测中的关键作用。

---

#### 📄 Abstract
Underwater video monitoring is a promising strategy for assessing marine
biodiversity, but the vast volume of uneventful footage makes manual inspection
highly impractical. In this work, we explore the use of visual anomaly
detection (VAD) based on deep neural networks to automatically identify
interesting or anomalous events. We introduce AURA, the first multi-annotator
benchmark dataset for underwater VAD, and evaluate four VAD models across two
marine scenes. We demonstrate the importance of robust frame selection
strategies to extract meaningful video segments. Our comparison against
multiple annotators reveals that VAD performance of current models varies
dramatically and is highly sensitive to both the amount of training data and
the variability in visual content that defines "normal" scenes. Our results
highlight the value of soft and consensus labels and offer a practical approach
for supporting scientific exploration and scalable biodiversity monitoring.


### [8] [LightPneumoNet: Lightweight Pneumonia Classifier](https://arxiv.org/abs/2510.11232)
*Neilansh Chauhan, Piyush Kumar Gupta, Faraz Doja*

#### 🧩 TL;DR
本研究提出了LightPneumoNet，一种轻量级卷积神经网络，专为资源受限环境下的肺炎X光诊断设计，在保持高准确率的同时显著降低了计算和存储需求。

---

#### 📘 Detailed Summary
**Motivation:** 当前肺炎诊断面临大型深度学习模型在资源受限环境中部署困难的问题，特别是在计算能力和存储空间有限的医疗场景下，需要开发高效且准确的轻量级解决方案。

**Method:** 采用从头设计的轻量级CNN架构，包含四个卷积块堆叠，仅388,082个可训练参数，预处理包括图像缩放至224x224、灰度转换和像素归一化，并通过数据增强技术防止过拟合。

**Result:** 在独立测试集上取得了0.942的总体准确率、0.92的精确率和0.96的F1分数，特别是达到了0.99的敏感度，几乎完美识别真实肺炎病例并最小化临床重要的假阴性。

**Conclusion:** 该模型的高效性使其能够在低成本硬件上部署，为资源匮乏诊所提供先进的计算机辅助诊断工具，作为可靠的第二意见工具改善患者预后，同时展示了轻量级架构在医疗影像分析中的巨大潜力。

---

#### 📄 Abstract
Effective pneumonia diagnosis is often challenged by the difficulty of
deploying large, computationally expensive deep learning models in
resource-limited settings. This study introduces LightPneumoNet, an efficient,
lightweight convolutional neural network (CNN) built from scratch to provide an
accessible and accurate diagnostic solution for pneumonia detection from chest
X-rays. Our model was trained on a public dataset of 5,856 chest X-ray images.
Preprocessing included image resizing to 224x224, grayscale conversion, and
pixel normalization, with data augmentation (rotation, zoom, shear) to prevent
overfitting. The custom architecture features four blocks of stacked
convolutional layers and contains only 388,082 trainable parameters, resulting
in a minimal 1.48 MB memory footprint. On the independent test set, our model
delivered exceptional performance, achieving an overall accuracy of 0.942,
precision of 0.92, and an F1-Score of 0.96. Critically, it obtained a
sensitivity (recall) of 0.99, demonstrating a near-perfect ability to identify
true pneumonia cases and minimize clinically significant false negatives.
Notably, LightPneumoNet achieves this high recall on the same dataset where
existing approaches typically require significantly heavier architectures or
fail to reach comparable sensitivity levels. The model's efficiency enables
deployment on low-cost hardware, making advanced computer-aided diagnosis
accessible in underserved clinics and serving as a reliable second-opinion tool
to improve patient outcomes.


### [9] [Frequency Domain Unlocks New Perspectives for Abdominal Medical Image Segmentation](https://arxiv.org/abs/2510.11005)
*Kai Han, Siqi Ma, Chengxuan Qian, Jun Chen, Chongwen Lyu, Yuqing Song, Zhe Liu*

#### 🧩 TL;DR
本文提出了前景感知频谱分割（FASS）框架，通过前景感知模块、小波变换特征增强和边缘约束模块，显著提升了医学图像中低对比度肿瘤分割的准确性和鲁棒性。

---

#### 📘 Detailed Summary
**Motivation:** 基础模型在分割任务中表现良好，但在复杂低对比度背景下难以聚焦前景区域，特别是当恶性肿瘤与正常器官形态相似时，上下文区分变得困难，这限制了医学图像分割在手术规划和肿瘤分期中的准确性。

**Method:** 提出FASS框架，包含三个核心模块：前景感知模块增强背景与整体体积空间的区分度；基于小波变换的特征级频率增强模块提取判别性高频特征以改善边界识别；边缘约束模块保持分割边界的几何连续性。

**Result:** 在多个医学数据集上的广泛实验表明，该框架在所有评估指标上均表现出优越性能，特别是在复杂条件下的鲁棒性和精细结构识别方面验证了其有效性，显著提升了低对比度图像的分割质量。

**Conclusion:** 该框架显著增强了低对比度医学图像的分割能力，为更广泛和复杂的医学成像场景应用铺平了道路，在手术规划和肿瘤分期等临床任务中具有重要应用价值。

---

#### 📄 Abstract
Accurate segmentation of tumors and adjacent normal tissues in medical images
is essential for surgical planning and tumor staging. Although foundation
models generally perform well in segmentation tasks, they often struggle to
focus on foreground areas in complex, low-contrast backgrounds, where some
malignant tumors closely resemble normal organs, complicating contextual
differentiation. To address these challenges, we propose the Foreground-Aware
Spectrum Segmentation (FASS) framework. First, we introduce a foreground-aware
module to amplify the distinction between background and the entire volume
space, allowing the model to concentrate more effectively on target areas.
Next, a feature-level frequency enhancement module, based on wavelet transform,
extracts discriminative high-frequency features to enhance boundary recognition
and detail perception. Eventually, we introduce an edge constraint module to
preserve geometric continuity in segmentation boundaries. Extensive experiments
on multiple medical datasets demonstrate superior performance across all
metrics, validating the effectiveness of our framework, particularly in
robustness under complex conditions and fine structure recognition. Our
framework significantly enhances segmentation of low-contrast images, paving
the way for applications in more diverse and complex medical imaging scenarios.


### [10] [LSVOS 2025 Challenge Report: Recent Advances in Complex Video Object Segmentation](https://arxiv.org/abs/2510.11063)
*Chang Liu, Henghui Ding, Kaining Ying, Lingyi Hong, Ning Xu, Linjie Yang, Yuchen Fan, Mingqi Gao, Jingkun Chen, Yunqi Miao, Gengshen Wu, Zhijin Qin, Jungong Han, Zhixiong Zhang, Shuangrui Ding, Xiaoyi Dong, Yuhang Zang, Yuhang Cao, Jiaqi Wang, Chang Soo Lim, Joonyoung Moon, Donghyeon Cho, Tingmin Li, Yixuan Li, Yang Yang, An Yan, Leilei Cao, Feng Lu, Ran Hong, Youhai Jiang, Fengjie Zhu, Yujie Xie, Hongyang Zhang, Zhihui Liu, Shihai Ruan, Quanzhu Niu, Dengxian Gong, Shihao Chen, Tao Zhang, Yikang Zhou, Haobo Yuan, Lu Qi, Xiangtai Li, Shunping Ji, Ran Hong, Feng Lu, Leilei Cao, An Yan, Alexey Nekrasov, Ali Athar, Daan de Geus, Alexander Hermans, Bastian Leibe*

#### 🧩 TL;DR
本文介绍了ICCV 2025第七届大规模视频目标分割挑战赛，在传统VOS和RVOS赛道基础上新增了更具挑战性的MOSEv2赛道，通过引入更复杂的真实场景推动长期一致性和泛化能力的发展。

---

#### 📘 Detailed Summary
**Motivation:** 该研究旨在解决传统视频目标分割在真实复杂场景中的局限性，特别是针对密集小目标、频繁消失重现、严重遮挡、恶劣天气和光照等更具挑战性但更现实的场景，推动模型在非精心策划基准测试之外的长期一致性和泛化能力。

**Method:** 挑战赛保留了VOS和RVOS两个传统赛道，并新增了MOSEv2赛道，该赛道采用J&F作为主要排名指标以更好地评估跨尺度和消失情况下的目标分割性能，同时强调了LLM/MLLM组件和内存感知传播等新兴技术趋势。

**Result:** 挑战赛采用了标准J、F和J&F指标评估VOS和RVOS赛道性能，而MOSEv2赛道采用J&F作为主要排名指标，通过总结顶级解决方案和新兴趋势，展示了在复杂真实场景下视频分割的最新进展。

**Conclusion:** 该研究为鲁棒、语言感知的视频分割技术指明了未来发展方向，强调了在真实复杂场景中提升模型性能的重要性，并为社区提供了评估长期一致性和泛化能力的新基准和协议。

---

#### 📄 Abstract
This report presents an overview of the 7th Large-scale Video Object
Segmentation (LSVOS) Challenge held in conjunction with ICCV 2025. Besides the
two traditional tracks of LSVOS that jointly target robustness in realistic
video scenarios: Classic VOS (VOS), and Referring VOS (RVOS), the 2025 edition
features a newly introduced track, Complex VOS (MOSEv2). Building upon prior
insights, MOSEv2 substantially increases difficulty, introducing more
challenging but realistic scenarios including denser small objects, frequent
disappear/reappear events, severe occlusions, adverse weather and lighting,
etc., pushing long-term consistency and generalization beyond curated
benchmarks. The challenge retains standard ${J}$, $F$, and ${J\&F}$ metrics for
VOS and RVOS, while MOSEv2 adopts ${J\&\dot{F}}$ as the primary ranking metric
to better evaluate objects across scales and disappearance cases. We summarize
datasets and protocols, highlight top-performing solutions, and distill
emerging trends, such as the growing role of LLM/MLLM components and
memory-aware propagation, aiming to chart future directions for resilient,
language-aware video segmentation in the wild.


### [11] [When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models](https://arxiv.org/abs/2510.11302)
*Samer Al-Hamadani*

#### 🧩 TL;DR
本研究首次对监督学习目标检测（YOLO）与零样本视觉语言模型检测（Gemini Flash 2.5）进行成本效益综合分析，建立了架构选择的定量平衡点阈值，揭示了部署规模、类别稳定性和预算约束对最优架构选择的关键影响。

---

#### 📘 Detailed Summary
**Motivation:** 传统监督目标检测依赖人工标注边界框，虽然精度高但标注成本巨大，而新兴的视觉语言模型支持零样本检测但精度较低，缺乏系统性的成本效益比较分析来指导实际部署决策。

**Method:** 研究采用系统评估方法，在1,000张分层COCO图像和200张多样化产品图像上进行测试，结合详细的总拥有成本建模，比较监督YOLO检测与零样本Gemini Flash 2.5推理的性能和成本效益。

**Result:** 监督YOLO在标准类别上达到91.2%准确率，显著高于Gemini的68.5%，但需要10,800美元标注成本；只有在超过5,500万次推理时投资才合理；Gemini在多样化产品类别上实现52.3%准确率，而YOLO因架构限制对未训练类别准确率为0%；每正确检测成本分析显示Gemini在10万次推理时成本显著更低（0.00050美元 vs 0.143美元）。

**Conclusion:** 最优检测架构选择关键取决于部署规模、类别稳定性、预算约束和精度要求，而非纯粹技术性能指标；研究开发了决策框架，证明在低推理量、动态类别或预算受限场景下，零样本VLM更具成本效益，而在高推理量、稳定类别场景下监督学习更优。

---

#### 📄 Abstract
Object detection systems have traditionally relied on supervised learning
with manually annotated bounding boxes, achieving high accuracy at the cost of
substantial annotation investment. The emergence of Vision-Language Models
(VLMs) offers an alternative paradigm enabling zero-shot detection through
natural language queries, eliminating annotation requirements but operating
with reduced accuracy. This paper presents the first comprehensive
cost-effectiveness analysis comparing supervised detection (YOLO) with
zero-shot VLM inference (Gemini Flash 2.5). Through systematic evaluation on
1,000 stratified COCO images and 200 diverse product images spanning consumer
electronics and rare categories, combined with detailed Total Cost of Ownership
modeling, we establish quantitative break-even thresholds governing
architecture selection. Our findings reveal that supervised YOLO achieves 91.2%
accuracy versus 68.5% for zero-shot Gemini on standard categories, representing
a 22.7 percentage point advantage that costs $10,800 in annotation for
100-category systems. However, this advantage justifies investment only beyond
55 million inferences, equivalent to 151,000 images daily for one year.
Zero-shot Gemini demonstrates 52.3% accuracy on diverse product categories
(ranging from highly web-prevalent consumer electronics at 75-85% to rare
specialized equipment at 25-40%) where supervised YOLO achieves 0% due to
architectural constraints preventing detection of untrained classes. Cost per
Correct Detection analysis reveals substantially lower per-detection costs for
Gemini ($0.00050 vs $0.143) at 100,000 inferences despite accuracy deficits. We
develop decision frameworks demonstrating that optimal architecture selection
depends critically on deployment volume, category stability, budget
constraints, and accuracy requirements rather than purely technical performance
metrics.


### [12] [Evaluating the effects of preprocessing, method selection, and hyperparameter tuning on SAR-based flood mapping and water depth estimation](https://arxiv.org/abs/2510.11305)
*Jean-Paul Travert, Cédric Goeury, Sébastien Boyaval, Vito Bacchi, Fabrice Zaoui*

#### 🧩 TL;DR
本研究评估了SAR图像洪水制图和水深估计的完整处理流程，发现方法选择和超参数调优对结果有显著影响，建议采用集成方法而非单一配置来处理洪水监测中的不确定性。

---

#### 📘 Detailed Summary
**Motivation:** 洪水制图和水深估计对于校准和验证水力模型至关重要，但现有方法在处理SAR图像时存在预处理、洪水制图和水深估计各步骤方法选择及超参数调优的不确定性，需要系统评估这些因素对最终结果的影响。

**Method:** 研究采用集成方法评估多种预处理技术（特别是斑点噪声抑制）、洪水制图方法（包括监督和无监督方法）和水深估计算法，通过考虑预处理图像、洪水图和水深场的集合来分析不同步骤方法选择及其超参数的影响。

**Result:** 结果表明斑点滤波器的选择会改变数平方公里的洪水范围估计，监督方法优于无监督方法但调优后的无监督方法（如局部阈值或变化检测）可达到相当性能，预处理和洪水制图步骤的累积不确定性导致水深场估计存在高度变异性。

**Conclusion:** 研究强调必须考虑包含预处理、洪水制图和水深估计方法及其相关超参数的完整处理流程，应采用集成方法并考虑方法学不确定性而非依赖单一配置，洪水制图中方法选择影响最大，水深估计中最具影响力的处理步骤是洪水制图步骤产生的洪水图输入和方法超参数。

---

#### 📄 Abstract
Flood mapping and water depth estimation from Synthetic Aperture Radar (SAR)
imagery are crucial for calibrating and validating hydraulic models. This study
uses SAR imagery to evaluate various preprocessing (especially speckle noise
reduction), flood mapping, and water depth estimation methods. The impact of
the choice of method at different steps and its hyperparameters is studied by
considering an ensemble of preprocessed images, flood maps, and water depth
fields. The evaluation is conducted for two flood events on the Garonne River
(France) in 2019 and 2021, using hydrodynamic simulations and in-situ
observations as reference data. Results show that the choice of speckle filter
alters flood extent estimations with variations of several square kilometers.
Furthermore, the selection and tuning of flood mapping methods also affect
performance. While supervised methods outperformed unsupervised ones, tuned
unsupervised approaches (such as local thresholding or change detection) can
achieve comparable results. The compounded uncertainty from preprocessing and
flood mapping steps also introduces high variability in the water depth field
estimates. This study highlights the importance of considering the entire
processing pipeline, encompassing preprocessing, flood mapping, and water depth
estimation methods and their associated hyperparameters. Rather than relying on
a single configuration, adopting an ensemble approach and accounting for
methodological uncertainty should be privileged. For flood mapping, the method
choice has the most influence. For water depth estimation, the most influential
processing step was the flood map input resulting from the flood mapping step
and the hyperparameters of the methods.


### [13] [SNAP: Towards Segmenting Anything in Any Point Cloud](https://arxiv.org/abs/2510.11565)
*Aniket Gupta, Hanhui Wang, Charles Saunders, Aruni RoyChowdhury, Hanumant Singh, Huaizu Jiang*

#### 🧩 TL;DR
SNAP是一个统一的交互式3D点云分割模型，支持跨域的点基和文本基提示，通过在7个数据集上的训练和域自适应归一化实现了卓越的零样本泛化能力。

---

#### 📘 Detailed Summary
**Motivation:** 当前交互式3D点云分割方法存在领域限制（仅室内或室外）和交互方式单一（仅空间点击或文本提示）的问题，同时在多数据集训练时容易产生负迁移，导致缺乏通用性的领域特定工具。

**Method:** 提出SNAP统一模型，采用域自适应归一化防止负迁移，在7个跨域数据集上训练；对于文本提示分割，自动生成掩码提案并与文本查询的CLIP嵌入进行匹配，实现全景和开放词汇分割。

**Result:** 在空间提示分割的9个零样本基准测试中，8个达到最先进性能；在文本提示分割的5个基准测试中均取得竞争性结果，证明了统一模型可以匹配或超越专门的领域特定方法。

**Conclusion:** 研究表明统一模型能够实现跨域通用性，为可扩展的3D标注提供了实用工具，打破了传统方法在领域和交互方式上的限制。

---

#### 📄 Abstract
Interactive 3D point cloud segmentation enables efficient annotation of
complex 3D scenes through user-guided prompts. However, current approaches are
typically restricted in scope to a single domain (indoor or outdoor), and to a
single form of user interaction (either spatial clicks or textual prompts).
Moreover, training on multiple datasets often leads to negative transfer,
resulting in domain-specific tools that lack generalizability. To address these
limitations, we present \textbf{SNAP} (\textbf{S}egment a\textbf{N}ything in
\textbf{A}ny \textbf{P}oint cloud), a unified model for interactive 3D
segmentation that supports both point-based and text-based prompts across
diverse domains. Our approach achieves cross-domain generalizability by
training on 7 datasets spanning indoor, outdoor, and aerial environments, while
employing domain-adaptive normalization to prevent negative transfer. For
text-prompted segmentation, we automatically generate mask proposals without
human intervention and match them against CLIP embeddings of textual queries,
enabling both panoptic and open-vocabulary segmentation. Extensive experiments
demonstrate that SNAP consistently delivers high-quality segmentation results.
We achieve state-of-the-art performance on 8 out of 9 zero-shot benchmarks for
spatial-prompted segmentation and demonstrate competitive results on all 5
text-prompted benchmarks. These results show that a unified model can match or
exceed specialized domain-specific approaches, providing a practical tool for
scalable 3D annotation. Project page is at, https://neu-vi.github.io/SNAP/


### [14] [MS-Mix: Unveiling the Power of Mixup for Multimodal Sentiment Analysis](https://arxiv.org/abs/2510.11579)
*Hongyu Zhu, Lin Chen, Mounim A. El-Yacoubi, Mingsheng Shang*

#### 🧩 TL;DR
本文提出了MS-Mix，一种用于多模态情感分析的自适应情感敏感数据增强框架，通过情感感知样本选择、情感强度引导的混合比例计算和情感对齐损失，有效解决了传统Mixup方法在多模态场景下导致的标签模糊和语义不一致问题。

---

#### 📘 Detailed Summary
**Motivation:** 多模态情感分析面临标注数据稀缺的挑战，而传统的Mixup数据增强方法直接应用于多模态场景时会引入标签模糊和语义不一致问题，因为缺乏情感感知的混合机制导致随机混合可能放大情感矛盾样本间的语义混淆。

**Method:** MS-Mix框架包含三个关键组件：情感感知样本选择策略防止情感矛盾样本混合导致的语义混淆；情感强度引导模块使用多头自注意力动态计算模态特定的混合比例；情感对齐损失通过KL散度损失作为正则化项联合训练情感强度预测器和骨干网络。

**Result:** 在三个基准数据集和六个最先进骨干网络上的广泛实验表明，MS-Mix持续优于现有方法，在多个评估指标上均取得了显著提升，为鲁棒的多模态情感增强建立了新的标准。

**Conclusion:** 该研究证明了情感感知的数据增强在多模态情感分析中的重要性，MS-Mix框架通过自适应混合机制有效缓解了数据稀缺问题，同时保持了语义一致性，为多模态学习中的增强策略设计提供了新的思路和方向。

---

#### 📄 Abstract
Multimodal Sentiment Analysis (MSA) aims to identify and interpret human
emotions by integrating information from heterogeneous data sources such as
text, video, and audio. While deep learning models have advanced in network
architecture design, they remain heavily limited by scarce multimodal annotated
data. Although Mixup-based augmentation improves generalization in unimodal
tasks, its direct application to MSA introduces critical challenges: random
mixing often amplifies label ambiguity and semantic inconsistency due to the
lack of emotion-aware mixing mechanisms. To overcome these issues, we propose
MS-Mix, an adaptive, emotion-sensitive augmentation framework that
automatically optimizes sample mixing in multimodal settings. The key
components of MS-Mix include: (1) a Sentiment-Aware Sample Selection (SASS)
strategy that effectively prevents semantic confusion caused by mixing samples
with contradictory emotions. (2) a Sentiment Intensity Guided (SIG) module
using multi-head self-attention to compute modality-specific mixing ratios
dynamically based on their respective emotional intensities. (3) a Sentiment
Alignment Loss (SAL) that aligns the prediction distributions across
modalities, and incorporates the Kullback-Leibler-based loss as an additional
regularization term to train the emotion intensity predictor and the backbone
network jointly. Extensive experiments on three benchmark datasets with six
state-of-the-art backbones confirm that MS-Mix consistently outperforms
existing methods, establishing a new standard for robust multimodal sentiment
augmentation. The source code is available at:
https://github.com/HongyuZhu-s/MS-Mix.


### [15] [Ev4DGS: Novel-view Rendering of Non-Rigid Objects from Monocular Event Streams](https://arxiv.org/abs/2510.11717)
*Takuya Nakabayashi, Navami Kairanda, Hideo Saito, Vladislav Golyanik*

#### 🧩 TL;DR
本文提出了Ev4DGS，这是首个仅从单目事件流中实现非刚性变形物体新视角渲染的方法，通过可变形3D高斯泼溅表示和基于事件的损失函数，解决了现有方法需要RGB输入的局限性。

---

#### 📘 Detailed Summary
**Motivation:** 现有基于事件相机的新视角渲染方法主要针对刚性场景，对于非刚性物体则需要额外的稀疏RGB输入，这在实践中存在显著限制；本文旨在探索是否能够仅从事件流中学习类似模型，填补这一研究空白。

**Method:** 该方法通过回归可变形3D高斯泼溅表示，采用两种关键技术：1）将估计模型输出与2D事件观测空间相关联的损失函数；2）从事件生成的二值掩码中训练的粗糙3D变形模型，实现了仅基于事件流的非刚性场景建模。

**Result:** 在现有的合成数据集和新录制的真实非刚性物体数据集上的实验表明，Ev4DGS方法有效可行，并且在我们的设定中相比多个朴素基线方法表现出优越性能，验证了仅使用事件流进行非刚性新视角渲染的可行性。

**Conclusion:** 这项研究证明了仅从事件流中学习非刚性变形物体新视角渲染模型的可行性，为事件相机在动态场景建模中的应用开辟了新途径，同时发布的模型和数据集将促进该领域的进一步研究发展。

---

#### 📄 Abstract
Event cameras offer various advantages for novel view rendering compared to
synchronously operating RGB cameras, and efficient event-based techniques
supporting rigid scenes have been recently demonstrated in the literature. In
the case of non-rigid objects, however, existing approaches additionally
require sparse RGB inputs, which can be a substantial practical limitation; it
remains unknown if similar models could be learned from event streams only.
This paper sheds light on this challenging open question and introduces Ev4DGS,
i.e., the first approach for novel view rendering of non-rigidly deforming
objects in the explicit observation space (i.e., as RGB or greyscale images)
from monocular event streams. Our method regresses a deformable 3D Gaussian
Splatting representation through 1) a loss relating the outputs of the
estimated model with the 2D event observation space, and 2) a coarse 3D
deformation model trained from binary masks generated from events. We perform
experimental comparisons on existing synthetic and newly recorded real datasets
with non-rigid objects. The results demonstrate the validity of Ev4DGS and its
superior performance compared to multiple naive baselines that can be applied
in our setting. We will release our models and the datasets used in the
evaluation for research purposes; see the project webpage:
https://4dqv.mpi-inf.mpg.de/Ev4DGS/.


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [16] [NG-Router: Graph-Supervised Multi-Agent Collaboration for Nutrition Question Answering](https://arxiv.org/abs/2510.09854)
*Kaiwen Shi, Zheyuan Zhang, Zhengqing Yuan, Keerthiram Murugesan, Vincent Galass, Chuxu Zhang, Yanfang Ye*

#### 🧩 TL;DR
本研究提出NG-Router框架，将营养问答建模为基于知识图谱引导的多智能体协作问题，通过图神经网络学习任务感知的路由分布，有效解决了单智能体推理能力有限和多智能体架构设计复杂等挑战。

---

#### 📘 Detailed Summary
**Motivation:** 现有营养问答方法面临两个基本挑战：单智能体系统的推理能力有限，以及设计有效多智能体架构的复杂性，同时上下文过载问题阻碍了准确决策制定。

**Method:** NG-Router框架将智能体节点集成到异构知识图谱中，采用图神经网络学习基于经验智能体性能的软监督任务感知路由分布，并提出基于梯度的子图检索机制来识别训练过程中的关键证据。

**Result:** 在多个基准测试和骨干模型上的广泛实验表明，NG-Router始终优于单智能体和集成基线方法，为复杂营养健康任务提供了领域感知多智能体推理的原则性方法。

**Conclusion:** 该研究为复杂营养健康任务提供了领域感知多智能体推理的原则性方法，通过知识图谱引导的协作机制有效提升了营养问答系统的推理能力和决策准确性。

---

#### 📄 Abstract
Diet plays a central role in human health, and Nutrition Question Answering
(QA) offers a promising path toward personalized dietary guidance and the
prevention of diet-related chronic diseases. However, existing methods face two
fundamental challenges: the limited reasoning capacity of single-agent systems
and the complexity of designing effective multi-agent architectures, as well as
contextual overload that hinders accurate decision-making. We introduce
Nutritional-Graph Router (NG-Router), a novel framework that formulates
nutritional QA as a supervised, knowledge-graph-guided multi-agent
collaboration problem. NG-Router integrates agent nodes into heterogeneous
knowledge graphs and employs a graph neural network to learn task-aware routing
distributions over agents, leveraging soft supervision derived from empirical
agent performance. To further address contextual overload, we propose a
gradient-based subgraph retrieval mechanism that identifies salient evidence
during training, thereby enhancing multi-hop and relational reasoning.
Extensive experiments across multiple benchmarks and backbone models
demonstrate that NG-Router consistently outperforms both single-agent and
ensemble baselines, offering a principled approach to domain-aware multi-agent
reasoning for complex nutritional health tasks.


### [17] [NarraBench: A Comprehensive Framework for Narrative Benchmarking](https://arxiv.org/abs/2510.09869)
*Sil Hamilton, Matthew Wilkens, Andrew Piper*

#### 🧩 TL;DR
本文提出了NarraBench，一个理论指导的叙事理解任务分类法，并对该领域的78个现有基准进行了系统调查，揭示了当前评估在叙事理解关键维度上的显著不足。

---

#### 📘 Detailed Summary
**Motivation:** 当前叙事理解领域的评估存在显著空白，许多关键叙事维度在现有基准中要么被忽视，要么与现有指标不匹配，需要系统性地识别这些评估缺口并指导未来基准开发。

**Method:** 研究开发了理论指导的叙事理解任务分类法，并对78个现有基准进行了全面调查，采用系统化方法评估当前基准对叙事任务的覆盖程度和评估质量。

**Result:** 研究发现仅有27%的叙事任务被现有基准充分覆盖，叙事事件、风格、视角和启示等关键维度在现有评估中几乎缺失，构成性主观和视角性方面的评估能力尤其不足。

**Conclusion:** 该研究为NLP研究者提供了识别叙事理解评估缺口的重要框架，强调了开发能够评估主观和视角性叙事方面的基准的迫切需求，对指导未来LLM叙事理解评估具有重要意义。

---

#### 📄 Abstract
We present NarraBench, a theory-informed taxonomy of narrative-understanding
tasks, as well as an associated survey of 78 existing benchmarks in the area.
We find significant need for new evaluations covering aspects of narrative
understanding that are either overlooked in current work or are poorly aligned
with existing metrics. Specifically, we estimate that only 27% of narrative
tasks are well captured by existing benchmarks, and we note that some areas --
including narrative events, style, perspective, and revelation -- are nearly
absent from current evaluations. We also note the need for increased
development of benchmarks capable of assessing constitutively subjective and
perspectival aspects of narrative, that is, aspects for which there is
generally no single correct answer. Our taxonomy, survey, and methodology are
of value to NLP researchers seeking to test LLM narrative understanding.


### [18] [Diversity Augmentation of Dynamic User Preference Data for Boosting Personalized Text Summarizers](https://arxiv.org/abs/2510.10082)
*Parthiv Chatterjee, Shivam Sonawane, Amey Hengle, Aditya Tanna, Sourish Dasgupta, Tanmoy Chakraborty*

#### 🧩 TL;DR
本研究提出PerAugy数据增强技术，通过跨轨迹混洗和摘要内容扰动解决个性化摘要训练数据稀缺问题，显著提升了用户编码器性能和个性化摘要质量。

---

#### 📘 Detailed Summary
**Motivation:** 个性化摘要面临训练数据稀缺的挑战，现有MS/CAS PENS数据集仅包含用户偏好历史而缺乏目标摘要，无法支持端到端监督学习，且主题转换多样性有限限制了模型泛化能力。

**Method:** 提出PerAugy数据增强技术，采用跨轨迹混洗和摘要内容扰动方法，显著提升了四种最先进用户编码器的性能，并引入TP、RTC和DegreeD三个数据集多样性指标量化增强效果。

**Result:** PerAugy使四种SOTA用户编码器的AUC指标最佳提升0.132，增强后的个性化摘要框架在PSE-SU4指标上平均提升61.2%，TP和DegreeD多样性指标与用户编码器性能呈强相关性。

**Conclusion:** 数据集多样性是驱动性能提升的关键因素，PerAugy通过有效的数据增强解决了个性化摘要的数据稀缺问题，为个性化信息提取系统提供了实用解决方案。

---

#### 📄 Abstract
Document summarization enables efficient extraction of user-relevant content
but is inherently shaped by individual subjectivity, making it challenging to
identify subjective salient information in multifaceted documents. This
complexity underscores the necessity for personalized summarization. However,
training models for personalized summarization has so far been challenging,
particularly because diverse training data containing both user preference
history (i.e., click-skip trajectory) and expected (gold-reference) summaries
are scarce. The MS/CAS PENS dataset is a valuable resource but includes only
preference history without target summaries, preventing end-to-end supervised
learning, and its limited topic-transition diversity further restricts
generalization. To address this, we propose $\mathrm{PerAugy}$, a novel
cross-trajectory shuffling and summary-content perturbation based data
augmentation technique that significantly boosts the accuracy of four
state-of-the-art baseline (SOTA) user-encoders commonly used in personalized
summarization frameworks (best result: $\text{0.132}$$\uparrow$ w.r.t AUC). We
select two such SOTA summarizer frameworks as baselines and observe that when
augmented with their corresponding improved user-encoders, they consistently
show an increase in personalization (avg. boost: $\text{61.2\%}\uparrow$ w.r.t.
PSE-SU4 metric). As a post-hoc analysis of the role of induced diversity in the
augmented dataset by \peraugy, we introduce three dataset diversity metrics --
$\mathrm{TP}$, $\mathrm{RTC}$, and \degreed\ to quantify the induced diversity.
We find that $\mathrm{TP}$ and $\mathrm{DegreeD}$ strongly correlate with
user-encoder performance on the PerAugy-generated dataset across all accuracy
metrics, indicating that increased dataset diversity is a key factor driving
performance gains.


### [19] [You're Not Gonna Believe This: A Computational Analysis of Factual Appeals and Sourcing in Partisan News](https://arxiv.org/abs/2510.10658)
*Guy Mor-Lan, Tamir Sheafer, Shaul R. Shenhav*

#### 🧩 TL;DR
本研究通过大规模比较CNN和福克斯新闻的报道风格，量化了党派媒体在构建现实时采用的不同认知策略，为媒体偏见研究增添了新的维度。研究发现CNN更倾向于使用事实陈述并引用外部来源，而福克斯新闻则偏好新闻报道和直接引语。

---

#### 📘 Detailed Summary
**Motivation:** 虽然媒体偏见已被广泛研究，但事实报道背后的认知策略在计算层面仍未被充分探索，本研究旨在填补这一空白，通过分析不同媒体在报道相同事件时采用的认知策略差异。

**Method:** 研究采用文章匹配策略来隔离报道风格与主题选择的影响，将FactAppeal框架应用于包含47万篇文章的语料库，涵盖COVID-19大流行和以色列-哈马斯战争两个高度政治化时期，比较CNN和福克斯新闻对相同事件的报道方式。

**Result:** 研究发现CNN的报道包含更多事实陈述且更倾向于将其建立在外部来源基础上，两家媒体展现出明显不同的来源模式：CNN通过引用专家和专家文件构建正式权威诉求，而福克斯新闻则偏爱新闻报道和直接引语。

**Conclusion:** 这项研究量化了党派媒体如何系统性地使用不同的认知策略来构建现实，揭示了媒体报道不仅在选择主题上存在偏见，在事实呈现的认知策略上也存在系统性差异，为理解媒体偏见提供了新的分析维度。

---

#### 📄 Abstract
While media bias is widely studied, the epistemic strategies behind factual
reporting remain computationally underexplored. This paper analyzes these
strategies through a large-scale comparison of CNN and Fox News. To isolate
reporting style from topic selection, we employ an article matching strategy to
compare reports on the same events and apply the FactAppeal framework to a
corpus of over 470K articles covering two highly politicized periods: the
COVID-19 pandemic and the Israel-Hamas war. We find that CNN's reporting
contains more factual statements and is more likely to ground them in external
sources. The outlets also exhibit sharply divergent sourcing patterns: CNN
builds credibility by citing Experts} and Expert Documents, constructing an
appeal to formal authority, whereas Fox News favors News Reports and direct
quotations. This work quantifies how partisan outlets use systematically
different epistemic strategies to construct reality, adding a new dimension to
the study of media bias.


### [20] [Towards Real-Time Fake News Detection under Evidence Scarcity](https://arxiv.org/abs/2510.11277)
*Guangyu Wei, Ke Han, Yueming Lyu, Yu Luo, Yue Jiang, Caifeng Shan, Nicu Sebe*

#### 🧩 TL;DR
本文提出了EASE框架，通过动态评估证据充分性来改进实时假新闻检测，在证据稀缺情况下显著提升了泛化能力。该框架引入三阶段评估机制，结合指令调优和伪标签训练，在多个基准测试中实现了最先进的性能。

---

#### 📘 Detailed Summary
**Motivation:** 现有假新闻检测方法严重依赖外部证据，在实时场景下新兴事件往往缺乏足够证据支持，导致模型在证据稀缺情况下泛化能力不足。需要开发能够动态适应证据可用性的检测框架。

**Method:** 提出EASE框架，包含三个独立视角的序列评估机制：基于证据的评估仅在证据充分支持时整合证据；基于推理的评估在可靠性足够时利用LLM的世界知识；情感回退机制在证据和推理均不可靠时整合情感线索。通过指令调优和伪标签训练提升评估准确性。

**Result:** EASE在多个基准测试中实现了最先进的性能，并显著提升了对实时新闻的泛化能力。构建了RealTimeNews-25新基准用于评估新兴新闻的检测效果，实验证明该框架在证据稀缺情况下表现优异。

**Conclusion:** EASE框架通过动态评估证据充分性实现了更鲁棒的假新闻检测，证明了多视角评估机制在证据稀缺场景下的有效性。该研究为实时假新闻检测提供了新范式，强调了评估感知决策的重要性。

---

#### 📄 Abstract
Fake news detection becomes particularly challenging in real-time scenarios,
where emerging events often lack sufficient supporting evidence. Existing
approaches often rely heavily on external evidence and therefore struggle to
generalize under evidence scarcity. To address this issue, we propose
Evaluation-Aware Selection of Experts (EASE), a novel framework for real-time
fake news detection that dynamically adapts its decision-making process
according to the assessed sufficiency of available evidence. EASE introduces a
sequential evaluation mechanism comprising three independent perspectives: (1)
Evidence-based evaluation, which assesses evidence and incorporates it into
decision-making only when the evidence is sufficiently supportive; (2)
Reasoning-based evaluation, which leverages the world knowledge of large
language models (LLMs) and applies them only when their reliability is
adequately established; and (3) Sentiment-based fallback, which integrates
sentiment cues when neither evidence nor reasoning is reliable. To enhance the
accuracy of evaluation processes, EASE employs instruction tuning with pseudo
labels to guide each evaluator in justifying its perspective-specific knowledge
through interpretable reasoning. Furthermore, the expert modules integrate the
evaluators' justified assessments with the news content to enable
evaluation-aware decision-making, thereby enhancing overall detection accuracy.
Moreover, we introduce RealTimeNews-25, a new benchmark comprising recent news
for evaluating model generalization on emerging news with limited evidence.
Extensive experiments demonstrate that EASE not only achieves state-of-the-art
performance across multiple benchmarks, but also significantly improves
generalization to real-time news. The code and dataset are available:
https://github.com/wgyhhhh/EASE.


### [21] [Do LLMs "Feel"? Emotion Circuits Discovery and Control](https://arxiv.org/abs/2510.11328)
*Chenxi Wang, Yixuan Zhang, Ruiji Yu, Yufei Zheng, Lang Gao, Zirui Song, Zixiang Xu, Gus Xia, Huishuai Zhang, Dongyan Zhao, Xiuying Chen*

#### 🧩 TL;DR
本研究首次系统性地揭示并验证了大型语言模型中的情感电路机制，通过构建受控数据集和因果分析方法，发现了跨上下文一致的情感编码模式，并实现了99.65%的情感表达控制准确率。

---

#### 📘 Detailed Summary
**Motivation:** 当前大型语言模型情感智能发展的关键挑战在于理解情感表达的内部机制并实现对生成文本中情感的控制，本研究旨在解决三个核心问题：LLMs是否包含塑造情感表达的上下文无关机制、这些机制的具体形式以及能否用于通用情感控制。

**Method:** 研究首先构建了受控数据集SEV来引发跨情感的可比内部状态，随后提取了上下文无关的情感方向，通过分析性分解和因果分析识别了局部执行情感计算的神经元和注意力头，并通过消融和增强干预验证其因果作用，最后量化各子层对最终情感表示的因果影响并整合局部组件为驱动情感表达的全局情感电路。

**Result:** 研究发现存在跨上下文一致的情感编码机制，识别出局部情感计算组件并验证其因果作用，直接调制这些情感电路在测试集上实现了99.65%的情感表达准确率，超越了基于提示和导向的方法。

**Conclusion:** 这是首个系统揭示和验证LLMs中情感电路的研究，为模型可解释性和可控情感智能提供了新的见解，通过理解内部情感机制实现了高效的情感控制，为开发更精准的情感智能系统奠定了基础。

---

#### 📄 Abstract
As the demand for emotional intelligence in large language models (LLMs)
grows, a key challenge lies in understanding the internal mechanisms that give
rise to emotional expression and in controlling emotions in generated text.
This study addresses three core questions: (1) Do LLMs contain context-agnostic
mechanisms shaping emotional expression? (2) What form do these mechanisms
take? (3) Can they be harnessed for universal emotion control? We first
construct a controlled dataset, SEV (Scenario-Event with Valence), to elicit
comparable internal states across emotions. Subsequently, we extract
context-agnostic emotion directions that reveal consistent, cross-context
encoding of emotion (Q1). We identify neurons and attention heads that locally
implement emotional computation through analytical decomposition and causal
analysis, and validate their causal roles via ablation and enhancement
interventions. Next, we quantify each sublayer's causal influence on the
model's final emotion representation and integrate the identified local
components into coherent global emotion circuits that drive emotional
expression (Q2). Directly modulating these circuits achieves 99.65%
emotion-expression accuracy on the test set, surpassing prompting- and
steering-based methods (Q3). To our knowledge, this is the first systematic
study to uncover and validate emotion circuits in LLMs, offering new insights
into interpretability and controllable emotional intelligence.


### [22] [Stabilizing MoE Reinforcement Learning by Aligning Training and Inference Routers](https://arxiv.org/abs/2510.11370)
*Wenhan Ma, Hailin Zhang, Liang Zhao, Yifan Song, Yudong Wang, Zhifang Sui, Fuli Luo*

#### 🧩 TL;DR
本文提出Rollout Routing Replay (R3)方法来解决混合专家模型在强化学习中路由机制的不稳定性问题，通过记录推理阶段的路由分布并在训练阶段重放，显著降低了训练-推理策略KL散度，有效防止了RL训练崩溃。

---

#### 📘 Detailed Summary
**Motivation:** 混合专家模型中的路由机制在强化学习训练过程中会引入不稳定性，甚至导致灾难性的训练崩溃。研究发现训练和推理阶段存在显著的路由行为不一致性，即使在相同条件下，路由框架也会在重复前向传播中产生不同的专家选择。

**Method:** 提出了Rollout Routing Replay (R3)方法，该方法记录推理引擎中的路由分布并在训练阶段进行重放。R3显著降低了训练-推理策略KL散度，缓解了极端差异，同时不损害训练速度。

**Result:** 在各种设置下的广泛实验证实，R3成功稳定了RL训练，防止了崩溃，并且在性能上超越了GSPO和TIS等方法。该方法有效解决了路由不一致性问题。

**Conclusion:** 这项工作为稳定混合专家模型中的强化学习训练提供了新的解决方案，通过确保训练和推理阶段的路由一致性，从根本上解决了路由机制的不稳定性问题，为MoE模型的RL应用开辟了新的可能性。

---

#### 📄 Abstract
Reinforcement learning (RL) has emerged as a crucial approach for enhancing
the capabilities of large language models. However, in Mixture-of-Experts (MoE)
models, the routing mechanism often introduces instability, even leading to
catastrophic RL training collapse. We analyze the training-inference
consistency of MoE models and identify a notable discrepancy in routing
behaviors between the two phases. Moreover, even under identical conditions,
the routing framework can yield divergent expert selections across repeated
forward passes. To address this foundational inconsistency, we propose Rollout
Routing Replay (R3), a method that records routing distributions from the
inference engine and replays them during training. R3 significantly reduces
training-inference policy KL divergence and mitigates extreme discrepancies
without compromising training speed. Extensive experiments on various settings
confirm that R3 succeeds in stabilizing RL training, preventing collapse and
outperforming methods such as GSPO and TIS. We believe this work can offer a
new solution for stabilizing RL in MoE models.


### [23] [StoryBox: Collaborative Multi-Agent Simulation for Hybrid Bottom-Up Long-Form Story Generation Using Large Language Models](https://arxiv.org/abs/2510.11618)
*Zehao Chen, Rong Pan, Haoran Li*

#### 🧩 TL;DR
本文提出了一种混合自底向上的长文本故事生成方法，通过多智能体模拟实现有机的故事演进。该方法利用智能体在动态沙盒环境中的交互产生涌现事件，能够生成超过10,000字的长篇故事，并在多个指标上达到最先进性能。

---

#### 📘 Detailed Summary
**Motivation:** 传统自上而下的故事生成方法强加刚性结构，限制了故事的有机发展。本研究旨在解决当前故事生成模型在长篇叙事中面临的连贯性和一致性挑战，通过模拟人类作家从整体心理场景出发的创作过程，实现更自然的故事演进。

**Method:** 采用混合自底向上的长文本故事生成框架，基于多智能体模拟技术。智能体在动态沙盒环境中进行交互，其行为和与环境及其他智能体的互动产生涌现事件，这些事件构成故事的基础，支持有机的角色发展和情节推进。

**Result:** 该系统能够生成超过10,000字的长篇故事，同时保持故事的连贯性和一致性。在多个评估指标上实现了最先进的性能表现，证明了该方法在长文本故事生成任务中的有效性。

**Conclusion:** 混合自底向上的方法为创建动态、沉浸式的长篇故事提供了可扩展的创新解决方案。该方法通过智能体驱动的交互实现故事的自然演进，为故事生成领域开辟了新的研究方向，展示了多智能体模拟在创造性写作任务中的潜力。

---

#### 📄 Abstract
Human writers often begin their stories with an overarching mental scene,
where they envision the interactions between characters and their environment.
Inspired by this creative process, we propose a novel approach to long-form
story generation, termed hybrid bottom-up long-form story generation, using
multi-agent simulations. In our method, agents interact within a dynamic
sandbox environment, where their behaviors and interactions with one another
and the environment generate emergent events. These events form the foundation
for the story, enabling organic character development and plot progression.
Unlike traditional top-down approaches that impose rigid structures, our hybrid
bottom-up approach allows for the natural unfolding of events, fostering more
spontaneous and engaging storytelling. The system is capable of generating
stories exceeding 10,000 words while maintaining coherence and consistency,
addressing some of the key challenges faced by current story generation models.
We achieve state-of-the-art performance across several metrics. This approach
offers a scalable and innovative solution for creating dynamic, immersive
long-form stories that evolve organically from agent-driven interactions.


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [24] [Failure-Driven Workflow Refinement](https://arxiv.org/abs/2510.10035)
*Jusheng Zhang, Kaitong Cai, Qinglin Zeng, Ningyuan Liu, Stephen Fan, Ziliang Chen, Keze Wang*

#### 🧩 TL;DR
本文提出了一种新的LLM工作流优化范式，将问题重新概念化为分布优化问题，通过最小化期望失败质量而非最大化标量分数来系统性地学习并重塑失败分布的几何结构。

---

#### 📘 Detailed Summary
**Motivation:** 现有LLM工作流优化方法存在信息坍缩问题，将丰富的多步骤执行轨迹简化为简单的成功/失败信号，导致无法建模工作流的失败分布结构，从根本上限制了优化效果。

**Method:** 提出了CE-Graph框架，通过失败驱动的细化过程来操作化这一范式：从反例池中近似失败分布，识别最密集区域作为重复失败模式，并通过提出-验证机制应用有针对性的操作符约束图编辑来贪婪地减少失败质量。

**Result:** 在数学、代码和问答基准测试中，CE-Graph以显著更低的成本实现了比强基线更高的鲁棒性，证明了该方法在优化效率和效果上的优势。

**Conclusion:** 系统的可靠性并非来自避免失败，而是通过系统性地学习和重塑其失败分布的几何结构来实现，这为LLM工作流优化提供了新的理论基础和方法论框架。

---

#### 📄 Abstract
Optimizing LLM-based workflows is typically formulated as a global search,
where candidate workflows are evaluated based on a scalar metric. This
paradigm, however, suffers from a critical flaw: information collapse. By
reducing rich, multi-step execution traces to simple success/failure signals,
existing methods are rendered blind to the underlying structure of failures,
fundamentally preventing them from modeling the workflow's failure
distribution. We reconceptualize this challenge as a distributional problem. We
propose a new paradigm where the optimization goal is not to maximize a scalar
score, but to directly minimize a workflow's Expected Failure Mass, i.e., the
integral of its failure probability density function defined over a
high-dimensional Failure Signature Space (FSS). This distributional lens allows
us to move from inefficient, zero-order optimization to a principled,
gradient-like descent on the failure landscape itself. We introduce CE-Graph, a
framework that operationalizes this paradigm through a novel, failure-driven
refinement process. CE-Graph approximates the failure distribution from a pool
of counterexamples, identifies its densest regions as recurring failure modes,
and applies targeted, operator-constrained graph edits via a Propose-and-Verify
mechanism to greedily reduce the failure mass. On math, code, and QA
benchmarks, our CE-Graph achieves higher robustness at a significantly lower
cost than strong baselines. This suggests that a system's reliability emerges
not from avoiding failures, but from systematically learning and reshaping the
geometric structure of its failure distributions.


### [25] [SwarmSys: Decentralized Swarm-Inspired Agents for Scalable and Adaptive Reasoning](https://arxiv.org/abs/2510.10047)
*Ruohao Li, Hongjun Liu, Leyi Zhao, Zisu Li, Jiawei Li, Jiajun Jiang, Linning Xu, Chen Zhao, Mingming Fan, Chen Liang*

#### 🧩 TL;DR
SwarmSys是一个受群体智能启发的分布式多智能体推理框架，通过探索者、工作者和验证者三种角色的迭代交互实现闭环推理，在符号推理、研究综合和科学编程任务中显著优于基线方法。该研究表明协调扩展可能成为与模型扩展同等重要的LLM智能发展范式。

---

#### 📘 Detailed Summary
**Motivation:** 现有LLM多智能体框架通常依赖固定角色或集中控制，在长视野推理中限制了可扩展性和适应性。为了解决这些问题，本研究旨在开发一个能够实现分布式、自适应协作的推理框架。

**Method:** SwarmSys框架通过三种专门角色的迭代交互实现协调：探索者、工作者和验证者，它们持续循环执行探索、利用和验证过程。该框架集成了自适应智能体和事件配置文件、基于嵌入的概率匹配以及受信息素启发的强化机制，支持动态任务分配和无全局监督的自组织收敛。

**Result:** 在符号推理、研究综合和科学编程任务上的实验表明，SwarmSys始终优于基线方法，显著提高了准确性和推理稳定性。该框架在各种复杂推理任务中展现出卓越的性能表现。

**Conclusion:** 研究表明群体启发的协调机制是构建可扩展、鲁棒和自适应多智能体推理的有前景范式。协调扩展可能与模型扩展在推进LLM智能方面具有同等重要性，为未来多智能体系统设计提供了新的方向。

---

#### 📄 Abstract
Large language model (LLM) agents have shown remarkable reasoning abilities.
However, existing multi-agent frameworks often rely on fixed roles or
centralized control, limiting scalability and adaptability in long-horizon
reasoning. We introduce SwarmSys, a closed-loop framework for distributed
multi-agent reasoning inspired by swarm intelligence. Coordination in SwarmSys
emerges through iterative interactions among three specialized roles,
Explorers, Workers, and Validators, that continuously cycle through
exploration, exploitation, and validation. To enable scalable and adaptive
collaboration, we integrate adaptive agent and event profiles, embedding-based
probabilistic matching, and a pheromone-inspired reinforcement mechanism,
supporting dynamic task allocation and self-organizing convergence without
global supervision. Across symbolic reasoning, research synthesis, and
scientific programming tasks, SwarmSys consistently outperforms baselines,
improving both accuracy and reasoning stability. These findings highlight
swarm-inspired coordination as a promising paradigm for scalable, robust, and
adaptive multi-agent reasoning, suggesting that coordination scaling may rival
model scaling in advancing LLM intelligence.


### [26] [Traj-CoA: Patient Trajectory Modeling via Chain-of-Agents for Lung Cancer Risk Prediction](https://arxiv.org/abs/2510.10454)
*Sihang Zeng, Yujuan Fu, Sitong Zhou, Zixuan Yu, Lucas Jing Liu, Jun Wen, Matthew Thompson, Ruth Etzioni, Meliha Yetisgen*

#### 🧩 TL;DR
本文提出了Traj-CoA，一种基于多智能体系统的患者轨迹建模方法，通过链式智能体处理电子健康记录的长序列数据，在零样本肺癌风险预测任务中显著优于基线方法。

---

#### 📘 Detailed Summary
**Motivation:** 大型语言模型虽然为患者轨迹建模提供了通用方法，但在处理电子健康记录的长序列和噪声数据时面临时序推理困难，需要解决数据长度和噪声对模型性能的限制问题。

**Method:** Traj-CoA采用多智能体系统架构，包含多个工作智能体按顺序处理可管理的数据块，将关键事件提炼到共享长期记忆模块EHRMem中，最后由管理智能体综合工作智能体的总结和EHRMem中的时间线进行预测。

**Result:** 在基于五年电子健康记录的零样本一年期肺癌风险预测任务中，Traj-CoA在四类基线方法上均表现出优越性能，分析显示该方法展现出与临床对齐的时序推理能力。

**Conclusion:** Traj-CoA为复杂患者轨迹建模提供了一个稳健且可推广的方法，其多智能体架构有效解决了长序列电子健康记录的处理挑战，展示了在医疗时序推理任务中的实用价值。

---

#### 📄 Abstract
Large language models (LLMs) offer a generalizable approach for modeling
patient trajectories, but suffer from the long and noisy nature of electronic
health records (EHR) data in temporal reasoning. To address these challenges,
we introduce Traj-CoA, a multi-agent system involving chain-of-agents for
patient trajectory modeling. Traj-CoA employs a chain of worker agents to
process EHR data in manageable chunks sequentially, distilling critical events
into a shared long-term memory module, EHRMem, to reduce noise and preserve a
comprehensive timeline. A final manager agent synthesizes the worker agents'
summary and the extracted timeline in EHRMem to make predictions. In a
zero-shot one-year lung cancer risk prediction task based on five-year EHR
data, Traj-CoA outperforms baselines of four categories. Analysis reveals that
Traj-CoA exhibits clinically aligned temporal reasoning, establishing it as a
promisingly robust and generalizable approach for modeling complex patient
trajectories.


### [27] [Explainability, risk modeling, and segmentation based customer churn analytics for personalized retention in e-commerce](https://arxiv.org/abs/2510.11604)
*Sanjula De Alwis, Indrajith Ekanayake*

#### 🧩 TL;DR
本研究提出了一个三组件框架，将可解释AI、生存分析和RFM分析相结合，用于客户流失预测和保留策略制定。该框架能够量化特征贡献、建模流失风险时间动态，并识别高价值客户细分，从而支持个性化保留干预。

---

#### 📘 Detailed Summary
**Motivation:** 当前客户流失模型多为黑盒操作，限制了企业对流失驱动因素、干预时机和高风险客户细分的深入理解。研究旨在从单纯预测转向基于可解释证据的个性化保留策略设计，解决传统模型在洞察力和可操作性方面的局限性。

**Method:** 提出三组件框架：使用可解释AI量化特征对流失的贡献度，应用生存分析建模时间到事件的流失风险动态，结合RFM分析根据交易行为对客户进行细分。这些方法协同工作实现流失驱动因素归因、干预窗口估计和目标细分优先级排序。

**Result:** 该框架能够实现流失驱动因素的可解释归因，准确估计保留干预的最佳时间窗口，并有效识别需要优先关注的高风险客户细分。综合方法支持制定减少客户流失和增强客户忠诚度的针对性策略。

**Conclusion:** 研究表明，将可解释性、时间动态分析和行为细分相结合，能够显著提升客户流失管理的战略价值。该框架为从预测性分析转向可操作的保留策略提供了可行路径，强调了解释性在客户关系管理中的关键作用。

---

#### 📄 Abstract
In online retail, customer acquisition typically incurs higher costs than
customer retention, motivating firms to invest in churn analytics. However,
many contemporary churn models operate as opaque black boxes, limiting insight
into the determinants of attrition, the timing of retention opportunities, and
the identification of high-risk customer segments. Accordingly, the emphasis
should shift from prediction alone to the design of personalized retention
strategies grounded in interpretable evidence. This study advances a
three-component framework that integrates explainable AI to quantify feature
contributions, survival analysis to model time-to-event churn risk, and RFM
profiling to segment customers by transactional behaviour. In combination,
these methods enable the attribution of churn drivers, estimation of
intervention windows, and prioritization of segments for targeted actions,
thereby supporting strategies that reduce attrition and strengthen customer
loyalty.
