{"id": "2511.21337", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21337", "abs": "https://arxiv.org/abs/2511.21337", "authors": ["Munish Rathee", "Boris Ba\u010di\u0107", "Maryam Doborjeh"], "title": "Hybrid SIFT-SNN for Efficient Anomaly Detection of Traffic Flow-Control Infrastructure", "comment": "8 pages, 6 figures. This is a preprint of a paper accepted for presentation at the 2025 International Conference on Image and Vision Computing New Zealand (IVCNZ). The final version will appear in IEEE Xplore", "summary": "This paper presents the SIFT-SNN framework, a low-latency neuromorphic signal-processing pipeline for real-time detection of structural anomalies in transport infrastructure. The proposed approach integrates Scale-Invariant Feature Transform (SIFT) for spatial feature encoding with a latency-driven spike conversion layer and a Leaky Integrate-and-Fire (LIF) Spiking Neural Network (SNN) for classification. The Auckland Harbour Bridge dataset is recorded under various weather and lighting conditions, comprising 6,000 labelled frames that include both real and synthetically augmented unsafe cases. The presented system achieves a classification accuracy of 92.3% (+- 0.8%) with a per-frame inference time of 9.5 ms. Achieved sub-10 millisecond latency, combined with sparse spike activity (8.1%), enables real-time, low-power edge deployment. Unlike conventional CNN-based approaches, the hybrid SIFT-SNN pipeline explicitly preserves spatial feature grounding, enhances interpretability, supports transparent decision-making, and operates efficiently on embedded hardware. Although synthetic augmentation improved robustness, generalisation to unseen field conditions remains to be validated. The SIFT-SNN framework is validated through a working prototype deployed on a consumer-grade system and framed as a generalisable case study in structural safety monitoring for movable concrete barriers, which, as a traffic flow-control infrastructure, is deployed in over 20 cities worldwide.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SIFT-SNN\u6846\u67b6\uff0c\u4e00\u79cd\u7528\u4e8e\u4ea4\u901a\u57fa\u7840\u8bbe\u65bd\u7ed3\u6784\u5f02\u5e38\u5b9e\u65f6\u68c0\u6d4b\u7684\u4f4e\u5ef6\u8fdf\u795e\u7ecf\u5f62\u6001\u4fe1\u53f7\u5904\u7406\u7ba1\u9053\uff0c\u901a\u8fc7\u7ed3\u5408\u5c3a\u5ea6\u4e0d\u53d8\u7279\u5f81\u53d8\u6362\u548c\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u4e8692.3%\u7684\u5206\u7c7b\u51c6\u786e\u7387\u548c9.5\u6beb\u79d2\u7684\u63a8\u7406\u65f6\u95f4\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u4f20\u7edf\u57fa\u4e8eCNN\u7684\u65b9\u6cd5\u5728\u5b9e\u65f6\u7ed3\u6784\u5b89\u5168\u76d1\u6d4b\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5305\u62ec\u9ad8\u5ef6\u8fdf\u3001\u9ad8\u529f\u8017\u4ee5\u53ca\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u7b49\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u573a\u666f\u4e0b\u9700\u8981\u4f4e\u5ef6\u8fdf\u548c\u900f\u660e\u51b3\u7b56\u652f\u6301\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6574\u5408\u4e86\u5c3a\u5ea6\u4e0d\u53d8\u7279\u5f81\u53d8\u6362\u7528\u4e8e\u7a7a\u95f4\u7279\u5f81\u7f16\u7801\uff0c\u7ed3\u5408\u5ef6\u8fdf\u9a71\u52a8\u7684\u8109\u51b2\u8f6c\u6362\u5c42\u548c\u6cc4\u6f0f\u79ef\u5206\u53d1\u653e\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u5206\u7c7b\uff0c\u5728\u5965\u514b\u5170\u6d77\u6e2f\u5927\u6865\u6570\u636e\u96c6\u4e0a\u4f7f\u75286000\u4e2a\u6807\u8bb0\u5e27\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5305\u542b\u771f\u5b9e\u548c\u5408\u6210\u589e\u5f3a\u7684\u4e0d\u5b89\u5168\u6848\u4f8b\u3002", "result": "\u7cfb\u7edf\u5b9e\u73b0\u4e8692.3%\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u6bcf\u5e27\u63a8\u7406\u65f6\u95f4\u4e3a9.5\u6beb\u79d2\uff0c\u7a00\u758f\u8109\u51b2\u6d3b\u52a8\u7387\u4e3a8.1%\uff0c\u5408\u6210\u589e\u5f3a\u63d0\u9ad8\u4e86\u9c81\u68d2\u6027\uff0c\u4f46\u5728\u672a\u89c1\u73b0\u573a\u6761\u4ef6\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u4ecd\u9700\u9a8c\u8bc1\u3002", "conclusion": "SIFT-SNN\u6846\u67b6\u5728\u4fdd\u6301\u7a7a\u95f4\u7279\u5f81\u57fa\u7840\u7684\u540c\u65f6\u589e\u5f3a\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u652f\u6301\u900f\u660e\u51b3\u7b56\uff0c\u5e76\u5728\u5d4c\u5165\u5f0f\u786c\u4ef6\u4e0a\u9ad8\u6548\u8fd0\u884c\uff0c\u4f5c\u4e3a\u53ef\u79fb\u52a8\u6df7\u51dd\u571f\u62a4\u680f\u7ed3\u6784\u5b89\u5168\u76d1\u6d4b\u7684\u53ef\u63a8\u5e7f\u6848\u4f8b\u7814\u7a76\uff0c\u5df2\u5728\u5168\u740320\u591a\u4e2a\u57ce\u5e02\u90e8\u7f72\u7684\u4ea4\u901a\u6d41\u63a7\u5236\u57fa\u7840\u8bbe\u65bd\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002"}}
{"id": "2511.21439", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21439", "abs": "https://arxiv.org/abs/2511.21439", "authors": ["Futian Wang", "Fan Zhang", "Xiao Wang", "Mengqi Wang", "Dexing Huang", "Jin Tang"], "title": "EvRainDrop: HyperGraph-guided Completion for Effective Frame and Event Stream Aggregation", "comment": null, "summary": "Event cameras produce asynchronous event streams that are spatially sparse yet temporally dense. Mainstream event representation learning algorithms typically use event frames, voxels, or tensors as input. Although these approaches have achieved notable progress, they struggle to address the undersampling problem caused by spatial sparsity. In this paper, we propose a novel hypergraph-guided spatio-temporal event stream completion mechanism, which connects event tokens across different times and spatial locations via hypergraphs and leverages contextual information message passing to complete these sparse events. The proposed method can flexibly incorporate RGB tokens as nodes in the hypergraph within this completion framework, enabling multi-modal hypergraph-based information completion. Subsequently, we aggregate hypergraph node information across different time steps through self-attention, enabling effective learning and fusion of multi-modal features. Extensive experiments on both single- and multi-label event classification tasks fully validated the effectiveness of our proposed framework. The source code of this paper will be released on https://github.com/Event-AHU/EvRainDrop.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d85\u56fe\u5f15\u5bfc\u7684\u65f6\u7a7a\u4e8b\u4ef6\u6d41\u8865\u5168\u673a\u5236\uff0c\u901a\u8fc7\u8d85\u56fe\u8fde\u63a5\u4e0d\u540c\u65f6\u95f4\u548c\u7a7a\u95f4\u4f4d\u7f6e\u7684\u4e8b\u4ef6\u6807\u8bb0\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u4fe1\u606f\u4f20\u9012\u6765\u8865\u5168\u7a00\u758f\u4e8b\u4ef6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4e8b\u4ef6\u76f8\u673a\u6570\u636e\u7a7a\u95f4\u7a00\u758f\u6027\u5bfc\u81f4\u7684\u6b20\u91c7\u6837\u95ee\u9898\u3002", "motivation": "\u4e3b\u6d41\u4e8b\u4ef6\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u4e8b\u4ef6\u5e27\u3001\u4f53\u7d20\u6216\u5f20\u91cf\u4f5c\u4e3a\u8f93\u5165\uff0c\u867d\u7136\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u96be\u4ee5\u89e3\u51b3\u7531\u7a7a\u95f4\u7a00\u758f\u6027\u5bfc\u81f4\u7684\u6b20\u91c7\u6837\u95ee\u9898\uff0c\u9650\u5236\u4e86\u4e8b\u4ef6\u6570\u636e\u7684\u6709\u6548\u5229\u7528\u548c\u7279\u5f81\u5b66\u4e60\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u8d85\u56fe\u5f15\u5bfc\u7684\u65f6\u7a7a\u4e8b\u4ef6\u6d41\u8865\u5168\u673a\u5236\uff0c\u901a\u8fc7\u8d85\u56fe\u8fde\u63a5\u4e0d\u540c\u65f6\u95f4\u548c\u7a7a\u95f4\u4f4d\u7f6e\u7684\u4e8b\u4ef6\u6807\u8bb0\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u4fe1\u606f\u4f20\u9012\u5b8c\u6210\u7a00\u758f\u4e8b\u4ef6\u8865\u5168\uff1b\u8be5\u6846\u67b6\u53ef\u7075\u6d3b\u96c6\u6210RGB\u6807\u8bb0\u4f5c\u4e3a\u8d85\u56fe\u8282\u70b9\uff0c\u5b9e\u73b0\u591a\u6a21\u6001\u8d85\u56fe\u4fe1\u606f\u8865\u5168\uff0c\u5e76\u901a\u8fc7\u8de8\u65f6\u95f4\u6b65\u7684\u81ea\u6ce8\u610f\u529b\u805a\u5408\u8d85\u56fe\u8282\u70b9\u4fe1\u606f\u3002", "result": "\u5728\u5355\u6807\u7b7e\u548c\u591a\u6807\u7b7e\u4e8b\u4ef6\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u5145\u5206\u9a8c\u8bc1\u4e86\u6240\u63d0\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u5347\u4e8b\u4ef6\u6570\u636e\u7684\u8868\u793a\u5b66\u4e60\u6027\u80fd\u548c\u5904\u7406\u6548\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4e8b\u4ef6\u76f8\u673a\u6570\u636e\u5904\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u8d85\u56fe\u8865\u5168\u8303\u5f0f\uff0c\u901a\u8fc7\u65f6\u7a7a\u4e0a\u4e0b\u6587\u4fe1\u606f\u4f20\u9012\u548c\u591a\u6a21\u6001\u878d\u5408\uff0c\u6709\u6548\u514b\u670d\u4e86\u4e8b\u4ef6\u6d41\u7a7a\u95f4\u7a00\u758f\u6027\u5e26\u6765\u7684\u6311\u6218\uff0c\u4e3a\u4e8b\u4ef6\u8868\u793a\u5b66\u4e60\u5f00\u8f9f\u4e86\u65b0\u7684\u6280\u672f\u8def\u5f84\u3002"}}
