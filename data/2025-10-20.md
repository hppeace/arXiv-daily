<div id=toc></div>

# Table of Contents

- [cs.NE](#cs.NE) [Total: 1]


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [1] [SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware](https://arxiv.org/abs/2510.15542)
*Ivan Kartashov, Mariia Pushkareva, Iakov Karandashev*

#### 🧩 TL;DR
SpikeFit是一种新颖的脉冲神经网络训练方法，通过联合优化离散权重集与硬件约束，实现了在神经形态硬件上的高效推理，同时满足神经元数量、突触连接数和低比特位宽表示等严格硬件要求。

---

#### 📘 Detailed Summary
**Motivation:** 现有脉冲神经网络压缩方法仅能解决数值精度受限或网络神经元数量受限等部分硬件约束问题，无法全面满足神经形态处理器对神经元数量、突触连接数和低比特位宽表示的多重严格要求，限制了SNN在多样化神经形态硬件上的完整部署。

**Method:** SpikeFit提出将允许的权重离散值本身作为可学习参数与模型共同优化，实现低精度（2位、4位或8位）下的最优聚类感知训练，同时引入硬件友好的Fisher脉冲贡献剪枝方法，限制唯一突触连接数量以适应神经形态处理器的要求。

**Result:** 在仅允许四个唯一突触权重值（M=4）的约束下，SpikeFit不仅超越了现有最先进的SNN压缩方法和传统基线方法，还满足了更广泛的神经形态硬件要求，在实验中实现了最低的能耗使用。

**Conclusion:** 该研究表明联合优化离散权重集与硬件约束的方法能够实现更高效的网络压缩，为脉冲神经网络在多样化神经形态处理器上的完整部署提供了有效解决方案，同时提出的FSC剪枝方法展现了最先进的性能表现。

---

#### 📄 Abstract
This paper introduces SpikeFit, a novel training method for Spiking Neural
Networks (SNNs) that enables efficient inference on neuromorphic hardware,
considering all its stringent requirements: the number of neurons and synapses
that can fit on a single device, and lower bit-width representations (e.g.,
4-bit, 8-bit). Unlike conventional compressing approaches that address only a
subset of these requirements (limited numerical precision and limited number of
neurons in the network), SpikeFit treats the allowed weights' discrete values
themselves as learnable parameters co-optimized with the model, allowing for
optimal Clusterization-Aware Training (CAT) of the model's weights at low
precision (2-, 4-, or 8-bit) which results in higher network compression
efficiency, as well as limiting the number of unique synaptic connections to a
value required by neuromorphic processor. This joint optimization allows
SpikeFit to find a discrete weight set aligned with hardware constraints,
enabling the most complete deployment across a broader range of neuromorphic
processors than existing methods of SNN compression support. Moreover, SpikeFit
introduces a new hardware-friendly Fisher Spike Contribution (FSC) pruning
method showing the state-of-the-art performance. We demonstrate that for
spiking neural networks constrained to only four unique synaptic weight values
(M = 4), our SpikeFit method not only outperforms state-of-the-art SNNs
compression methods and conventional baselines combining extreme quantization
schemes and clustering algorithms, but also meets a wider range of neuromorphic
hardware requirements and provides the lowest energy use in experiments.
