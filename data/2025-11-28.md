<div id=toc></div>

# Table of Contents

- [cs.NE](#cs.NE) [Total: 1]


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [1] [Event-driven eligibility propagation in large sparse networks: efficiency shaped by biological realism](https://arxiv.org/abs/2511.21674)
*Agnes Korcsak-Gorzo, JesÃºs A. Espinoza Valverde, Jonas Stapmanns, Hans Ekkehard Plesser, David Dahmen, Matthias Bolten, Sacha J. van Albada, Markus Diesmann*

#### ğŸ§© TL;DR
æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºç”Ÿç‰©å¯å‘çš„èµ„æ ¼ä¼ æ’­å­¦ä¹ è§„åˆ™æ‰©å±•ï¼Œå°†æ—¶é—´é©±åŠ¨æ›´æ–°è½¬æ¢ä¸ºäº‹ä»¶é©±åŠ¨æœºåˆ¶ï¼Œå®ç°äº†å¤§è§„æ¨¡è„‰å†²ç¥ç»ç½‘ç»œçš„é«˜æ•ˆå­¦ä¹ ã€‚è¯¥å·¥ä½œå±•ç¤ºäº†ç”Ÿç‰©çº¦æŸå¦‚ä½•æŒ‡å¯¼è®¡ç®—é«˜æ•ˆAIç®—æ³•çš„è®¾è®¡ï¼Œä¸ºå¯æŒç»­çš„ç”Ÿç‰©å¯å‘AIç³»ç»Ÿé“ºå¹³é“è·¯ã€‚

---

#### ğŸ“˜ Detailed Summary
**Motivation:** å°½ç®¡AIæŠ€æœ¯å–å¾—äº†æ˜¾è‘—è¿›æ­¥ï¼Œä½†ç°æœ‰ç³»ç»Ÿä»å¯ä»ç”Ÿç‰©åŸç†ä¸­è·ç›Šï¼Œç‰¹åˆ«æ˜¯å¾ªç¯è¿æ¥å’Œèƒ½é‡é«˜æ•ˆæœºåˆ¶ã€‚æœ¬ç ”ç©¶æ—¨åœ¨å¼¥åˆæœºå™¨å­¦ä¹ ä¸è®¡ç®—ç¥ç»ç§‘å­¦ä¹‹é—´çš„é¸¿æ²Ÿï¼Œæ¢ç´¢å¦‚ä½•å°†å¤§è„‘çš„ç”Ÿç‰©å­¦ç‰¹å¾è½¬åŒ–ä¸ºè®¡ç®—é«˜æ•ˆçš„AIç®—æ³•è®¾è®¡åŸåˆ™ã€‚

**Method:** æœ¬ç ”ç©¶æå‡ºäº†èµ„æ ¼ä¼ æ’­å­¦ä¹ è§„åˆ™çš„ç”Ÿç‰©å­¦åˆç†æ‰©å±•ï¼Œå°†æ—¶é—´é©±åŠ¨æ›´æ–°æ–¹æ¡ˆè½¬æ¢ä¸ºäº‹ä»¶é©±åŠ¨æœºåˆ¶ã€‚è¯¥æ–¹æ³•æ•´åˆäº†è¿ç»­åŠ¨æ€å’Œæƒé‡æ›´æ–°ã€ä¸¥æ ¼å±€éƒ¨æ€§ä»¥åŠç¨€ç–è¿æ¥ç­‰çªå‡ºç”Ÿç‰©å­¦ç‰¹å¾ï¼Œå¹¶åœ¨å¤§è§„æ¨¡è„‰å†²ç¥ç»ç½‘ç»œä»¿çœŸå¹³å°ä¸Šå®ç°äº†è¯¥å­¦ä¹ è§„åˆ™ã€‚

**Result:** å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç”Ÿç‰©å¯å‘å­¦ä¹ è§„åˆ™èƒ½å¤Ÿæ‰©å±•åˆ°æ•°ç™¾ä¸‡ç¥ç»å…ƒè§„æ¨¡è€Œä¸å½±å“å­¦ä¹ æ€§èƒ½ã€‚åœ¨ç¥ç»å½¢æ€MNISTç­‰ä»»åŠ¡ä¸ŠéªŒè¯äº†å…¶é€‚ç”¨æ€§ï¼Œè¯æ˜äº†ç”Ÿç‰©åŸºç¡€çº¦æŸå¯ä»¥æŒ‡å¯¼è®¡ç®—é«˜æ•ˆAIç®—æ³•çš„è®¾è®¡ã€‚

**Conclusion:** è¿™é¡¹å·¥ä½œä¸ºå¯æŒç»­çš„ç”Ÿç‰©å¯å‘AIç³»ç»Ÿå¼€è¾Ÿäº†é“è·¯ï¼ŒåŒæ—¶æ¨è¿›äº†æˆ‘ä»¬å¯¹ç±»è„‘å­¦ä¹ çš„ç†è§£ã€‚ç ”ç©¶è¡¨æ˜ç”Ÿç‰©çº¦æŸå¯ä»¥æœ‰æ•ˆåœ°æŒ‡å¯¼AIç®—æ³•è®¾è®¡ï¼Œå®ç°è®¡ç®—æ•ˆç‡ä¸å­¦ä¹ æ€§èƒ½çš„å¹³è¡¡ï¼Œä¸ºæœªæ¥ç¥ç»å½¢æ€è®¡ç®—å’ŒèŠ‚èƒ½AIç³»ç»Ÿçš„å‘å±•æä¾›äº†é‡è¦å¯ç¤ºã€‚

---

#### ğŸ“„ Abstract
Despite remarkable technological advances, AI systems may still benefit from biological principles, such as recurrent connectivity and energy-efficient mechanisms. Drawing inspiration from the brain, we present a biologically plausible extension of the eligibility propagation (e-prop) learning rule for recurrent spiking networks. By translating the time-driven update scheme into an event-driven one, we integrate the learning rule into a simulation platform for large-scale spiking neural networks and demonstrate its applicability to tasks such as neuromorphic MNIST. We extend the model with prominent biological features such as continuous dynamics and weight updates, strict locality, and sparse connectivity. Our results show that biologically grounded constraints can inform the design of computationally efficient AI algorithms, offering scalability to millions of neurons without compromising learning performance. This work bridges machine learning and computational neuroscience, paving the way for sustainable, biologically inspired AI systems while advancing our understanding of brain-like learning.
