<div id=toc></div>

# Table of Contents

- [cs.NE](#cs.NE) [Total: 1]


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [1] [A feedback control optimizer for online and hardware-aware training of Spiking Neural Networks](https://arxiv.org/abs/2602.13261)
*Matteo Saponati, Chiara De Luca, Giacomo Indiveri, Benjamin Grewe*

#### ğŸ§© TL;DR
æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºæ··åˆä¿¡å·ç¥ç»å½¢æ€è®¾å¤‡çš„æ–°å‹å°–å³°ç¥ç»ç½‘ç»œå­¦ä¹ ç®—æ³•ï¼Œè¯¥ç®—æ³•é€šè¿‡å°–å³°æ§åˆ¶å™¨ç”Ÿæˆåé¦ˆä¿¡å·æ¥æŒ‡å¯¼ç½‘ç»œæ´»åŠ¨å’Œæƒé‡æ›´æ–°ï¼Œå®ç°äº†å¯æ‰©å±•çš„ç‰‡ä¸Šå­¦ä¹ ï¼Œåœ¨åˆ†ç±»ä»»åŠ¡ä¸Šè¾¾åˆ°ä¸ä¼ ç»Ÿäººå·¥ç¥ç»ç½‘ç»œç›¸å½“çš„æ€§èƒ½ã€‚

---

#### ğŸ“˜ Detailed Summary
**Motivation:** æ··åˆä¿¡å·ç¥ç»å½¢æ€è®¾å¤‡ä¸»è¦ä¾èµ–åŠç›‘ç£æˆ–æ— ç›‘ç£å­¦ä¹ è§„åˆ™ï¼Œè¿™äº›è§„åˆ™åœ¨ç›‘ç£å­¦ä¹ ä»»åŠ¡ä¸­ä¼˜åŒ–ç¡¬ä»¶æ•ˆæœæœ‰é™ï¼Œç¼ºä¹å¯æ‰©å±•çš„ç‰‡ä¸Šå­¦ä¹ è§£å†³æ–¹æ¡ˆé™åˆ¶äº†æ··åˆä¿¡å·è®¾å¤‡åœ¨å¯æŒç»­æ™ºèƒ½è¾¹ç¼˜ç³»ç»Ÿä¸­çš„æ½œåŠ›ï¼Œå› æ­¤éœ€è¦å¼€å‘é€‚ç”¨äºæ­¤ç±»è®¾å¤‡çš„æœ‰æ•ˆå­¦ä¹ ç®—æ³•ã€‚

**Method:** æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹å°–å³°ç¥ç»ç½‘ç»œå­¦ä¹ ç®—æ³•ï¼Œè¯¥ç®—æ³•å°†åŸºäºå°–å³°çš„æƒé‡æ›´æ–°ä¸åé¦ˆæ§åˆ¶ä¿¡å·ç›¸ç»“åˆï¼Œé€šè¿‡å°–å³°æ§åˆ¶å™¨ç”Ÿæˆåé¦ˆä¿¡å·æ¥æŒ‡å¯¼SNNæ´»åŠ¨å¹¶é©±åŠ¨æƒé‡æ›´æ–°ï¼Œå®ç°äº†å¯æ‰©å±•ä¸”å±€éƒ¨çš„ç‰‡ä¸Šå­¦ä¹ æœºåˆ¶ã€‚

**Result:** åœ¨å¤šç§åˆ†ç±»ä»»åŠ¡è¯„ä¼°ä¸­ï¼Œä½¿ç”¨åé¦ˆæ§åˆ¶è®­ç»ƒçš„å•å±‚å°–å³°ç¥ç»ç½‘ç»œè¾¾åˆ°äº†ä¸ä¼ ç»Ÿäººå·¥ç¥ç»ç½‘ç»œç›¸å½“çš„æ€§èƒ½ï¼Œåœ¨æ··åˆä¿¡å·ç¥ç»å½¢æ€è®¾å¤‡ä¸Šçš„è¿ç»­åœ¨çº¿å­¦ä¹ åœºæ™¯æµ‹è¯•è¡¨æ˜ï¼Œè¯¥ç®—æ³•å…·æœ‰è‰¯å¥½çš„ç½‘ç»œæ€§èƒ½å’Œå¯¹è¶…å‚æ•°å¤±é…çš„é²æ£’æ€§ã€‚

**Conclusion:** åé¦ˆæ§åˆ¶ä¼˜åŒ–å™¨ä¸ç¥ç»å½¢æ€åº”ç”¨å…¼å®¹ï¼Œæ¨è¿›äº†è¾¹ç¼˜åº”ç”¨ä¸­å¯æ‰©å±•ç‰‡ä¸Šå­¦ä¹ è§£å†³æ–¹æ¡ˆçš„æ½œåŠ›ï¼Œä¸ºæ··åˆä¿¡å·ç¥ç»å½¢æ€è®¾å¤‡åœ¨å¯æŒç»­æ™ºèƒ½è¾¹ç¼˜ç³»ç»Ÿä¸­çš„å®é™…åº”ç”¨æä¾›äº†å…³é”®æŠ€æœ¯æ”¯æ’‘ã€‚

---

#### ğŸ“„ Abstract
Unlike traditional artificial neural networks (ANNs), biological neuronal networks solve complex cognitive tasks with sparse neuronal activity, recurrent connections, and local learning rules. These mechanisms serve as design principles in Neuromorphic computing, which addresses the critical challenge of energy consumption in modern computing. However, most mixed-signal neuromorphic devices rely on semi- or unsupervised learning rules, which are ineffective for optimizing hardware in supervised learning tasks. This lack of scalable solutions for on-chip learning restricts the potential of mixed-signal devices to enable sustainable, intelligent edge systems. To address these challenges, we present a novel learning algorithm for Spiking Neural Networks (SNNs) on mixed-signal devices that integrates spike-based weight updates with feedback control signals. In our framework, a spiking controller generates feedback signals to guide SNN activity and drive weight updates, enabling scalable and local on-chip learning. We first evaluate the algorithm on various classification tasks, demonstrating that single-layer SNNs trained with feedback control achieve performance comparable to artificial neural networks (ANNs). We then assess its implementation on mixed-signal neuromorphic devices by testing network performance in continuous online learning scenarios and evaluating resilience to hyperparameter mismatches. Our results show that the feedback control optimizer is compatible with neuromorphic applications, advancing the potential for scalable, on-chip learning solutions in edge applications.
