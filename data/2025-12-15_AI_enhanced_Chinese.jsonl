{"id": "2512.11743", "categories": ["cs.NE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11743", "abs": "https://arxiv.org/abs/2512.11743", "authors": ["Yongsheng Huang", "Peibo Duan", "Yujie Wu", "Kai Sun", "Zhipeng Liu", "Changsheng Zhang", "Bin Zhang", "Mingkun Xu"], "title": "CogniSNN: Enabling Neuron-Expandability, Pathway-Reusability, and Dynamic-Configurability with Random Graph Architectures in Spiking Neural Networks", "comment": null, "summary": "Spiking neural networks (SNNs), regarded as the third generation of artificial neural networks, are expected to bridge the gap between artificial intelligence and computational neuroscience. However, most mainstream SNN research directly adopts the rigid, chain-like hierarchical architecture of traditional artificial neural networks (ANNs), ignoring key structural characteristics of the brain. Biological neurons are stochastically interconnected, forming complex neural pathways that exhibit Neuron-Expandability, Pathway-Reusability, and Dynamic-Configurability. In this paper, we introduce a new SNN paradigm, named Cognition-aware SNN (CogniSNN), by incorporating Random Graph Architecture (RGA). Furthermore, we address the issues of network degradation and dimensional mismatch in deep pathways by introducing an improved pure spiking residual mechanism alongside an adaptive pooling strategy. Then, we design a Key Pathway-based Learning without Forgetting (KP-LwF) approach, which selectively reuses critical neural pathways while retaining historical knowledge, enabling efficient multi-task transfer. Finally, we propose a Dynamic Growth Learning (DGL) algorithm that allows neurons and synapses to grow dynamically along the internal temporal dimension. Extensive experiments demonstrate that CogniSNN achieves performance comparable to, or even surpassing, current state-of-the-art SNNs on neuromorphic datasets and Tiny-ImageNet. The Pathway-Reusability enhances the network's continuous learning capability across different scenarios, while the dynamic growth algorithm improves robustness against interference and mitigates the fixed-timestep constraints during neuromorphic chip deployment. This work demonstrates the potential of SNNs with random graph structures in advancing brain-inspired intelligence and lays the foundation for their practical application on neuromorphic hardware.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCogniSNN\u7684\u65b0\u578b\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u8303\u5f0f\uff0c\u901a\u8fc7\u5f15\u5165\u968f\u673a\u56fe\u67b6\u6784\u6765\u6a21\u62df\u751f\u7269\u795e\u7ecf\u7f51\u7edc\u7684\u968f\u673a\u8fde\u63a5\u7279\u6027\uff0c\u5e76\u7ed3\u5408\u6539\u8fdb\u7684\u6b8b\u5dee\u673a\u5236\u3001\u81ea\u9002\u5e94\u6c60\u5316\u7b56\u7565\u3001\u5173\u952e\u8def\u5f84\u5b66\u4e60\u4e0e\u52a8\u6001\u589e\u957f\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86SNN\u7684\u6027\u80fd\u548c\u8fde\u7eed\u5b66\u4e60\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u4e3b\u6d41\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u7814\u7a76\u5927\u591a\u76f4\u63a5\u91c7\u7528\u4f20\u7edf\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u7684\u521a\u6027\u94fe\u5f0f\u5c42\u6b21\u67b6\u6784\uff0c\u5ffd\u89c6\u4e86\u5927\u8111\u7684\u5173\u952e\u7ed3\u6784\u7279\u5f81\uff0c\u5982\u795e\u7ecf\u5143\u7684\u968f\u673a\u4e92\u8fde\u3001\u795e\u7ecf\u901a\u8def\u7684\u590d\u6742\u7f51\u7edc\u7ed3\u6784\u4ee5\u53ca\u795e\u7ecf\u5143\u53ef\u6269\u5c55\u6027\u3001\u901a\u8def\u53ef\u91cd\u7528\u6027\u548c\u52a8\u6001\u53ef\u914d\u7f6e\u6027\u7b49\u7279\u6027\uff0c\u8fd9\u9650\u5236\u4e86SNN\u5728\u8111\u542f\u53d1\u667a\u80fd\u65b9\u9762\u7684\u6f5c\u529b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86CogniSNN\u8303\u5f0f\uff0c\u6838\u5fc3\u65b9\u6cd5\u5305\u62ec\uff1a\u5f15\u5165\u968f\u673a\u56fe\u67b6\u6784\u6a21\u62df\u751f\u7269\u795e\u7ecf\u7f51\u7edc\u7684\u968f\u673a\u8fde\u63a5\uff1b\u8bbe\u8ba1\u6539\u8fdb\u7684\u7eaf\u8109\u51b2\u6b8b\u5dee\u673a\u5236\u548c\u81ea\u9002\u5e94\u6c60\u5316\u7b56\u7565\u89e3\u51b3\u6df1\u5ea6\u901a\u8def\u4e2d\u7684\u7f51\u7edc\u9000\u5316\u548c\u7ef4\u5ea6\u4e0d\u5339\u914d\u95ee\u9898\uff1b\u5f00\u53d1\u57fa\u4e8e\u5173\u952e\u8def\u5f84\u7684\u5b66\u4e60\u4e0d\u9057\u5fd8\u65b9\u6cd5\uff0c\u9009\u62e9\u6027\u91cd\u7528\u5173\u952e\u795e\u7ecf\u901a\u8def\u5e76\u4fdd\u7559\u5386\u53f2\u77e5\u8bc6\uff1b\u63d0\u51fa\u52a8\u6001\u589e\u957f\u5b66\u4e60\u7b97\u6cd5\uff0c\u4f7f\u795e\u7ecf\u5143\u548c\u7a81\u89e6\u80fd\u591f\u6cbf\u5185\u90e8\u65f6\u95f4\u7ef4\u5ea6\u52a8\u6001\u589e\u957f\u3002", "result": "\u5728\u795e\u7ecf\u5f62\u6001\u6570\u636e\u96c6\u548cTiny-ImageNet\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cCogniSNN\u5b9e\u73b0\u4e86\u4e0e\u5f53\u524d\u6700\u5148\u8fdbSNN\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u7684\u6027\u80fd\u3002\u901a\u8def\u53ef\u91cd\u7528\u6027\u589e\u5f3a\u4e86\u7f51\u7edc\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u8fde\u7eed\u5b66\u4e60\u80fd\u529b\uff0c\u800c\u52a8\u6001\u589e\u957f\u7b97\u6cd5\u63d0\u9ad8\u4e86\u5bf9\u6297\u5e72\u6270\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u7f13\u89e3\u4e86\u795e\u7ecf\u5f62\u6001\u82af\u7247\u90e8\u7f72\u4e2d\u7684\u56fa\u5b9a\u65f6\u95f4\u6b65\u7ea6\u675f\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u5177\u6709\u968f\u673a\u56fe\u7ed3\u6784\u7684SNN\u5728\u63a8\u8fdb\u8111\u542f\u53d1\u667a\u80fd\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5e76\u4e3a\u5176\u5728\u795e\u7ecf\u5f62\u6001\u786c\u4ef6\u4e0a\u7684\u5b9e\u9645\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002CogniSNN\u8303\u5f0f\u901a\u8fc7\u6a21\u62df\u751f\u7269\u795e\u7ecf\u7f51\u7edc\u7684\u5173\u952e\u7ed3\u6784\u7279\u5f81\uff0c\u4e3a\u6784\u5efa\u66f4\u63a5\u8fd1\u5927\u8111\u8ba1\u7b97\u539f\u7406\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2512.11510", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2512.11510", "abs": "https://arxiv.org/abs/2512.11510", "authors": ["Hanyue Lou", "Jiayi Zhou", "Yang Zhang", "Boyu Li", "Yi Wang", "Guangnan Ye", "Boxin Shi"], "title": "Reconstruction as a Bridge for Event-Based Visual Question Answering", "comment": null, "summary": "Integrating event cameras with Multimodal Large Language Models (MLLMs) promises general scene understanding in challenging visual conditions, yet requires navigating a trade-off between preserving the unique advantages of event data and ensuring compatibility with frame-based models. We address this challenge by using reconstruction as a bridge, proposing a straightforward Frame-based Reconstruction and Tokenization (FRT) method and designing an efficient Adaptive Reconstruction and Tokenization (ART) method that leverages event sparsity. For robust evaluation, we introduce EvQA, the first objective, real-world benchmark for event-based MLLMs, comprising 1,000 event-Q&A pairs from 22 public datasets. Our experiments demonstrate that our methods achieve state-of-the-art performance on EvQA, highlighting the significant potential of MLLMs in event-based vision.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u4e8b\u4ef6\u76f8\u673a\u4e0e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u5efa\u4f5c\u4e3a\u6865\u6881\uff0c\u8bbe\u8ba1\u4e86FRT\u548cART\u4e24\u79cd\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86\u9996\u4e2a\u5ba2\u89c2\u7684\u57fa\u4e8e\u4e8b\u4ef6\u7684MLLM\u57fa\u51c6EvQA\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u573a\u666f\u7406\u89e3\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u5c06\u4e8b\u4ef6\u76f8\u673a\u4e0e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u6709\u671b\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u89c6\u89c9\u6761\u4ef6\u4e0b\u5b9e\u73b0\u901a\u7528\u573a\u666f\u7406\u89e3\uff0c\u4f46\u9700\u8981\u5728\u4fdd\u7559\u4e8b\u4ef6\u6570\u636e\u72ec\u7279\u4f18\u52bf\u4e0e\u786e\u4fdd\u4e0e\u57fa\u4e8e\u5e27\u7684\u6a21\u578b\u517c\u5bb9\u6027\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\uff0c\u8fd9\u662f\u5f53\u524d\u7814\u7a76\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u4e3b\u8981\u65b9\u6cd5\uff1a\u57fa\u4e8e\u5e27\u7684\u91cd\u5efa\u4e0e\u6807\u8bb0\u5316\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u76f4\u63a5\u7684\u91cd\u5efa\u6865\u6881\u65b9\u6cd5\uff1b\u4ee5\u53ca\u81ea\u9002\u5e94\u91cd\u5efa\u4e0e\u6807\u8bb0\u5316\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u4e8b\u4ef6\u6570\u636e\u7684\u7a00\u758f\u6027\u5b9e\u73b0\u9ad8\u6548\u5904\u7406\u3002\u540c\u65f6\uff0c\u4f5c\u8005\u8fd8\u8bbe\u8ba1\u4e86EvQA\u57fa\u51c6\uff0c\u8fd9\u662f\u9996\u4e2a\u57fa\u4e8e\u4e8b\u4ef6\u7684MLLM\u5ba2\u89c2\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728EvQA\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u8868\u73b0\uff0c\u8be5\u57fa\u51c6\u5305\u542b\u6765\u81ea22\u4e2a\u516c\u5171\u6570\u636e\u96c6\u76841000\u4e2a\u4e8b\u4ef6\u95ee\u7b54\u5bf9\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u5728\u4e8b\u4ef6\u89c6\u89c9\u573a\u666f\u7406\u89e3\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u5c55\u793a\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e8b\u4ef6\u89c6\u89c9\u9886\u57df\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u91cd\u5efa\u6865\u6881\u65b9\u6cd5\u548c\u5168\u9762\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u4e3a\u4e8b\u4ef6\u76f8\u673a\u4e0e\u5148\u8fdbAI\u6a21\u578b\u7684\u96c6\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u5728\u6311\u6218\u6027\u89c6\u89c9\u6761\u4ef6\u4e0b\u7684\u901a\u7528\u573a\u666f\u7406\u89e3\u80fd\u529b\u53d1\u5c55\u3002"}}
