<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models](https://arxiv.org/abs/2512.22046)
*Zongmin Zhang, Zhen Sun, Yifan Liao, Wenhan Dong, Xinlei He, Xingshuo Han, Shengmin Xu, Xinyi Huang*

#### ğŸ§© TL;DR
æœ¬æ–‡æå‡ºäº†BadVSFMï¼Œè¿™æ˜¯é¦–ä¸ªé’ˆå¯¹æç¤ºé©±åŠ¨è§†é¢‘åˆ†å‰²åŸºç¡€æ¨¡å‹ï¼ˆVSFMï¼‰çš„åé—¨æ”»å‡»æ¡†æ¶ï¼Œé€šè¿‡ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥å®ç°äº†å¯¹è§¦å‘æ ·æœ¬çš„å¼ºæ•ˆæ§åˆ¶ï¼ŒåŒæ—¶ä¿æŒå¹²å‡€æ ·æœ¬çš„åˆ†å‰²è´¨é‡ã€‚

---

#### ğŸ“˜ Detailed Summary
**Motivation:** ç ”ç©¶å‘ç°ä¼ ç»Ÿåé—¨æ”»å‡»æ–¹æ³•ï¼ˆå¦‚BadNetï¼‰åœ¨è§†é¢‘åˆ†å‰²åŸºç¡€æ¨¡å‹ä¸Šå‡ ä¹æ— æ•ˆï¼ˆæ”»å‡»æˆåŠŸç‡ä½äº5%ï¼‰ï¼Œè¿™æ˜¯å› ä¸ºä¼ ç»Ÿè®­ç»ƒä¸­å¹²å‡€æ ·æœ¬å’Œè§¦å‘æ ·æœ¬çš„æ¢¯åº¦ä¿æŒé«˜åº¦å¯¹é½ï¼Œæ³¨æ„åŠ›æœºåˆ¶ä»èšç„¦äºçœŸå®ç›®æ ‡ï¼Œå¯¼è‡´ç¼–ç å™¨æ— æ³•å­¦ä¹ åˆ°ä¸è§¦å‘å™¨ç›¸å…³çš„ç‹¬ç‰¹è¡¨ç¤ºï¼Œå› æ­¤éœ€è¦ä¸“é—¨é’ˆå¯¹VSFMç‰¹æ€§çš„åé—¨æ”»å‡»æ¡†æ¶ã€‚

**Method:** BadVSFMé‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼šç¬¬ä¸€é˜¶æ®µå¼•å¯¼å›¾åƒç¼–ç å™¨ï¼Œä½¿è§¦å‘å¸§æ˜ å°„åˆ°æŒ‡å®šçš„ç›®æ ‡åµŒå…¥ï¼Œè€Œå¹²å‡€å¸§ä¿æŒä¸å¹²å‡€å‚è€ƒç¼–ç å™¨å¯¹é½ï¼›ç¬¬äºŒé˜¶æ®µè®­ç»ƒæ©ç è§£ç å™¨ï¼Œç¡®ä¿åœ¨ä¸åŒæç¤ºç±»å‹ä¸‹ï¼Œè§¦å‘å¸§-æç¤ºå¯¹äº§ç”Ÿå…±äº«çš„ç›®æ ‡æ©ç ï¼ŒåŒæ—¶å¹²å‡€è¾“å‡ºä¿æŒæ¥è¿‘å‚è€ƒè§£ç å™¨ã€‚

**Result:** åœ¨ä¸¤ä¸ªæ•°æ®é›†å’Œäº”ä¸ªVSFMä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒBadVSFMåœ¨å¤šç§è§¦å‘å™¨å’Œæç¤ºç±»å‹ä¸‹å®ç°äº†å¼ºå¤§ä¸”å¯æ§çš„åé—¨æ•ˆæœï¼ŒåŒæ—¶ä¿æŒäº†å¹²å‡€åˆ†å‰²è´¨é‡ã€‚æ¶ˆèå®éªŒéªŒè¯äº†ä¸¤é˜¶æ®µè®¾è®¡çš„å¿…è¦æ€§ï¼Œæ¢¯åº¦å†²çªåˆ†æå’Œæ³¨æ„åŠ›å¯è§†åŒ–æ˜¾ç¤ºBadVSFMæˆåŠŸåˆ†ç¦»äº†è§¦å‘å’Œå¹²å‡€è¡¨ç¤ºï¼Œå¹¶å°†æ³¨æ„åŠ›è½¬ç§»åˆ°è§¦å‘åŒºåŸŸï¼Œè€Œå››ç§ä»£è¡¨æ€§é˜²å¾¡æ–¹æ³•åŸºæœ¬æ— æ•ˆã€‚

**Conclusion:** è¯¥ç ”ç©¶æ­ç¤ºäº†å½“å‰è§†é¢‘åˆ†å‰²åŸºç¡€æ¨¡å‹ä¸­å­˜åœ¨æœªè¢«å……åˆ†æ¢ç´¢çš„å®‰å…¨æ¼æ´ï¼ŒBadVSFMæ¡†æ¶çš„æˆåŠŸå®æ–½è¡¨æ˜éœ€è¦é’ˆå¯¹VSFMç‰¹æ€§è®¾è®¡ä¸“é—¨çš„é˜²å¾¡æœºåˆ¶ï¼Œä¸ºæœªæ¥å®‰å…¨ç ”ç©¶æä¾›äº†é‡è¦æ–¹å‘ï¼ŒåŒæ—¶ä¹Ÿå‡¸æ˜¾äº†åŸºç¡€æ¨¡å‹éƒ¨ç½²ä¸­çš„å®é™…å®‰å…¨é£é™©ã€‚

---

#### ğŸ“„ Abstract
Prompt-driven Video Segmentation Foundation Models (VSFMs) such as SAM2 are increasingly deployed in applications like autonomous driving and digital pathology, raising concerns about backdoor threats. Surprisingly, we find that directly transferring classic backdoor attacks (e.g., BadNet) to VSFMs is almost ineffective, with ASR below 5\%. To understand this, we study encoder gradients and attention maps and observe that conventional training keeps gradients for clean and triggered samples largely aligned, while attention still focuses on the true object, preventing the encoder from learning a distinct trigger-related representation. To address this challenge, we propose BadVSFM, the first backdoor framework tailored to prompt-driven VSFMs. BadVSFM uses a two-stage strategy: (1) steer the image encoder so triggered frames map to a designated target embedding while clean frames remain aligned with a clean reference encoder; (2) train the mask decoder so that, across prompt types, triggered frame-prompt pairs produce a shared target mask, while clean outputs stay close to a reference decoder. Extensive experiments on two datasets and five VSFMs show that BadVSFM achieves strong, controllable backdoor effects under diverse triggers and prompts while preserving clean segmentation quality. Ablations over losses, stages, targets, trigger settings, and poisoning rates demonstrate robustness to reasonable hyperparameter changes and confirm the necessity of the two-stage design. Finally, gradient-conflict analysis and attention visualizations show that BadVSFM separates triggered and clean representations and shifts attention to trigger regions, while four representative defenses remain largely ineffective, revealing an underexplored vulnerability in current VSFMs.
