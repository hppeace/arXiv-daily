<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <title>2025-10-22.md</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@5/github-markdown.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
  <style>
    body {
      background-color: #fafafa;
      font-family: 'Inter', sans-serif;
      padding: 2rem;
    }
    .markdown-body {
      max-width: 900px;
      margin: auto;
      background: white;
      padding: 2rem;
      border-radius: 12px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    h1, h2, h3 {
      border-bottom: 1px solid #eaecef;
      padding-bottom: 0.3em;
    }
  </style>
</head>
<body>
  <article class="markdown-body">
    <div id=toc></div>

<h1 id="table-of-contents">Table of Contents</h1>
<ul>
<li><a href="#cs.NE">cs.NE</a> [Total: 1]</li>
</ul>
<div id='cs.NE'></div>

<h1 id="csne-back">cs.NE <a href="#toc">[Back]</a></h1>
<h3 id="1-decoding-listeners-identity-person-identification-from-eeg-signals-using-a-lightweight-spiking-transformer">[1] <a href="https://arxiv.org/abs/2510.17879">Decoding Listeners Identity: Person Identification from EEG Signals Using a Lightweight Spiking Transformer</a></h3>
<p><em>Zheyuan Lin, Siqi Cai, Haizhou Li</em></p>
<h4 id="tldr">ğŸ§© TL;DR</h4>
<p>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºè„‰å†²ç¥ç»ç½‘ç»œå’Œè½»é‡çº§è„‰å†²å˜æ¢å™¨çš„EEGäººå‘˜è¯†åˆ«æ–¹æ³•ï¼Œåœ¨å®ç°100%åˆ†ç±»ç²¾åº¦çš„åŒæ—¶å°†èƒ½è€—é™ä½è‡³ä¼ ç»Ÿæ·±åº¦ç¥ç»ç½‘ç»œçš„10%ä»¥ä¸‹ï¼Œä¸ºé«˜æ•ˆèƒ½è„‘æœºæ¥å£æä¾›äº†æ–°æ–¹å‘ã€‚</p>
<hr />
<h4 id="detailed-summary">ğŸ“˜ Detailed Summary</h4>
<p><strong>Motivation:</strong> ç°æœ‰åŸºäºEEGçš„äººå‘˜è¯†åˆ«æŠ€æœ¯é€šå¸¸ä¾èµ–è®¡ç®—æˆæœ¬é«˜æ˜‚çš„æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œé™åˆ¶äº†å…¶åœ¨å®‰å…¨ã€ä¸ªæ€§åŒ–è„‘æœºæ¥å£å’Œè®¤çŸ¥ç›‘æµ‹ç­‰é¢†åŸŸçš„åº”ç”¨èŒƒå›´ï¼Œå› æ­¤éœ€è¦å¼€å‘æ›´é«˜æ•ˆçš„è¯†åˆ«æ–¹æ³•ã€‚</p>
<p><strong>Method:</strong> æœ¬ç ”ç©¶é‡‡ç”¨è„‰å†²ç¥ç»ç½‘ç»œç»“åˆè½»é‡çº§è„‰å†²å˜æ¢å™¨æ¶æ„ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†EEGä¿¡å·ä¸­å›ºæœ‰çš„æ—¶é—´å¤æ‚æ€§ï¼Œåœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½è®¡ç®—èƒ½è€—ã€‚</p>
<p><strong>Result:</strong> åœ¨EEGéŸ³ä¹æƒ…æ„Ÿè¯†åˆ«æŒ‘æˆ˜æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ‰€ææ¨¡å‹å®ç°äº†100%çš„åˆ†ç±»å‡†ç¡®ç‡ï¼ŒåŒæ—¶èƒ½è€—ä»…ä¸ºä¼ ç»Ÿæ·±åº¦ç¥ç»ç½‘ç»œçš„ä¸åˆ°10%ï¼Œå±•ç°äº†å“è¶Šçš„èƒ½æ•ˆæ¯”ã€‚</p>
<p><strong>Conclusion:</strong> è¯¥ç ”ç©¶ä¸ºå¼€å‘é«˜èƒ½æ•ˆã€é«˜æ€§èƒ½çš„è„‘æœºæ¥å£ç³»ç»Ÿæä¾›äº†æœ‰å‰æ™¯çš„æŠ€æœ¯è·¯å¾„ï¼Œè¯æ˜äº†è„‰å†²ç¥ç»ç½‘ç»œåœ¨ç”Ÿç‰©ä¿¡å·å¤„ç†é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ï¼Œå¹¶ä¸ºèµ„æºå—é™ç¯å¢ƒä¸‹çš„å®æ—¶EEGåˆ†æå¼€è¾Ÿäº†æ–°æ–¹å‘ã€‚</p>
<hr />
<h4 id="abstract">ğŸ“„ Abstract</h4>
<p>EEG-based person identification enables applications in security,
personalized brain-computer interfaces (BCIs), and cognitive monitoring.
However, existing techniques often rely on deep learning architectures at high
computational cost, limiting their scope of applications. In this study, we
propose a novel EEG person identification approach using spiking neural
networks (SNNs) with a lightweight spiking transformer for efficiency and
effectiveness. The proposed SNN model is capable of handling the temporal
complexities inherent in EEG signals. On the EEG-Music Emotion Recognition
Challenge dataset, the proposed model achieves 100% classification accuracy
with less than 10% energy consumption of traditional deep neural networks. This
study offers a promising direction for energy-efficient and high-performance
BCIs. The source code is available at
https://github.com/PatrickZLin/Decode-ListenerIdentity.</p>
  </article>
</body>
</html>
