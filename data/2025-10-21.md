<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 1]
- [cs.NE](#cs.NE) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Exploring The Missing Semantics In Event Modality](https://arxiv.org/abs/2510.17347)
*Jingqian Wu, Shengpeng Xu, Yunbo Jia, Edmund Y. Lam*

#### 🧩 TL;DR
本文提出Semantic-E2VID框架，通过引入跨模态语义对齐机制，将视觉基础模型SAM的语义知识迁移到事件相机视频重建中，显著提升了事件到视频重建的语义信息恢复能力。

---

#### 📘 Detailed Summary
**Motivation:** 事件相机虽然具有低延迟、高动态范围等优势，但事件到视频重建任务面临语义信息缺失的挑战，因为事件相机仅捕获强度变化而忽略静态对象和背景，导致现有E2V方法难以恢复语义内容。

**Method:** 提出Semantic-E2VID框架，包含跨模态特征对齐模块将SAM的视觉语义知识迁移到事件编码器，语义感知特征融合块整合学习到的语义特征形成丰富语义的事件表示，以及语义感知E2V监督机制利用SAM生成的类别标签指导语义细节重建。

**Result:** 在多个基准测试上的广泛实验表明，Semantic-E2VID显著提升了帧质量，在多个指标上超越了最先进的E2V方法，证明了语义信息对事件到视频重建的重要性。

**Conclusion:** 该研究证明了将视觉基础模型的语义知识迁移到事件模态的有效性，为事件相机视觉任务提供了新的语义增强范式，未来可扩展到其他事件视觉任务中提升性能。

---

#### 📄 Abstract
Event cameras offer distinct advantages such as low latency, high dynamic
range, and efficient motion capture. However, event-to-video reconstruction
(E2V), a fundamental event-based vision task, remains challenging, particularly
for reconstructing and recovering semantic information. This is primarily due
to the nature of the event camera, as it only captures intensity changes,
ignoring static objects and backgrounds, resulting in a lack of semantic
information in captured event modality. Further, semantic information plays a
crucial role in video and frame reconstruction, yet is often overlooked by
existing E2V approaches. To bridge this gap, we propose Semantic-E2VID, an E2V
framework that explores the missing visual semantic knowledge in event modality
and leverages it to enhance event-to-video reconstruction. Specifically,
Semantic-E2VID introduces a cross-modal feature alignment (CFA) module to
transfer the robust visual semantics from a frame-based vision foundation
model, the Segment Anything Model (SAM), to the event encoder, while aligning
the high-level features from distinct modalities. To better utilize the learned
semantic feature, we further propose a semantic-aware feature fusion (SFF)
block to integrate learned semantics in frame modality to form event
representations with rich semantics that can be decoded by the event decoder.
Further, to facilitate the reconstruction of semantic information, we propose a
novel Semantic Perceptual E2V Supervision that helps the model to reconstruct
semantic details by leveraging SAM-generated categorical labels. Extensive
experiments demonstrate that Semantic-E2VID significantly enhances frame
quality, outperforming state-of-the-art E2V methods across multiple benchmarks.
The sample code is included in the supplementary material.


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [2] [ReLACE: A Resource-Efficient Low-Latency Cortical Acceleration Engine](https://arxiv.org/abs/2510.17392)
*Sonu Kumar, Arjun S. Nair, Bhawna Chaudhary, Mukul Lokhande, Santosh Kumar Vishvakarma*

#### 🧩 TL;DR
本文提出了一种基于CORDIC的Hodgkin Huxley神经元模型和皮质神经池架构，实现了生物精确、低资源消耗的脉冲神经网络，在FPGA上相比现有技术实现了显著的资源优化和性能提升。该设计为资源受限的边缘AI应用提供了高效的SNN实现方案。

---

#### 📘 Detailed Summary
**Motivation:** 当前基于CORDIC的深度神经网络方法存在资源共享和性能限制的问题，无法满足资源受限边缘AI应用对生物精确脉冲神经网络的需求。本研究旨在开发一种高效、低资源的SNN实现方案，解决现有设计在计算效率和资源利用率方面的不足。

**Method:** 提出了一种皮质神经池架构，采用模块化和性能优化的CORDIC级联结构，设计了高速、资源高效的基于CORDIC的Hodgkin Huxley神经元模型。该模型通过延迟-面积权衡优化，实现了比共享CORDIC方法更好的性能表现。

**Result:** FPGA实现显示，RCHH神经元相比最先进设计减少了24.5%的LUT使用，速度提升35.2%，归一化均方根误差改善70%。皮质神经池在MNIST数据集上实现了2.85倍吞吐量提升，达到12.69 GOPS，与等效DNN相比精度仅下降0.35%。

**Conclusion:** 该研究证明了基于CORDIC的Hodgkin Huxley神经元模型能够实现生物精确且资源高效的SNN实现，为边缘AI应用提供了可行的解决方案。架构的模块化设计和性能优化策略为未来低功耗神经形态计算系统的发展提供了重要参考。

---

#### 📄 Abstract
We present a Cortical Neural Pool (CNP) architecture featuring a high-speed,
resource-efficient CORDIC-based Hodgkin Huxley (RCHH) neuron model. Unlike
shared CORDIC-based DNN approaches, the proposed neuron leverages modular and
performance-optimised CORDIC stages with a latency-area trade-off. The FPGA
implementation of the RCHH neuron shows 24.5% LUT reduction and 35.2% improved
speed, compared to SoTA designs, with 70% better normalised root mean square
error (NRMSE). Furthermore, the CNP exhibits 2.85x higher throughput (12.69
GOPS) compared to a functionally equivalent CORDIC-based DNN engine, with only
a 0.35% accuracy drop compared to the DNN counterpart on the MNIST dataset. The
overall results indicate that the design shows biologically accurate,
low-resource spiking neural network implementations for resource-constrained
edge AI applications.


### [3] [A Multi-Threading Kernel for Enabling Neuromorphic Edge Applications](https://arxiv.org/abs/2510.17745)
*Lars Niedermeier, Vyom Shah, Jeffrey L. Krichmar*

#### 🧩 TL;DR
本文提出了一种多线程内核，使脉冲神经网络能够在边缘设备上高效运行，实现了4倍的加速比和70%的能效提升，支持低SWaP的神经形态应用开发。

---

#### 📘 Detailed Summary
**Motivation:** 当前神经形态应用在边缘计算环境中面临处理效率低和能耗高的问题，需要解决在无云服务依赖条件下直接处理感官输入的挑战，以及多核处理器的负载均衡优化需求。

**Method:** 研究开发了一种多线程内核技术，专门针对脉冲神经网络的稀疏事件驱动特性进行优化，实现了在多核ARM处理器上的动态负载均衡，取代了传统的静态核心分配方式。

**Result:** 实验结果显示，该内核在中等规模SNN上实现了4倍的加速比，在Synfire网络上达到1.7倍加速，相比静态核心分配能耗降低70%，有效平衡了多核处理器的所有可用核心。

**Conclusion:** 这项工作为开发低尺寸、重量和功耗的边缘神经形态应用提供了关键技术支撑，同时为神经形态芯片的集成原型设计奠定了基础，推动了边缘AI计算的发展。

---

#### 📄 Abstract
Spiking Neural Networks (SNNs) have sparse, event driven processing that can
leverage neuromorphic applications. In this work, we introduce a
multi-threading kernel that enables neuromorphic applications running at the
edge, meaning they process sensory input directly and without any up-link to or
dependency on a cloud service. The kernel shows speed-up gains over single
thread processing by a factor of four on moderately sized SNNs and 1.7X on a
Synfire network. Furthermore, it load-balances all cores available on
multi-core processors, such as ARM, which run today's mobile devices and is up
to 70% more energy efficient compared to statical core assignment. The present
work can enable the development of edge applications that have low Size,
Weight, and Power (SWaP), and can prototype the integration of neuromorphic
chips.
