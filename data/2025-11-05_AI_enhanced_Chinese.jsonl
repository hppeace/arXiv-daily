{"id": "2511.02180", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.02180", "abs": "https://arxiv.org/abs/2511.02180", "authors": ["Mehdi Sefidgar Dilmaghani", "Waseem Shariff", "Cian Ryan", "Joe Lemley", "Peter Corcoran"], "title": "Autobiasing Event Cameras for Flickering Mitigation", "comment": null, "summary": "Understanding and mitigating flicker effects caused by rapid variations in\nlight intensity is critical for enhancing the performance of event cameras in\ndiverse environments. This paper introduces an innovative autonomous mechanism\nfor tuning the biases of event cameras, effectively addressing flicker across a\nwide frequency range -25 Hz to 500 Hz. Unlike traditional methods that rely on\nadditional hardware or software for flicker filtering, our approach leverages\nthe event cameras inherent bias settings. Utilizing a simple Convolutional\nNeural Networks -CNNs, the system identifies instances of flicker in a spatial\nspace and dynamically adjusts specific biases to minimize its impact. The\nefficacy of this autobiasing system was robustly tested using a face detector\nframework under both well-lit and low-light conditions, as well as across\nvarious frequencies. The results demonstrated significant improvements:\nenhanced YOLO confidence metrics for face detection, and an increased\npercentage of frames capturing detected faces. Moreover, the average gradient,\nwhich serves as an indicator of flicker presence through edge detection,\ndecreased by 38.2 percent in well-lit conditions and by 53.6 percent in\nlow-light conditions. These findings underscore the potential of our approach\nto significantly improve the functionality of event cameras in a range of\nadverse lighting scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u81ea\u9002\u5e94\u504f\u7f6e\u8c03\u8282\u673a\u5236\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u4e8b\u4ef6\u76f8\u673a\u7684\u504f\u7f6e\u8bbe\u7f6e\u6765\u6291\u523625-500Hz\u8303\u56f4\u5185\u7684\u95ea\u70c1\u6548\u5e94\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e8b\u4ef6\u76f8\u673a\u5728\u590d\u6742\u5149\u7167\u73af\u5883\u4e0b\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u4e8b\u4ef6\u76f8\u673a\u5728\u52a8\u6001\u5149\u7167\u73af\u5883\u4e2d\u5bb9\u6613\u53d7\u5230\u95ea\u70c1\u6548\u5e94\u7684\u5f71\u54cd\uff0c\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u989d\u5916\u786c\u4ef6\u6216\u8f6f\u4ef6\u6ee4\u6ce2\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528\u4e8b\u4ef6\u76f8\u673a\u56fa\u6709\u7684\u504f\u7f6e\u8bbe\u7f6e\u81ea\u4e3b\u89e3\u51b3\u95ea\u70c1\u95ee\u9898\uff0c\u63d0\u5347\u5176\u5728\u591a\u6837\u5316\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u3002", "method": "\u91c7\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5728\u7a7a\u95f4\u57df\u8bc6\u522b\u95ea\u70c1\u73b0\u8c61\uff0c\u5e76\u52a8\u6001\u8c03\u8282\u4e8b\u4ef6\u76f8\u673a\u7684\u7279\u5b9a\u504f\u7f6e\u53c2\u6570\uff0c\u901a\u8fc7\u81ea\u504f\u7f6e\u7cfb\u7edf\u5b9e\u73b0\u65e0\u9700\u5916\u90e8\u5e72\u9884\u7684\u95ea\u70c1\u6291\u5236\u3002", "result": "\u5728\u4eba\u8138\u68c0\u6d4b\u6846\u67b6\u4e0b\u9a8c\u8bc1\u663e\u793a\uff0cYOLO\u7f6e\u4fe1\u5ea6\u663e\u8457\u63d0\u5347\uff0c\u68c0\u6d4b\u5230\u4eba\u8138\u7684\u5e27\u6bd4\u4f8b\u589e\u52a0\uff0c\u5e73\u5747\u68af\u5ea6\u6307\u6807\u5728\u826f\u597d\u5149\u7167\u4e0b\u964d\u4f4e38.2%\uff0c\u4f4e\u5149\u6761\u4ef6\u4e0b\u964d\u4f4e53.6%\uff0c\u6709\u6548\u6307\u793a\u4e86\u95ea\u70c1\u6291\u5236\u6548\u679c\u3002", "conclusion": "\u8be5\u81ea\u504f\u7f6e\u65b9\u6cd5\u8bc1\u660e\u4e86\u901a\u8fc7\u667a\u80fd\u8c03\u8282\u4e8b\u4ef6\u76f8\u673a\u5185\u90e8\u53c2\u6570\u53ef\u6709\u6548\u5e94\u5bf9\u590d\u6742\u5149\u7167\u6311\u6218\uff0c\u4e3a\u4e8b\u4ef6\u76f8\u673a\u5728\u6076\u52a3\u5149\u7167\u6761\u4ef6\u4e0b\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u548c\u91cd\u8981\u6280\u672f\u652f\u6491\u3002"}}
