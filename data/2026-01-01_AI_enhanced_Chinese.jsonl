{"id": "2512.23950", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2512.23950", "abs": "https://arxiv.org/abs/2512.23950", "authors": ["Huibin Li", "Haoran Liu", "Mingzhe Liu", "Yulong Xiao", "Peng Li", "Guibin Zan"], "title": "U-Net-Like Spiking Neural Networks for Single Image Dehazing", "comment": "9 pages, 4 figures. Accepted at IJCNN 2025 (Rome, Italy). To appear in IEEE/IJCNN 2025 proceedings", "summary": "Image dehazing is a critical challenge in computer vision, essential for enhancing image clarity in hazy conditions. Traditional methods often rely on atmospheric scattering models, while recent deep learning techniques, specifically Convolutional Neural Networks (CNNs) and Transformers, have improved performance by effectively analyzing image features. However, CNNs struggle with long-range dependencies, and Transformers demand significant computational resources. To address these limitations, we propose DehazeSNN, an innovative architecture that integrates a U-Net-like design with Spiking Neural Networks (SNNs). DehazeSNN captures multi-scale image features while efficiently managing local and long-range dependencies. The introduction of the Orthogonal Leaky-Integrate-and-Fire Block (OLIFBlock) enhances cross-channel communication, resulting in superior dehazing performance with reduced computational burden. Our extensive experiments show that DehazeSNN is highly competitive to state-of-the-art methods on benchmark datasets, delivering high-quality haze-free images with a smaller model size and less multiply-accumulate operations. The proposed dehazing method is publicly available at https://github.com/HaoranLiu507/DehazeSNN.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDehazeSNN\uff0c\u4e00\u79cd\u5c06U-Net\u67b6\u6784\u4e0e\u8109\u51b2\u795e\u7ecf\u7f51\u7edc(SNN)\u76f8\u7ed3\u5408\u7684\u65b0\u578b\u56fe\u50cf\u53bb\u96fe\u65b9\u6cd5\uff0c\u901a\u8fc7\u6b63\u4ea4\u6cc4\u6f0f\u79ef\u5206\u53d1\u653e\u5757(OLIFBlock)\u589e\u5f3a\u8de8\u901a\u9053\u901a\u4fe1\uff0c\u5728\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u53bb\u96fe\u3002", "motivation": "\u56fe\u50cf\u53bb\u96fe\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u5927\u6c14\u6563\u5c04\u6a21\u578b\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5982CNN\u548cTransformer\u867d\u63d0\u5347\u4e86\u6027\u80fd\u4f46\u5b58\u5728\u5c40\u9650\uff1aCNN\u96be\u4ee5\u5904\u7406\u957f\u7a0b\u4f9d\u8d56\uff0cTransformer\u5219\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u6709\u6548\u6355\u83b7\u591a\u5c3a\u5ea6\u7279\u5f81\u53c8\u80fd\u964d\u4f4e\u8ba1\u7b97\u8d1f\u62c5\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51faDehazeSNN\u67b6\u6784\uff0c\u91c7\u7528U-Net\u5f0f\u8bbe\u8ba1\u96c6\u6210\u8109\u51b2\u795e\u7ecf\u7f51\u7edc(SNN)\uff0c\u6709\u6548\u6355\u83b7\u591a\u5c3a\u5ea6\u56fe\u50cf\u7279\u5f81\u5e76\u7ba1\u7406\u5c40\u90e8\u4e0e\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\uff0c\u901a\u8fc7\u5f15\u5165\u6b63\u4ea4\u6cc4\u6f0f\u79ef\u5206\u53d1\u653e\u5757(OLIFBlock)\u589e\u5f3a\u8de8\u901a\u9053\u901a\u4fe1\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cDehazeSNN\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u6bd4\u5177\u6709\u9ad8\u5ea6\u7ade\u4e89\u529b\uff0c\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u65e0\u96fe\u56fe\u50cf\uff0c\u540c\u65f6\u6a21\u578b\u5c3a\u5bf8\u66f4\u5c0f\u4e14\u4e58\u79ef\u7d2f\u52a0\u8fd0\u7b97(MAC)\u66f4\u5c11\uff0c\u5b9e\u73b0\u4e86\u8ba1\u7b97\u6548\u7387\u4e0e\u53bb\u96fe\u6027\u80fd\u7684\u826f\u597d\u5e73\u8861\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86SNN\u5728\u56fe\u50cf\u53bb\u96fe\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u8ba1\u7b97\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4e3a\u672a\u6765\u4f4e\u529f\u8017\u89c6\u89c9\u5e94\u7528\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u540c\u65f6\u516c\u5f00\u7684\u4ee3\u7801\u5e93\u4fc3\u8fdb\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u4e0e\u590d\u73b0\u3002"}}
{"id": "2512.24243", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2512.24243", "abs": "https://arxiv.org/abs/2512.24243", "authors": ["Fuqiang Gu", "Yuanke Li", "Xianlei Long", "Kangping Ji", "Chao Chen", "Qingyi Gu", "Zhenliang Ni"], "title": "MambaSeg: Harnessing Mamba for Accurate and Efficient Image-Event Semantic Segmentation", "comment": "Accepted by AAAI 2026", "summary": "Semantic segmentation is a fundamental task in computer vision with wide-ranging applications, including autonomous driving and robotics. While RGB-based methods have achieved strong performance with CNNs and Transformers, their effectiveness degrades under fast motion, low-light, or high dynamic range conditions due to limitations of frame cameras. Event cameras offer complementary advantages such as high temporal resolution and low latency, yet lack color and texture, making them insufficient on their own. To address this, recent research has explored multimodal fusion of RGB and event data; however, many existing approaches are computationally expensive and focus primarily on spatial fusion, neglecting the temporal dynamics inherent in event streams. In this work, we propose MambaSeg, a novel dual-branch semantic segmentation framework that employs parallel Mamba encoders to efficiently model RGB images and event streams. To reduce cross-modal ambiguity, we introduce the Dual-Dimensional Interaction Module (DDIM), comprising a Cross-Spatial Interaction Module (CSIM) and a Cross-Temporal Interaction Module (CTIM), which jointly perform fine-grained fusion along both spatial and temporal dimensions. This design improves cross-modal alignment, reduces ambiguity, and leverages the complementary properties of each modality. Extensive experiments on the DDD17 and DSEC datasets demonstrate that MambaSeg achieves state-of-the-art segmentation performance while significantly reducing computational cost, showcasing its promise for efficient, scalable, and robust multimodal perception.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86MambaSeg\uff0c\u4e00\u79cd\u65b0\u9896\u7684\u53cc\u5206\u652f\u8bed\u4e49\u5206\u5272\u6846\u67b6\uff0c\u91c7\u7528\u5e76\u884cMamba\u7f16\u7801\u5668\u9ad8\u6548\u5efa\u6a21RGB\u56fe\u50cf\u548c\u4e8b\u4ef6\u6d41\uff0c\u5e76\u901a\u8fc7\u53cc\u7ef4\u4ea4\u4e92\u6a21\u5757\u5b9e\u73b0\u7a7a\u95f4\u548c\u65f6\u95f4\u7ef4\u5ea6\u7684\u7ec6\u7c92\u5ea6\u878d\u5408\uff0c\u5728\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "RGB\u76f8\u673a\u5728\u5feb\u901f\u8fd0\u52a8\u3001\u4f4e\u5149\u7167\u6216\u9ad8\u52a8\u6001\u8303\u56f4\u6761\u4ef6\u4e0b\u6027\u80fd\u4e0b\u964d\uff0c\u800c\u4e8b\u4ef6\u76f8\u673a\u867d\u7136\u5177\u6709\u9ad8\u65f6\u95f4\u5206\u8fa8\u7387\u548c\u4f4e\u5ef6\u8fdf\u4f18\u52bf\uff0c\u4f46\u7f3a\u4e4f\u989c\u8272\u548c\u7eb9\u7406\u4fe1\u606f\u3002\u73b0\u6709RGB\u4e0e\u4e8b\u4ef6\u6570\u636e\u878d\u5408\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u4e3b\u8981\u5173\u6ce8\u7a7a\u95f4\u878d\u5408\uff0c\u5ffd\u7565\u4e86\u4e8b\u4ef6\u6d41\u56fa\u6709\u7684\u65f6\u95f4\u52a8\u6001\u7279\u6027\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u5168\u9762\u7684\u8de8\u6a21\u6001\u878d\u5408\u65b9\u6cd5\u3002", "method": "MambaSeg\u91c7\u7528\u5e76\u884cMamba\u7f16\u7801\u5668\u5206\u522b\u5904\u7406RGB\u56fe\u50cf\u548c\u4e8b\u4ef6\u6d41\uff0c\u5e76\u5f15\u5165\u53cc\u7ef4\u4ea4\u4e92\u6a21\u5757\uff08DDIM\uff09\u5305\u542b\u8de8\u7a7a\u95f4\u4ea4\u4e92\u6a21\u5757\uff08CSIM\uff09\u548c\u8de8\u65f6\u95f4\u4ea4\u4e92\u6a21\u5757\uff08CTIM\uff09\uff0c\u5728\u7a7a\u95f4\u548c\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u8054\u5408\u6267\u884c\u7ec6\u7c92\u5ea6\u878d\u5408\uff0c\u6539\u5584\u8de8\u6a21\u6001\u5bf9\u9f50\u5e76\u51cf\u5c11\u6a21\u7cca\u6027\u3002", "result": "\u5728DDD17\u548cDSEC\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cMambaSeg\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u8bed\u4e49\u5206\u5272\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u5c55\u793a\u4e86\u5176\u5728\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u548c\u9c81\u68d2\u7684\u591a\u6a21\u6001\u611f\u77e5\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u901a\u8fc7\u5e76\u884cMamba\u7f16\u7801\u5668\u548c\u53cc\u7ef4\u4ea4\u4e92\u6a21\u5757\u53ef\u4ee5\u6709\u6548\u878d\u5408RGB\u548c\u4e8b\u4ef6\u6570\u636e\u7684\u4e92\u8865\u7279\u6027\uff0c\u4e3a\u9ad8\u6548\u7684\u591a\u6a21\u6001\u611f\u77e5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u8ba1\u7b97\u8d44\u6e90\u53d7\u9650\u7684\u5b9e\u65f6\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
