{"id": "2602.23101", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.23101", "abs": "https://arxiv.org/abs/2602.23101", "authors": ["Paul Kielty", "Timothy Hanley", "Peter Corcoran"], "title": "Locally Adaptive Decay Surfaces for High-Speed Face and Landmark Detection with Event Cameras", "comment": null, "summary": "Event cameras record luminance changes with microsecond resolution, but converting their sparse, asynchronous output into dense tensors that neural networks can exploit remains a core challenge. Conventional histograms or globally-decayed time-surface representations apply fixed temporal parameters across the entire image plane, which in practice creates a trade-off between preserving spatial structure during still periods and retaining sharp edges during rapid motion. We introduce Locally Adaptive Decay Surfaces (LADS), a family of event representations in which the temporal decay at each location is modulated according to local signal dynamics. Three strategies are explored, based on event rate, Laplacian-of-Gaussian response, and high-frequency spectral energy. These adaptive schemes preserve detail in quiescent regions while reducing blur in regions of dense activity. Extensive experiments on the public data show that LADS consistently improves both face detection and facial landmark accuracy compared to standard non-adaptive representations. At 30 Hz, LADS achieves higher detection accuracy and lower landmark error than either baseline, and at 240 Hz it mitigates the accuracy decline typically observed at higher frequencies, sustaining 2.44 % normalized mean error for landmarks and 0.966 mAP50 in face detection. These high-frequency results even surpass the accuracy reported in prior works operating at 30 Hz, setting new benchmarks for event-based face analysis. Moreover, by preserving spatial structure at the representation stage, LADS supports the use of much lighter network architectures while still retaining real-time performance. These results highlight the importance of context-aware temporal integration for neuromorphic vision and point toward real-time, high-frequency human-computer interaction systems that exploit the unique advantages of event cameras.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5c40\u90e8\u81ea\u9002\u5e94\u8870\u51cf\u8868\u9762\uff08LADS\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u578b\u4e8b\u4ef6\u76f8\u673a\u8868\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u6839\u636e\u5c40\u90e8\u4fe1\u53f7\u52a8\u6001\u8c03\u5236\u6bcf\u4e2a\u4f4d\u7f6e\u7684\u65f6\u95f4\u8870\u51cf\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u56fa\u5b9a\u65f6\u95f4\u53c2\u6570\u8868\u793a\u5728\u9759\u6001\u533a\u57df\u548c\u5feb\u901f\u8fd0\u52a8\u533a\u57df\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u4e8b\u4ef6\u76f8\u673a\u4ee5\u5fae\u79d2\u7ea7\u5206\u8fa8\u7387\u8bb0\u5f55\u4eae\u5ea6\u53d8\u5316\uff0c\u4f46\u5c06\u5176\u7a00\u758f\u5f02\u6b65\u8f93\u51fa\u8f6c\u6362\u4e3a\u795e\u7ecf\u7f51\u7edc\u53ef\u5229\u7528\u7684\u5bc6\u96c6\u5f20\u91cf\u4ecd\u662f\u4e00\u4e2a\u6838\u5fc3\u6311\u6218\u3002\u4f20\u7edf\u76f4\u65b9\u56fe\u6216\u5168\u5c40\u8870\u51cf\u65f6\u95f4\u8868\u9762\u8868\u793a\u5728\u6574\u4e2a\u56fe\u50cf\u5e73\u9762\u4e0a\u5e94\u7528\u56fa\u5b9a\u7684\u65f6\u95f4\u53c2\u6570\uff0c\u8fd9\u5728\u5b9e\u9645\u4e2d\u9020\u6210\u4e86\u5728\u9759\u6b62\u671f\u95f4\u4fdd\u7559\u7a7a\u95f4\u7ed3\u6784\u4e0e\u5728\u5feb\u901f\u8fd0\u52a8\u671f\u95f4\u4fdd\u7559\u6e05\u6670\u8fb9\u7f18\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "method": "\u672c\u6587\u5f15\u5165\u4e86\u5c40\u90e8\u81ea\u9002\u5e94\u8870\u51cf\u8868\u9762\uff08LADS\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u4e8b\u4ef6\u8868\u793a\u65b9\u6cd5\u5bb6\u65cf\uff0c\u5176\u4e2d\u6bcf\u4e2a\u4f4d\u7f6e\u7684\u65f6\u95f4\u8870\u51cf\u6839\u636e\u5c40\u90e8\u4fe1\u53f7\u52a8\u6001\u8fdb\u884c\u8c03\u5236\u3002\u63a2\u7d22\u4e86\u4e09\u79cd\u7b56\u7565\uff1a\u57fa\u4e8e\u4e8b\u4ef6\u7387\u3001\u62c9\u666e\u62c9\u65af-\u9ad8\u65af\u54cd\u5e94\u548c\u9ad8\u9891\u9891\u8c31\u80fd\u91cf\u3002\u8fd9\u4e9b\u81ea\u9002\u5e94\u65b9\u6848\u5728\u9759\u6b62\u533a\u57df\u4fdd\u7559\u7ec6\u8282\uff0c\u540c\u65f6\u5728\u5bc6\u96c6\u6d3b\u52a8\u533a\u57df\u51cf\u5c11\u6a21\u7cca\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cLADS\u76f8\u6bd4\u6807\u51c6\u975e\u81ea\u9002\u5e94\u8868\u793a\u6301\u7eed\u6539\u5584\u4e86\u4eba\u8138\u68c0\u6d4b\u548c\u9762\u90e8\u5173\u952e\u70b9\u51c6\u786e\u6027\u3002\u572830Hz\u4e0b\uff0cLADS\u5b9e\u73b0\u4e86\u6bd4\u57fa\u7ebf\u66f4\u9ad8\u7684\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u66f4\u4f4e\u7684\u5173\u952e\u70b9\u8bef\u5dee\uff1b\u5728240Hz\u4e0b\uff0c\u5b83\u7f13\u89e3\u4e86\u901a\u5e38\u5728\u9ad8\u9891\u4e0b\u89c2\u5bdf\u5230\u7684\u51c6\u786e\u6027\u4e0b\u964d\uff0c\u7ef4\u6301\u4e862.44%\u7684\u5f52\u4e00\u5316\u5e73\u5747\u8bef\u5dee\u7528\u4e8e\u5173\u952e\u70b9\u548c0.966 mAP50\u7528\u4e8e\u4eba\u8138\u68c0\u6d4b\u3002\u8fd9\u4e9b\u9ad8\u9891\u7ed3\u679c\u751a\u81f3\u8d85\u8fc7\u4e86\u5148\u524d\u5de5\u4f5c\u572830Hz\u4e0b\u62a5\u544a\u7684\u51c6\u786e\u6027\uff0c\u4e3a\u57fa\u4e8e\u4e8b\u4ef6\u7684\u4eba\u8138\u5206\u6790\u8bbe\u5b9a\u4e86\u65b0\u57fa\u51c6\u3002", "conclusion": "\u901a\u8fc7\u5728\u8868\u793a\u9636\u6bb5\u4fdd\u7559\u7a7a\u95f4\u7ed3\u6784\uff0cLADS\u652f\u6301\u4f7f\u7528\u66f4\u8f7b\u91cf\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u540c\u65f6\u4ecd\u4fdd\u6301\u5b9e\u65f6\u6027\u80fd\u3002\u8fd9\u4e9b\u7ed3\u679c\u7a81\u663e\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u65f6\u95f4\u96c6\u6210\u5bf9\u4e8e\u795e\u7ecf\u5f62\u6001\u89c6\u89c9\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u5411\u5229\u7528\u4e8b\u4ef6\u76f8\u673a\u72ec\u7279\u4f18\u52bf\u7684\u5b9e\u65f6\u9ad8\u9891\u4eba\u673a\u4ea4\u4e92\u7cfb\u7edf\u3002\u8be5\u65b9\u6cd5\u4e3a\u4e8b\u4ef6\u76f8\u673a\u8868\u793a\u63d0\u4f9b\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u80fd\u591f\u5728\u4e0d\u540c\u8fd0\u52a8\u6761\u4ef6\u4e0b\u4f18\u5316\u65f6\u7a7a\u4fe1\u606f\u4fdd\u7559\u3002"}}
{"id": "2602.23204", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.23204", "abs": "https://arxiv.org/abs/2602.23204", "authors": ["Roberto Pellerito", "Nico Messikommer", "Giovanni Cioffi", "Marco Cannici", "Davide Scaramuzza"], "title": "Motion-aware Event Suppression for Event Cameras", "comment": null, "summary": "In this work, we introduce the first framework for Motion-aware Event Suppression, which learns to filter events triggered by IMOs and ego-motion in real time. Our model jointly segments IMOs in the current event stream while predicting their future motion, enabling anticipatory suppression of dynamic events before they occur. Our lightweight architecture achieves 173 Hz inference on consumer-grade GPUs with less than 1 GB of memory usage, outperforming previous state-of-the-art methods on the challenging EVIMO benchmark by 67\\% in segmentation accuracy while operating at a 53\\% higher inference rate. Moreover, we demonstrate significant benefits for downstream applications: our method accelerates Vision Transformer inference by 83\\% via token pruning and improves event-based visual odometry accuracy, reducing Absolute Trajectory Error (ATE) by 13\\%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u8fd0\u52a8\u611f\u77e5\u4e8b\u4ef6\u6291\u5236\u6846\u67b6\uff0c\u80fd\u591f\u5b9e\u65f6\u8fc7\u6ee4\u7531\u72ec\u7acb\u8fd0\u52a8\u7269\u4f53\u548c\u81ea\u8eab\u8fd0\u52a8\u89e6\u53d1\u7684\u4e8b\u4ef6\u3002\u8be5\u6a21\u578b\u540c\u65f6\u5206\u5272\u5f53\u524d\u4e8b\u4ef6\u6d41\u4e2d\u7684\u72ec\u7acb\u8fd0\u52a8\u7269\u4f53\u5e76\u9884\u6d4b\u5176\u672a\u6765\u8fd0\u52a8\uff0c\u5b9e\u73b0\u4e86\u5bf9\u52a8\u6001\u4e8b\u4ef6\u7684\u9884\u89c1\u6027\u6291\u5236\u3002", "motivation": "\u4e8b\u4ef6\u76f8\u673a\u5728\u52a8\u6001\u573a\u666f\u4e2d\u9762\u4e34\u72ec\u7acb\u8fd0\u52a8\u7269\u4f53\u548c\u81ea\u8eab\u8fd0\u52a8\u89e6\u53d1\u7684\u5927\u91cf\u5197\u4f59\u4e8b\u4ef6\u5e72\u6270\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5b9e\u65f6\u6709\u6548\u5730\u8fc7\u6ee4\u8fd9\u4e9b\u52a8\u6001\u4e8b\u4ef6\uff0c\u9650\u5236\u4e86\u4e8b\u4ef6\u76f8\u673a\u5728\u5b9e\u65f6\u5e94\u7528\u4e2d\u7684\u6027\u80fd\u8868\u73b0\u548c\u4e0b\u6e38\u4efb\u52a1\u6548\u7387\u3002", "method": "\u8be5\u6846\u67b6\u91c7\u7528\u8f7b\u91cf\u7ea7\u67b6\u6784\u5b9e\u73b0\u8fd0\u52a8\u611f\u77e5\u4e8b\u4ef6\u6291\u5236\uff0c\u901a\u8fc7\u8054\u5408\u5206\u5272\u5f53\u524d\u4e8b\u4ef6\u6d41\u4e2d\u7684\u72ec\u7acb\u8fd0\u52a8\u7269\u4f53\u5e76\u9884\u6d4b\u5176\u672a\u6765\u8fd0\u52a8\u8f68\u8ff9\uff0c\u5b9e\u73b0\u4e86\u5bf9\u52a8\u6001\u4e8b\u4ef6\u7684\u9884\u89c1\u6027\u6291\u5236\u3002\u6a21\u578b\u8bbe\u8ba1\u6ce8\u91cd\u8ba1\u7b97\u6548\u7387\uff0c\u80fd\u591f\u5728\u6d88\u8d39\u7ea7GPU\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u63a8\u7406\u3002", "result": "\u5728EVIMO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u5206\u5272\u51c6\u786e\u7387\u4e0a\u6bd4\u5148\u524d\u6700\u4f18\u65b9\u6cd5\u63d0\u534767%\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u9ad853%\uff0c\u8fbe\u5230173Hz\u3002\u5728\u4e0b\u6e38\u5e94\u7528\u4e2d\uff0c\u901a\u8fc7\u4ee4\u724c\u526a\u679d\u5c06\u89c6\u89c9Transformer\u63a8\u7406\u901f\u5ea6\u63d0\u534783%\uff0c\u5e76\u5c06\u4e8b\u4ef6\u89c6\u89c9\u91cc\u7a0b\u8ba1\u7684\u7edd\u5bf9\u8f68\u8ff9\u8bef\u5dee\u964d\u4f4e13%\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u8fd0\u52a8\u611f\u77e5\u4e8b\u4ef6\u6291\u5236\u6846\u67b6\u5728\u63d0\u5347\u4e8b\u4ef6\u76f8\u673a\u7cfb\u7edf\u5b9e\u65f6\u6027\u80fd\u548c\u4e0b\u6e38\u4efb\u52a1\u6548\u7387\u65b9\u9762\u7684\u663e\u8457\u4ef7\u503c\uff0c\u4e3a\u4e8b\u4ef6\u76f8\u673a\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u9884\u5904\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u8f7b\u91cf\u7ea7\u67b6\u6784\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u5b9e\u65f6\u63a8\u7406\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2602.23357", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.23357", "abs": "https://arxiv.org/abs/2602.23357", "authors": ["Aheli Saha", "Ren\u00e9 Schuster", "Didier Stricker"], "title": "Sensor Generalization for Adaptive Sensing in Event-based Object Detection via Joint Distribution Training", "comment": "12 pages, International Conference on Pattern Recognition Applications and Methods", "summary": "Bio-inspired event cameras have recently attracted significant research due to their asynchronous and low-latency capabilities. These features provide a high dynamic range and significantly reduce motion blur. However, because of the novelty in the nature of their output signals, there is a gap in the variability of available data and a lack of extensive analysis of the parameters characterizing their signals. This paper addresses these issues by providing readers with an in-depth understanding of how intrinsic parameters affect the performance of a model trained on event data, specifically for object detection. We also use our findings to expand the capabilities of the downstream model towards sensor-agnostic robustness.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6df1\u5165\u5206\u6790\u4e86\u4e8b\u4ef6\u76f8\u673a\u5185\u5728\u53c2\u6570\u5bf9\u57fa\u4e8e\u4e8b\u4ef6\u6570\u636e\u7684\u7269\u4f53\u68c0\u6d4b\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u53d1\u73b0\u6269\u5c55\u4e86\u4e0b\u6e38\u6a21\u578b\u5bf9\u4f20\u611f\u5668\u65e0\u5173\u9c81\u68d2\u6027\u7684\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1\u751f\u7269\u542f\u53d1\u7684\u4e8b\u4ef6\u76f8\u673a\u56e0\u5176\u5f02\u6b65\u548c\u4f4e\u5ef6\u8fdf\u7279\u6027\u800c\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u7531\u4e8e\u5176\u8f93\u51fa\u4fe1\u53f7\u7684\u65b0\u9896\u6027\uff0c\u73b0\u6709\u6570\u636e\u5b58\u5728\u53ef\u53d8\u6027\u5dee\u8ddd\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u5176\u4fe1\u53f7\u7279\u5f81\u53c2\u6570\u7684\u5e7f\u6cdb\u5206\u6790\uff0c\u8fd9\u9650\u5236\u4e86\u57fa\u4e8e\u4e8b\u4ef6\u6570\u636e\u7684\u6a21\u578b\u6027\u80fd\u4f18\u5316\u548c\u4f20\u611f\u5668\u65e0\u5173\u9c81\u68d2\u6027\u7684\u5b9e\u73b0\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u4e8b\u4ef6\u76f8\u673a\u7684\u5185\u5728\u53c2\u6570\u5982\u4f55\u5f71\u54cd\u57fa\u4e8e\u4e8b\u4ef6\u6570\u636e\u7684\u7269\u4f53\u68c0\u6d4b\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u5206\u6790\u7ed3\u679c\u6765\u6269\u5c55\u4e0b\u6e38\u6a21\u578b\u7684\u4f20\u611f\u5668\u65e0\u5173\u9c81\u68d2\u6027\u80fd\u529b\uff0c\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\u53c2\u6570\u5f71\u54cd\u5206\u6790\u548c\u6a21\u578b\u80fd\u529b\u6269\u5c55\u6846\u67b6\u3002", "result": "\u7814\u7a76\u63d0\u4f9b\u4e86\u5173\u4e8e\u5185\u5728\u53c2\u6570\u5bf9\u4e8b\u4ef6\u6570\u636e\u8bad\u7ec3\u6a21\u578b\u6027\u80fd\u5f71\u54cd\u7684\u6df1\u5165\u7406\u89e3\uff0c\u7279\u522b\u662f\u5728\u7269\u4f53\u68c0\u6d4b\u4efb\u52a1\u4e0a\u7684\u5177\u4f53\u5f71\u54cd\uff0c\u5e76\u6210\u529f\u6269\u5c55\u4e86\u4e0b\u6e38\u6a21\u578b\u5bf9\u4f20\u611f\u5668\u53d8\u5316\u7684\u9c81\u68d2\u6027\uff0c\u5b9e\u73b0\u4e86\u4f20\u611f\u5668\u65e0\u5173\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u4e8b\u4ef6\u76f8\u673a\u53c2\u6570\u5206\u6790\u9886\u57df\u7684\u7a7a\u767d\uff0c\u4e3a\u4f18\u5316\u57fa\u4e8e\u4e8b\u4ef6\u6570\u636e\u7684\u6a21\u578b\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\uff0c\u540c\u65f6\u63d0\u51fa\u7684\u4f20\u611f\u5668\u65e0\u5173\u9c81\u68d2\u6027\u6269\u5c55\u65b9\u6cd5\u4e3a\u4e8b\u4ef6\u76f8\u673a\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u4e8b\u4ef6\u89c6\u89c9\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
