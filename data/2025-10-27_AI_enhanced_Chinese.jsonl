{"id": "2510.21403", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2510.21403", "abs": "https://arxiv.org/abs/2510.21403", "authors": ["Jieyuan Zhang", "Xiaolong Zhou", "Shuai Wang", "Wenjie Wei", "Hanwen Liu", "Qian Sun", "Malu Zhang", "Yang Yang", "Haizhou Li"], "title": "Unveiling the Spatial-temporal Effective Receptive Fields of Spiking Neural Networks", "comment": "Acceped by 39th Conference on Neural Information Processing Systems\n  (NeurIPS 2025)", "summary": "Spiking Neural Networks (SNNs) demonstrate significant potential for\nenergy-efficient neuromorphic computing through an event-driven paradigm. While\ntraining methods and computational models have greatly advanced, SNNs struggle\nto achieve competitive performance in visual long-sequence modeling tasks. In\nartificial neural networks, the effective receptive field (ERF) serves as a\nvaluable tool for analyzing feature extraction capabilities in visual\nlong-sequence modeling. Inspired by this, we introduce the Spatio-Temporal\nEffective Receptive Field (ST-ERF) to analyze the ERF distributions across\nvarious Transformer-based SNNs. Based on the proposed ST-ERF, we reveal that\nthese models suffer from establishing a robust global ST-ERF, thereby limiting\ntheir visual feature modeling capabilities. To overcome this issue, we propose\ntwo novel channel-mixer architectures:\n\\underline{m}ulti-\\underline{l}ayer-\\underline{p}erceptron-based\nm\\underline{ixer} (MLPixer) and \\underline{s}plash-and-\\underline{r}econstruct\n\\underline{b}lock (SRB). These architectures enhance global spatial ERF through\nall timesteps in early network stages of Transformer-based SNNs, improving\nperformance on challenging visual long-sequence modeling tasks. Extensive\nexperiments conducted on the Meta-SDT variants and across object detection and\nsemantic segmentation tasks further validate the effectiveness of our proposed\nmethod. Beyond these specific applications, we believe the proposed ST-ERF\nframework can provide valuable insights for designing and optimizing SNN\narchitectures across a broader range of tasks. The code is available at\n\\href{https://github.com/EricZhang1412/Spatial-temporal-ERF}{\\faGithub~EricZhang1412/Spatial-temporal-ERF}.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u65f6\u7a7a\u6709\u6548\u611f\u53d7\u91ce\uff08ST-ERF\uff09\u6846\u67b6\u6765\u5206\u6790\u57fa\u4e8eTransformer\u7684\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e24\u79cd\u65b0\u578b\u901a\u9053\u6df7\u5408\u5668\u67b6\u6784MLPixer\u548cSRB\u6765\u589e\u5f3a\u5168\u5c40\u65f6\u7a7a\u611f\u53d7\u91ce\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89c6\u89c9\u957f\u5e8f\u5217\u5efa\u6a21\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u5728\u89c6\u89c9\u957f\u5e8f\u5217\u5efa\u6a21\u4efb\u52a1\u4e2d\u96be\u4ee5\u8fbe\u5230\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u4e3b\u8981\u95ee\u9898\u5728\u4e8e\u7f3a\u4e4f\u6709\u6548\u7684\u5168\u5c40\u65f6\u7a7a\u7279\u5f81\u63d0\u53d6\u80fd\u529b\uff0c\u800c\u4f20\u7edf\u6709\u6548\u611f\u53d7\u91ce\u5206\u6790\u5de5\u5177\u5728SNN\u4e2d\u7684\u9002\u7528\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u4e86\u65f6\u7a7a\u6709\u6548\u611f\u53d7\u91ce\uff08ST-ERF\uff09\u5206\u6790\u6846\u67b6\u6765\u8bc4\u4f30Transformer-based SNNs\u7684\u611f\u53d7\u91ce\u5206\u5e03\u7279\u6027\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e24\u79cd\u65b0\u578b\u901a\u9053\u6df7\u5408\u5668\u67b6\u6784\uff1a\u57fa\u4e8e\u591a\u5c42\u611f\u77e5\u673a\u7684MLPixer\u548c\u57fa\u4e8esplash-and-reconstruct\u7684SRB\u6a21\u5757\uff0c\u901a\u8fc7\u5728\u65e9\u671f\u7f51\u7edc\u9636\u6bb5\u589e\u5f3a\u5168\u5c40\u7a7a\u95f4\u611f\u53d7\u91ce\u6765\u6539\u8fdb\u7279\u5f81\u5efa\u6a21\u80fd\u529b\u3002", "result": "\u5728Meta-SDT\u53d8\u4f53\u4ee5\u53ca\u76ee\u6807\u68c0\u6d4b\u548c\u8bed\u4e49\u5206\u5272\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8eTransformer\u7684SNNs\u5728\u89c6\u89c9\u957f\u5e8f\u5217\u5efa\u6a21\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u63d0\u51fa\u7684ST-ERF\u6846\u67b6\u4e0d\u4ec5\u89e3\u51b3\u4e86\u5f53\u524dSNNs\u5728\u89c6\u89c9\u957f\u5e8f\u5217\u5efa\u6a21\u4e2d\u7684\u6027\u80fd\u74f6\u9888\uff0c\u8fd8\u4e3a\u66f4\u5e7f\u6cdbSNN\u67b6\u6784\u7684\u8bbe\u8ba1\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5206\u6790\u5de5\u5177\u548c\u8bbe\u8ba1\u601d\u8def\uff0c\u63a8\u52a8\u4e86\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u5728\u590d\u6742\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u53d1\u5c55\u3002"}}
